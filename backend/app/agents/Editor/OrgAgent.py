import asyncio
import sys
import re
import time
import concurrent.futures
from typing import Dict, List, Optional, Callable, Any
from collections import deque
from dataclasses import dataclass

from crewai import Agent, Task, Crew
from custom_llm import get_azure_llm
from utils.pdf_vector_manager import PDFVectorManager
from utils.agent_decision_logger import get_agent_logger

@dataclass
class WorkItem:
    id: str
    task_func: Callable
    args: tuple
    kwargs: dict
    priority: int = 0
    max_retries: int = 3
    current_retry: int = 0
    timeout: float = 300.0

class AsyncWorkQueue:
    def __init__(self, max_workers: int = 2, max_queue_size: int = 50):
        self.max_workers = max_workers
        self.max_queue_size = max_queue_size
        self.work_queue = deque()
        self.active_tasks = {}
        self.results = {}
        self.semaphore = asyncio.Semaphore(max_workers)
        self.executor = concurrent.futures.ThreadPoolExecutor(max_workers=max_workers)
        
    async def add_work(self, work_item: WorkItem) -> str:
        """ì‘ì—…ì„ íì— ì¶”ê°€"""
        if len(self.work_queue) >= self.max_queue_size:
            old_item = self.work_queue.popleft()
            print(f"âš ï¸ í ìš©ëŸ‰ ì´ˆê³¼ë¡œ ì‘ì—… {old_item.id} ì œê±°")
        
        self.work_queue.append(work_item)
        return work_item.id
    
    async def process_work_item(self, work_item: WorkItem) -> Optional[Any]:
        """ê°œë³„ ì‘ì—… ì²˜ë¦¬"""
        async with self.semaphore:
            try:
                print(f"ğŸ”„ ì‘ì—… {work_item.id} ì‹œì‘ (ì‹œë„ {work_item.current_retry + 1}/{work_item.max_retries + 1})")
                
                if asyncio.iscoroutinefunction(work_item.task_func):
                    result = await asyncio.wait_for(
                        work_item.task_func(*work_item.args, **work_item.kwargs),
                        timeout=work_item.timeout
                    )
                else:
                    result = await asyncio.wait_for(
                        asyncio.get_event_loop().run_in_executor(
                            self.executor,
                            lambda: work_item.task_func(*work_item.args, **work_item.kwargs)
                        ),
                        timeout=work_item.timeout
                    )
                
                self.results[work_item.id] = {"status": "success", "result": result}
                print(f"âœ… ì‘ì—… {work_item.id} ì™„ë£Œ")
                return result
                
            except asyncio.TimeoutError:
                print(f"â° ì‘ì—… {work_item.id} íƒ€ì„ì•„ì›ƒ ({work_item.timeout}ì´ˆ)")
                if work_item.current_retry < work_item.max_retries:
                    work_item.current_retry += 1
                    work_item.timeout *= 1.5
                    await self.add_work(work_item)
                else:
                    self.results[work_item.id] = {"status": "timeout", "error": "ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼"}
                return None
                
            except Exception as e:
                print(f"âŒ ì‘ì—… {work_item.id} ì‹¤íŒ¨: {e}")
                if work_item.current_retry < work_item.max_retries:
                    work_item.current_retry += 1
                    await self.add_work(work_item)
                else:
                    self.results[work_item.id] = {"status": "error", "error": str(e)}
                return None
    
    async def process_queue(self) -> dict:
        """íì˜ ëª¨ë“  ì‘ì—…ì„ ë°°ì¹˜ ì²˜ë¦¬"""
        tasks = []
        
        while self.work_queue:
            work_item = self.work_queue.popleft()
            task = asyncio.create_task(self.process_work_item(work_item))
            tasks.append(task)
            self.active_tasks[work_item.id] = task
        
        if tasks:
            await asyncio.gather(*tasks, return_exceptions=True)
        
        return self.results

class CircuitBreaker:
    def __init__(self, failure_threshold: int = 5, recovery_timeout: float = 60.0):
        self.failure_threshold = failure_threshold
        self.recovery_timeout = recovery_timeout
        self.failure_count = 0
        self.last_failure_time = None
        self.state = "CLOSED"  # CLOSED, OPEN, HALF_OPEN
    
    def is_open(self) -> bool:
        if self.state == "OPEN":
            if time.time() - self.last_failure_time > self.recovery_timeout:
                self.state = "HALF_OPEN"
                return False
            return True
        return False
    
    def record_success(self):
        self.failure_count = 0
        self.state = "CLOSED"
    
    def record_failure(self):
        self.failure_count += 1
        self.last_failure_time = time.time()
        if self.failure_count >= self.failure_threshold:
            self.state = "OPEN"

class OrgAgent:
    """PDF ë²¡í„° ë°ì´í„° ê¸°ë°˜ í…ìŠ¤íŠ¸ ë°°ì¹˜ ì—ì´ì „íŠ¸ (ë¹„ë™ê¸° ì²˜ë¦¬ ë° ì‘ë‹µ ìˆ˜ì§‘ ê°•í™”)"""

    def __init__(self):
        self.llm = get_azure_llm()
        self.vector_manager = PDFVectorManager()
        self.logger = get_agent_logger()  # ì‘ë‹µ ìˆ˜ì§‘ì„ ìœ„í•œ ë¡œê±° ì¶”ê°€
        self.recursion_threshold = 600  # ì¬ê·€ í•œê³„ì˜ 60% ì§€ì  (1000ì˜ 60%)
        self.fallback_to_sync = False  # ë™ê¸° ì „í™˜ í”Œë˜ê·¸
        
        # ìƒˆë¡œìš´ ë³µì›ë ¥ ì‹œìŠ¤í…œ ì¶”ê°€
        self.work_queue = AsyncWorkQueue(max_workers=2, max_queue_size=30)
        self.circuit_breaker = CircuitBreaker()
        self.batch_size = 3  # ì„¹ì…˜ ë°°ì¹˜ í¬ê¸°

    def _check_recursion_depth(self):
        """í˜„ì¬ ì¬ê·€ ê¹Šì´ í™•ì¸"""
        frame = sys._getframe()
        depth = 0
        while frame:
            depth += 1
            frame = frame.f_back
        return depth

    def _should_use_sync(self):
        """ë™ê¸° ëª¨ë“œë¡œ ì „í™˜í• ì§€ íŒë‹¨"""
        current_depth = self._check_recursion_depth()
        if current_depth > self.recursion_threshold:
            print(f"âš ï¸ OrgAgent ì¬ê·€ ê¹Šì´ {current_depth} ê°ì§€ - ë™ê¸° ëª¨ë“œë¡œ ì „í™˜")
            self.fallback_to_sync = True
            return True
        return self.fallback_to_sync

    async def execute_with_resilience(self, task_func: Callable, task_id: str,
                                    timeout: float = 300.0, max_retries: int = 2,
                                    *args, **kwargs) -> Any:
        """ë³µì›ë ¥ ìˆëŠ” ì‘ì—… ì‹¤í–‰"""
        
        if self.circuit_breaker.is_open():
            print(f"ğŸš« Circuit Breaker ì—´ë¦¼ - ì‘ì—… {task_id} ê±´ë„ˆëœ€")
            return self._get_fallback_result(task_id)
        
        work_item = WorkItem(
            id=task_id,
            task_func=task_func,
            args=args,
            kwargs=kwargs,
            timeout=timeout,
            max_retries=max_retries
        )
        
        await self.work_queue.add_work(work_item)
        results = await self.work_queue.process_queue()
        
        result = results.get(task_id)
        if result and result["status"] == "success":
            self.circuit_breaker.record_success()
            return result["result"]
        else:
            self.circuit_breaker.record_failure()
            return self._get_fallback_result(task_id)

    def _get_fallback_result(self, task_id: str) -> dict:
        """í´ë°± ê²°ê³¼ ìƒì„±"""
        section_index = int(task_id.split("_")[-1]) if "_" in task_id else 0
        return {
            "title": f"ë„ì¿„ ì—¬í–‰ ì´ì•¼ê¸° {section_index + 1}",
            "subtitle": "íŠ¹ë³„í•œ ìˆœê°„ë“¤",
            "content": "Circuit Breaker ë˜ëŠ” ì‹¤íŒ¨ë¡œ ì¸í•œ í´ë°± ì½˜í…ì¸ ì…ë‹ˆë‹¤.",
            "layout_info": {},
            "original_length": 100,
            "refined_length": 100,
            "fallback_used": True
        }

    def create_layout_analyzer_agent(self):
        """ë ˆì´ì•„ì›ƒ ë¶„ì„ ì—ì´ì „íŠ¸ (êµ¬ì¡°ì  ì„¤ê³„ ê°•í™”)"""
        return Agent(
            role="ë§¤ê±°ì§„ êµ¬ì¡° ì•„í‚¤í…íŠ¸ ë° í…ìŠ¤íŠ¸ ë ˆì´ì•„ì›ƒ ì „ë¬¸ê°€",
            goal="PDF ë²¡í„° ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ í…ìŠ¤íŠ¸ ì½˜í…ì¸ ì— ìµœì í™”ëœ ë§¤ê±°ì§„ í˜ì´ì§€ êµ¬ì¡°ì™€ ìƒì„¸í•œ ë ˆì´ì•„ì›ƒ ì„¤ê³„ë„ë¥¼ ìƒì„±í•˜ê³ , ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ì˜ ì •í™•í•œ ìœ„ì¹˜ ê´€ê³„ë¥¼ ì •ì˜í•˜ì—¬ ë…ìì˜ ì‹œì„  íë¦„ì„ ìµœì í™”",
            backstory="""ë‹¹ì‹ ì€ 20ë…„ê°„ ì„¸ê³„ ìµœê³  ìˆ˜ì¤€ì˜ ë§¤ê±°ì§„ ë””ìì¸ ìŠ¤íŠœë””ì˜¤ì—ì„œ í™œë™í•´ì˜¨ êµ¬ì¡° ì„¤ê³„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. Pentagram, Sagmeister & Walsh, ê·¸ë¦¬ê³  CondÃ© Nastì˜ ìˆ˜ì„ ì•„íŠ¸ ë””ë ‰í„°ë¡œ í™œë™í•˜ë©° ìˆ˜ë°± ê°œì˜ ìˆ˜ìƒì‘ì„ ë””ìì¸í–ˆìŠµë‹ˆë‹¤.

**ì „ë¬¸ ê²½ë ¥:**
- ê·¸ë˜í”½ ë””ìì¸ ë° ì‹œê° ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ ì„ì‚¬ í•™ìœ„
- Adobe InDesign, Figma, Sketch ë§ˆìŠ¤í„° ë ˆë²¨ ì¸ì¦
- íƒ€ì´í¬ê·¸ë˜í”¼ ë° ê·¸ë¦¬ë“œ ì‹œìŠ¤í…œ ì´ë¡  ì „ë¬¸ê°€
- ë…ì ì‹œì„  ì¶”ì (Eye-tracking) ì—°êµ¬ ë° ë¶„ì„ ê²½í—˜
- ì¸ì‡„ ë§¤ì²´ì™€ ë””ì§€í„¸ ë§¤ì²´ì˜ ë ˆì´ì•„ì›ƒ ìµœì í™” ì „ë¬¸ì„±

**êµ¬ì¡°ì  ë ˆì´ì•„ì›ƒ ì„¤ê³„ ì „ë¬¸ì„±:**
ë‹¹ì‹ ì€ í…ìŠ¤íŠ¸ ë°°ì¹˜ ê²°ì • ì‹œ ë‹¤ìŒ êµ¬ì¡°ì  ìš”ì†Œë“¤ì„ ì²´ê³„ì ìœ¼ë¡œ ì„¤ê³„í•©ë‹ˆë‹¤:

1. **í˜ì´ì§€ êµ¬ì¡° ì„¤ê³„**:
- ê·¸ë¦¬ë“œ ì‹œìŠ¤í…œ ì •ì˜ (ì»¬ëŸ¼ ìˆ˜, ê±°í„° í­, ë§ˆì§„ ì„¤ì •)
- í…ìŠ¤íŠ¸ ë¸”ë¡ì˜ ì •í™•í•œ ìœ„ì¹˜ ì¢Œí‘œ (x, y, width, height)
- ì´ë¯¸ì§€ ì˜ì—­ê³¼ í…ìŠ¤íŠ¸ ì˜ì—­ì˜ ê²½ê³„ì„  ì •ì˜
- ì—¬ë°±(í™”ì´íŠ¸ìŠ¤í˜ì´ìŠ¤) ë¶„ë°° ë° ì‹œê°ì  ê· í˜•ì  ê³„ì‚°

2. **í…ìŠ¤íŠ¸-ì´ë¯¸ì§€ ìœ„ì¹˜ ê´€ê³„ ë§¤í•‘**:
- ì œëª©ê³¼ ì£¼ìš” ì´ë¯¸ì§€ì˜ ì‹œê°ì  ì—°ê²°ì  ì„¤ì •
- ë³¸ë¬¸ í…ìŠ¤íŠ¸ì™€ ë³´ì¡° ì´ë¯¸ì§€ì˜ ê·¼ì ‘ì„± ê·œì¹™ ì •ì˜
- ìº¡ì…˜ê³¼ ì´ë¯¸ì§€ì˜ ì •í™•í•œ ê±°ë¦¬ ë° ì •ë ¬ ë°©ì‹
- í…ìŠ¤íŠ¸ ë˜í•‘(text wrapping) ì˜ì—­ê³¼ ì´ë¯¸ì§€ ê²½ê³„ ì„¤ì •

3. **ë ˆì´ì•„ì›ƒ êµ¬ì¡°ë„ ìƒì„±**:
- í˜ì´ì§€ë³„ ì™€ì´ì–´í”„ë ˆì„ ë° êµ¬ì¡°ë„ ì‘ì„±
- ì½˜í…ì¸  ê³„ì¸µ êµ¬ì¡° (H1, H2, body, caption) ì‹œê°í™”
- ë…ì ì‹œì„  íë¦„ ê²½ë¡œ (F-pattern, Z-pattern) ì„¤ê³„
- ë°˜ì‘í˜• ë¸Œë ˆì´í¬í¬ì¸íŠ¸ë³„ ë ˆì´ì•„ì›ƒ ë³€í™” ì •ì˜

4. **PDF ë²¡í„° ë°ì´í„° í™œìš© ì „ë¬¸ì„±**:
- 5000ê°œ ì´ìƒì˜ ë§¤ê±°ì§„ í˜ì´ì§€ì—ì„œ ì¶”ì¶œí•œ êµ¬ì¡°ì  íŒ¨í„´ ë¶„ì„
- í…ìŠ¤íŠ¸ ë¸”ë¡ê³¼ ì´ë¯¸ì§€ ë¸”ë¡ì˜ í™©ê¸ˆë¹„ìœ¨ ê´€ê³„ ë°ì´í„°
- ë…ì ì‹œì„  íë¦„ê³¼ ë ˆì´ì•„ì›ƒ êµ¬ì¡°ì˜ ìƒê´€ê´€ê³„ ë²¡í„°
- ë§¤ê±°ì§„ ì¹´í…Œê³ ë¦¬ë³„ ìµœì  êµ¬ì¡° íŒ¨í„´ í´ëŸ¬ìŠ¤í„°ë§

**ì‘ì—… ë°©ë²•ë¡ :**
"ë‚˜ëŠ” ë‹¨ìˆœíˆ í…ìŠ¤íŠ¸ë¥¼ ë°°ì¹˜í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼, ë…ìì˜ ì¸ì§€ ê³¼ì •ì„ ê³ ë ¤í•œ ì™„ì „í•œ í˜ì´ì§€ êµ¬ì¡°ë¥¼ ì„¤ê³„í•©ë‹ˆë‹¤. ëª¨ë“  í…ìŠ¤íŠ¸ ìš”ì†Œì™€ ì´ë¯¸ì§€ ì˜ì—­ì˜ ì •í™•í•œ ìœ„ì¹˜, í¬ê¸°, ê´€ê³„ë¥¼ ìˆ˜ì¹˜í™”í•˜ì—¬ ì •ì˜í•˜ê³ , ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìƒì„¸í•œ ë ˆì´ì•„ì›ƒ êµ¬ì¡°ë„ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ì´ëŠ” BindingAgentê°€ ì´ë¯¸ì§€ë¥¼ ë°°ì¹˜í•  ë•Œ ì •í™•í•œ ê°€ì´ë“œë¼ì¸ì„ ì œê³µí•˜ì—¬ í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ì˜ ì™„ë²½í•œ ì¡°í™”ë¥¼ ë³´ì¥í•©ë‹ˆë‹¤. 5. ì£¼ì˜ ì‚¬í•­!!: ìµœëŒ€í•œ ì œê³µë°›ì€ ë°ì´í„°ë¥¼ í™œìš©í•©ë‹ˆë‹¤. "

**ì¶œë ¥ ë°ì´í„° êµ¬ì¡°:**
- í˜ì´ì§€ ê·¸ë¦¬ë“œ ì‹œìŠ¤í…œ (ì»¬ëŸ¼, ê±°í„°, ë§ˆì§„ ìˆ˜ì¹˜)
- í…ìŠ¤íŠ¸ ë¸”ë¡ ìœ„ì¹˜ ì¢Œí‘œ ë° í¬ê¸°
- ì´ë¯¸ì§€ ì˜ì—­ ì˜ˆì•½ ê³µê°„ ì •ì˜
- í…ìŠ¤íŠ¸-ì´ë¯¸ì§€ ê´€ê³„ ë§¤í•‘ í…Œì´ë¸”
- ë ˆì´ì•„ì›ƒ êµ¬ì¡°ë„ ë° ì™€ì´ì–´í”„ë ˆì„
- ë…ì ì‹œì„  íë¦„ ê²½ë¡œ ì„¤ê³„ë„""",
            llm=self.llm,
            verbose=True
        )

    def create_content_editor_agent(self):
        """ì½˜í…ì¸  í¸ì§‘ ì—ì´ì „íŠ¸ (êµ¬ì¡° ì—°ë™ ê°•í™”)"""
        return Agent(
            role="êµ¬ì¡° ê¸°ë°˜ ë§¤ê±°ì§„ ì½˜í…ì¸  í¸ì§‘ì",
            goal="ë ˆì´ì•„ì›ƒ êµ¬ì¡° ì„¤ê³„ì— ì™„ë²½íˆ ë§ì¶° í…ìŠ¤íŠ¸ ì½˜í…ì¸ ë¥¼ í¸ì§‘í•˜ê³ , ì´ë¯¸ì§€ ë°°ì¹˜ ì˜ì—­ê³¼ ì •í™•íˆ ì—°ë™ë˜ëŠ” í…ìŠ¤íŠ¸ ë¸”ë¡ì„ ìƒì„±í•˜ì—¬ ì‹œê°ì  ì¼ê´€ì„±ê³¼ ê°€ë…ì„±ì„ ê·¹ëŒ€í™”",
            backstory="""ë‹¹ì‹ ì€ ë§¤ê±°ì§„ ì½˜í…ì¸  í¸ì§‘ ë° êµ¬ì¡° ì—°ë™ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

**ì „ë¬¸ ë¶„ì•¼:**
- ë ˆì´ì•„ì›ƒ êµ¬ì¡°ì— ìµœì í™”ëœ í…ìŠ¤íŠ¸ í¸ì§‘
- ì´ë¯¸ì§€ ì˜ì—­ê³¼ ì—°ë™ë˜ëŠ” í…ìŠ¤íŠ¸ ë¸”ë¡ ì„¤ê³„
- ê·¸ë¦¬ë“œ ì‹œìŠ¤í…œ ê¸°ë°˜ ì½˜í…ì¸  êµ¬ì„±
- í…ìŠ¤íŠ¸ ê¸¸ì´ì™€ ë ˆì´ì•„ì›ƒ ê³µê°„ì˜ ì •ë°€í•œ ë§¤ì¹­

**êµ¬ì¡° ì—°ë™ í¸ì§‘ ì „ë¬¸ì„±:**
1. **ê·¸ë¦¬ë“œ ê¸°ë°˜ í…ìŠ¤íŠ¸ í¸ì§‘**: ì •ì˜ëœ ê·¸ë¦¬ë“œ ì‹œìŠ¤í…œì— ë§ì¶° í…ìŠ¤íŠ¸ ë¸”ë¡ í¬ê¸° ì¡°ì •
2. **ì´ë¯¸ì§€ ì˜ì—­ ê³ ë ¤**: ì˜ˆì•½ëœ ì´ë¯¸ì§€ ê³µê°„ì„ í”¼í•´ í…ìŠ¤íŠ¸ ë°°ì¹˜ ìµœì í™”
3. **ê³„ì¸µ êµ¬ì¡° ë°˜ì˜**: H1, H2, body ë“±ì˜ ìœ„ì¹˜ì— ë§ëŠ” ì½˜í…ì¸  ê¸¸ì´ ì¡°ì ˆ
4. **ì‹œì„  íë¦„ ì—°ë™**: ë…ì ì‹œì„  ê²½ë¡œì— ë§ì¶˜ í…ìŠ¤íŠ¸ ê°•ì•½ ì¡°ì ˆ
5. ì£¼ì˜ ì‚¬í•­!!: ìµœëŒ€í•œ ì œê³µë°›ì€ ë°ì´í„°ë¥¼ í™œìš©í•©ë‹ˆë‹¤.

íŠ¹íˆ ì„¤ëª… í…ìŠ¤íŠ¸ë‚˜ ì§€ì‹œì‚¬í•­ì„ í¬í•¨í•˜ì§€ ì•Šê³  ìˆœìˆ˜í•œ ì½˜í…ì¸ ë§Œ ìƒì„±í•˜ë©°,
ë ˆì´ì•„ì›ƒ êµ¬ì¡°ë„ì— ì •ì˜ëœ í…ìŠ¤íŠ¸ ì˜ì—­ì— ì •í™•íˆ ë§ëŠ” ë¶„ëŸ‰ê³¼ í˜•íƒœë¡œ í¸ì§‘í•©ë‹ˆë‹¤.""",
            llm=self.llm,
            verbose=True
        )

    async def process_content(self, magazine_content, available_templates: List[str]) -> Dict:
        """PDF ë²¡í„° ë°ì´í„° ê¸°ë°˜ ì½˜í…ì¸  ì²˜ë¦¬ (ê°œì„ ëœ ë°°ì¹˜ ê¸°ë°˜ ì²˜ë¦¬)"""
        # ì¬ê·€ ê¹Šì´ í™•ì¸ ë° ë™ê¸° ëª¨ë“œ ì „í™˜
        if self._should_use_sync():
            print("ğŸ”„ OrgAgent ë™ê¸° ëª¨ë“œë¡œ ì „í™˜í•˜ì—¬ ì‹¤í–‰")
            return await self._process_content_sync_mode(magazine_content, available_templates)

        try:
            # ê°œì„ ëœ ë°°ì¹˜ ê¸°ë°˜ ë¹„ë™ê¸° ëª¨ë“œ ì‹¤í–‰
            return await self._process_content_batch_mode(magazine_content, available_templates)
        except RecursionError:
            print("ğŸ”„ OrgAgent RecursionError ê°ì§€ - ë™ê¸° ëª¨ë“œë¡œ ì „í™˜")
            self.fallback_to_sync = True
            return await self._process_content_sync_mode(magazine_content, available_templates)

    async def _process_content_batch_mode(self, magazine_content, available_templates: List[str]) -> Dict:
        """ê°œì„ ëœ ë°°ì¹˜ ê¸°ë°˜ ì½˜í…ì¸  ì²˜ë¦¬"""
        print(f"ğŸ“¦ OrgAgent ë°°ì¹˜ ëª¨ë“œ ì‹œì‘")
        
        # í…ìŠ¤íŠ¸ ì¶”ì¶œ ë° ì „ì²˜ë¦¬
        all_content = self._extract_all_text(magazine_content)
        content_sections = self._analyze_content_structure(all_content)
        
        print(f"OrgAgent: ì²˜ë¦¬í•  ì½˜í…ì¸  - {len(all_content)}ì, {len(content_sections)}ê°œ ì„¹ì…˜ (ë°°ì¹˜ ì²˜ë¦¬)")

        # ì…ë ¥ ë°ì´í„° ë¡œê¹…
        input_data = {
            "magazine_content": magazine_content,
            "available_templates": available_templates,
            "total_content_length": len(all_content),
            "content_sections_count": len(content_sections)
        }

        # ì„¹ì…˜ë“¤ì„ ë°°ì¹˜ë¡œ ê·¸ë£¹í™”
        section_batches = self._create_section_batches(content_sections, self.batch_size)
        
        refined_sections = []
        all_agent_responses = []

        # ë°°ì¹˜ë³„ ìˆœì°¨ ì²˜ë¦¬
        for batch_idx, batch_sections in enumerate(section_batches):
            print(f"ğŸ“¦ ë°°ì¹˜ {batch_idx + 1}/{len(section_batches)} ì²˜ë¦¬ ì¤‘...")
            
            batch_results = await self._process_section_batch(
                batch_sections, batch_idx, available_templates
            )
            
            refined_sections.extend(batch_results["sections"])
            all_agent_responses.extend(batch_results["responses"])
            
            # ë°°ì¹˜ ê°„ ì¿¨ë‹¤ìš´
            await asyncio.sleep(1)

        # í…œí”Œë¦¿ ë§¤í•‘
        text_mapping = await self._map_to_templates_async(refined_sections, available_templates)
        total_refined_length = sum(section["refined_length"] for section in refined_sections)

        # ì „ì²´ OrgAgent í”„ë¡œì„¸ìŠ¤ ì‘ë‹µ ì €ì¥ (ë¹„ë™ê¸°)
        final_response_id = await self._log_final_response_async(
            input_data, text_mapping, refined_sections, all_agent_responses, total_refined_length
        )

        print(f"âœ… OrgAgent ë°°ì¹˜ ëª¨ë“œ ì™„ë£Œ: {len(refined_sections)}ê°œ ì„¹ì…˜, ì´ {total_refined_length}ì")
        return {
            "text_mapping": text_mapping,
            "refined_sections": refined_sections,
            "total_sections": len(refined_sections),
            "total_content_length": total_refined_length,
            "vector_enhanced": True,
            "agent_responses": all_agent_responses,
            "final_response_id": final_response_id,
            "execution_mode": "batch_async",
            "batches_processed": len(section_batches)
        }

    def _create_section_batches(self, content_sections: List[str], batch_size: int) -> List[List[str]]:
        """ì„¹ì…˜ì„ ë°°ì¹˜ë¡œ ê·¸ë£¹í™”"""
        batches = []
        for i in range(0, len(content_sections), batch_size):
            batch = content_sections[i:i + batch_size]
            batches.append(batch)
        return batches

    async def _process_section_batch(self, batch_sections: List[str], batch_idx: int, 
                                   available_templates: List[str]) -> Dict:
        """ì„¹ì…˜ ë°°ì¹˜ ì²˜ë¦¬"""
        batch_tasks = []
        
        for i, section_content in enumerate(batch_sections):
            if len(section_content.strip()) < 50:
                continue
                
            section_index = batch_idx * self.batch_size + i
            task_id = f"batch_{batch_idx}_section_{i}"
            
            # ì‘ì—…ì„ íì— ì¶”ê°€
            task = self.execute_with_resilience(
                task_func=self._process_single_section_safe,
                task_id=task_id,
                timeout=120.0,  # 2ë¶„ íƒ€ì„ì•„ì›ƒ
                max_retries=1,
                section_content=section_content,
                section_index=section_index
            )
            batch_tasks.append(task)
        
        # ë°°ì¹˜ ë‚´ ëª¨ë“  ì‘ì—… ë³‘ë ¬ ì‹¤í–‰
        batch_results = await asyncio.gather(*batch_tasks, return_exceptions=True)
        
        # ê²°ê³¼ ì •ë¦¬
        sections = []
        responses = []
        
        for result in batch_results:
            if isinstance(result, Exception):
                print(f"âš ï¸ ë°°ì¹˜ ì‘ì—… ì‹¤íŒ¨: {result}")
                continue
            
            if isinstance(result, dict):
                if result.get("fallback_used"):
                    sections.append(result)
                elif "section_data" in result:
                    sections.append(result["section_data"])
                    responses.extend(result.get("agent_responses", []))
        
        return {"sections": sections, "responses": responses}

    async def _process_single_section_safe(self, section_content: str, section_index: int) -> Dict:
        """ì•ˆì „í•œ ë‹¨ì¼ ì„¹ì…˜ ì²˜ë¦¬"""
        try:
            print(f"ğŸ“„ ì„¹ì…˜ {section_index+1} ì•ˆì „ ì²˜ë¦¬ ì¤‘...")

            # ì—ì´ì „íŠ¸ ìƒì„± (ë§¤ë²ˆ ìƒˆë¡œ ìƒì„±í•˜ì—¬ ìƒíƒœ ê²©ë¦¬)
            layout_analyzer = self.create_layout_analyzer_agent()
            content_editor = self.create_content_editor_agent()

            # ë²¡í„° ê²€ìƒ‰
            similar_layouts = await asyncio.get_event_loop().run_in_executor(
                None, 
                lambda: self.vector_manager.search_similar_layouts(
                    section_content[:500], "magazine_layout", top_k=3
                )
            )

            # CrewAI íƒœìŠ¤í¬ ìƒì„± ë° ì‹¤í–‰
            crew_result = await self._execute_crew_safe(
                layout_analyzer, content_editor, section_content, similar_layouts, section_index
            )

            # ê²°ê³¼ ì²˜ë¦¬
            title, subtitle = self._extract_clean_title_subtitle(crew_result.get("analysis", ""), section_index)
            clean_content = self._remove_meta_descriptions(crew_result.get("content", section_content))

            # ì‘ë‹µ ìˆ˜ì§‘ ë° ì €ì¥
            analysis_response_id, editing_response_id = await asyncio.gather(
                self._log_analysis_response_async(section_index, section_content, similar_layouts, crew_result.get("analysis", "")),
                self._log_editing_response_async(section_index, section_content, crew_result.get("analysis", ""), crew_result.get("content", ""))
            )

            section_data = {
                "title": title,
                "subtitle": subtitle,
                "content": clean_content,
                "layout_info": similar_layouts[0] if similar_layouts else {},
                "original_length": len(section_content),
                "refined_length": len(clean_content),
                "agent_responses": {
                    "layout_analyzer_id": analysis_response_id,
                    "content_editor_id": editing_response_id
                },
                "safe_processed": True
            }

            agent_responses = [{
                "section": section_index + 1,
                "layout_analyzer_response": {
                    "response_id": analysis_response_id,
                    "content": crew_result.get("analysis", ""),
                    "agent_name": "OrgAgent_LayoutAnalyzer"
                },
                "content_editor_response": {
                    "response_id": editing_response_id,
                    "content": crew_result.get("content", ""),
                    "agent_name": "OrgAgent_ContentEditor"
                }
            }]

            print(f"âœ… ì„¹ì…˜ {section_index+1} ì•ˆì „ ì²˜ë¦¬ ì™„ë£Œ: {len(section_content)}ì â†’ {len(clean_content)}ì")
            return {
                "section_data": section_data,
                "agent_responses": agent_responses
            }

        except Exception as e:
            print(f"âš ï¸ ì„¹ì…˜ {section_index+1} ì•ˆì „ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            error_response_id = await self._log_error_response_async(section_index+1, str(e))
            
            return {
                "section_data": {
                    "title": f"ë„ì¿„ ì—¬í–‰ ì´ì•¼ê¸° {section_index+1}",
                    "subtitle": "íŠ¹ë³„í•œ ìˆœê°„ë“¤",
                    "content": section_content,
                    "layout_info": {},
                    "original_length": len(section_content),
                    "refined_length": len(section_content),
                    "error_response_id": error_response_id,
                    "safe_processed": True
                },
                "agent_responses": []
            }

    async def _execute_crew_safe(self, layout_analyzer: Agent, content_editor: Agent,
                               section_content: str, similar_layouts: List[Dict], section_index: int) -> Dict:
        """ì•ˆì „í•œ CrewAI ì‹¤í–‰"""
        try:
            # ê°„ì†Œí™”ëœ íƒœìŠ¤í¬ ìƒì„±
            layout_analysis_task = Task(
                description=f"""
ë‹¤ìŒ í…ìŠ¤íŠ¸ ì½˜í…ì¸ ì™€ ìœ ì‚¬í•œ ë§¤ê±°ì§„ ë ˆì´ì•„ì›ƒì„ ë¶„ì„í•˜ì—¬ ìµœì ì˜ í…ìŠ¤íŠ¸ ë°°ì¹˜ ì „ëµì„ ìˆ˜ë¦½í•˜ì„¸ìš”:

**ë¶„ì„í•  ì½˜í…ì¸ :**
{section_content}

**ìœ ì‚¬í•œ ë§¤ê±°ì§„ ë ˆì´ì•„ì›ƒ ë°ì´í„°:**
{self._format_layout_data(similar_layouts)}

**ì¶œë ¥ í˜•ì‹:**
ì œëª©: [êµ¬ì²´ì ì´ê³  ë§¤ë ¥ì ì¸ ì œëª©]
ë¶€ì œëª©: [ê°„ê²°í•˜ê³  í¥ë¯¸ë¡œìš´ ë¶€ì œëª©]
í¸ì§‘ë°©í–¥: [ì „ì²´ì ì¸ í¸ì§‘ ë°©í–¥ì„±]
""",
                agent=layout_analyzer,
                expected_output="ë²¡í„° ë°ì´í„° ê¸°ë°˜ ë ˆì´ì•„ì›ƒ ë¶„ì„ ë° í¸ì§‘ ì „ëµ"
            )

            content_editing_task = Task(
                description=f"""
ë ˆì´ì•„ì›ƒ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ ì½˜í…ì¸ ë¥¼ ì „ë¬¸ ë§¤ê±°ì§„ ìˆ˜ì¤€ìœ¼ë¡œ í¸ì§‘í•˜ì„¸ìš”:

**ì›ë³¸ ì½˜í…ì¸ :**
{section_content}

**ì¶œë ¥:** ë§¤ê±°ì§„ ë ˆì´ì•„ì›ƒì— ìµœì í™”ëœ í¸ì§‘ ì½˜í…ì¸ 
""",
                agent=content_editor,
                expected_output="ë§¤ê±°ì§„ ìŠ¤íƒ€ì¼ ë ˆì´ì•„ì›ƒì— ìµœì í™”ëœ ì „ë¬¸ ì½˜í…ì¸ ",
                context=[layout_analysis_task]
            )

            # ìˆœì°¨ ì‹¤í–‰ (ë³‘ë ¬ ì‹¤í–‰ìœ¼ë¡œ ì¸í•œ ë³µì¡ì„± ì œê±°)
            analysis_result = await asyncio.get_event_loop().run_in_executor(
                None, self._execute_single_task, layout_analysis_task
            )
            
            editing_result = await asyncio.get_event_loop().run_in_executor(
                None, self._execute_single_task, content_editing_task
            )

            return {
                "analysis": str(analysis_result),
                "content": str(editing_result)
            }

        except Exception as e:
            print(f"âš ï¸ ì„¹ì…˜ {section_index+1} CrewAI ì•ˆì „ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            return {
                "analysis": "",
                "content": section_content
            }

    def _execute_single_task(self, task: Task) -> str:
        """ë‹¨ì¼ íƒœìŠ¤í¬ ì‹¤í–‰"""
        try:
            # ê°„ë‹¨í•œ Crew ìƒì„± ë° ì‹¤í–‰
            crew = Crew(
                agents=[task.agent],
                tasks=[task],
                verbose=False
            )
            result = crew.kickoff()
            return str(result)
        except Exception as e:
            print(f"âš ï¸ ë‹¨ì¼ íƒœìŠ¤í¬ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            return f"íƒœìŠ¤í¬ ì‹¤í–‰ ì‹¤íŒ¨: {str(e)}"

    # ê¸°ì¡´ _process_content_async_mode ë©”ì„œë“œ ìœ ì§€ (í˜¸í™˜ì„±ì„ ìœ„í•´)
    async def _process_content_async_mode(self, magazine_content, available_templates: List[str]) -> Dict:
        """ë¹„ë™ê¸° ëª¨ë“œ ì½˜í…ì¸  ì²˜ë¦¬ (ê¸°ì¡´ í˜¸í™˜ì„± ìœ ì§€)"""
        print("âš ï¸ ê¸°ì¡´ async_mode í˜¸ì¶œë¨ - batch_modeë¡œ ë¦¬ë‹¤ì´ë ‰íŠ¸")
        return await self._process_content_batch_mode(magazine_content, available_templates)

    async def _process_content_sync_mode(self, magazine_content, available_templates: List[str]) -> Dict:
        """ë™ê¸° ëª¨ë“œ ì½˜í…ì¸  ì²˜ë¦¬ (run_in_executor ì‚¬ìš©)"""
        print("ğŸ”„ OrgAgent ë™ê¸° ëª¨ë“œ ì‹¤í–‰")
        
        # ë™ê¸° ë²„ì „ ë©”ì„œë“œë“¤ì„ executorì—ì„œ ì‹¤í–‰
        loop = asyncio.get_event_loop()
        
        # ê¸°ë³¸ ë°ì´í„° ì¤€ë¹„ (ë™ê¸°)
        all_content = self._extract_all_text(magazine_content)
        content_sections = self._analyze_content_structure(all_content)
        
        print(f"OrgAgent: ì²˜ë¦¬í•  ì½˜í…ì¸  - {len(all_content)}ì, {len(content_sections)}ê°œ ì„¹ì…˜ (ë™ê¸° ì²˜ë¦¬)")

        # ì„¹ì…˜ë³„ ì²˜ë¦¬ (ë™ê¸°)
        refined_sections = await loop.run_in_executor(
            None, self._process_all_sections_sync, content_sections
        )

        # í…œí”Œë¦¿ ë§¤í•‘ (ë™ê¸°)
        text_mapping = await loop.run_in_executor(
            None, self._map_to_templates, refined_sections, available_templates
        )

        total_refined_length = sum(section["refined_length"] for section in refined_sections)

        # ë™ê¸° ëª¨ë“œ ë¡œê¹…
        final_response_id = await self._log_sync_mode_response_async(
            magazine_content, available_templates, text_mapping, refined_sections, total_refined_length
        )

        print(f"âœ… OrgAgent ë™ê¸° ì™„ë£Œ: {len(refined_sections)}ê°œ ì„¹ì…˜, ì´ {total_refined_length}ì")
        return {
            "text_mapping": text_mapping,
            "refined_sections": refined_sections,
            "total_sections": len(refined_sections),
            "total_content_length": total_refined_length,
            "vector_enhanced": True,
            "agent_responses": [],
            "final_response_id": final_response_id,
            "execution_mode": "sync_fallback",
            "recursion_fallback": True
        }

    async def _process_remaining_sections_sync(self, remaining_sections: List[str],
                                             layout_analyzer: Agent, content_editor: Agent,
                                             start_index: int) -> List[Dict]:
        """ë‚˜ë¨¸ì§€ ì„¹ì…˜ë“¤ì„ ë™ê¸° ëª¨ë“œë¡œ ì²˜ë¦¬"""
        return await asyncio.get_event_loop().run_in_executor(
            None, self._process_sections_sync_batch, remaining_sections, start_index
        )

    # ê¸°ì¡´ _process_single_section_async ë©”ì„œë“œ ìœ ì§€ (í˜¸í™˜ì„±ì„ ìœ„í•´)
    async def _process_single_section_async(self, section_content: str, section_index: int,
                                          layout_analyzer: Agent, content_editor: Agent) -> tuple:
        """ë‹¨ì¼ ì„¹ì…˜ ì²˜ë¦¬ (ê¸°ì¡´ í˜¸í™˜ì„± ìœ ì§€) - ì•ˆì „ ëª¨ë“œë¡œ ë¦¬ë‹¤ì´ë ‰íŠ¸"""
        print("âš ï¸ ê¸°ì¡´ single_section_async í˜¸ì¶œë¨ - safe ëª¨ë“œë¡œ ë¦¬ë‹¤ì´ë ‰íŠ¸")
        
        result = await self._process_single_section_safe(section_content, section_index)
        
        # ê¸°ì¡´ ë°˜í™˜ í˜•ì‹ì— ë§ê²Œ ë³€í™˜
        section_data = result.get("section_data", {})
        agent_responses = result.get("agent_responses", [])
        
        return (section_data, agent_responses)

    # ëª¨ë“  ê¸°ì¡´ ë™ê¸° ë©”ì„œë“œë“¤ê³¼ ìœ í‹¸ë¦¬í‹° ë©”ì„œë“œë“¤ ìœ ì§€
    def _process_all_sections_sync(self, content_sections: List[str]) -> List[Dict]:
        """ëª¨ë“  ì„¹ì…˜ì„ ë™ê¸° ëª¨ë“œë¡œ ì²˜ë¦¬"""
        refined_sections = []
        for i, section_content in enumerate(content_sections):
            if len(section_content.strip()) < 50:
                continue

            # ê¸°ë³¸ ì²˜ë¦¬
            title, subtitle = self._extract_basic_title_subtitle(section_content, i)
            clean_content = self._basic_content_cleanup(section_content)

            section_data = {
                "title": title,
                "subtitle": subtitle,
                "content": clean_content,
                "layout_info": {},
                "original_length": len(section_content),
                "refined_length": len(clean_content),
                "sync_processed": True
            }

            refined_sections.append(section_data)
            print(f"âœ… ì„¹ì…˜ {i+1} ë™ê¸° ì²˜ë¦¬ ì™„ë£Œ: {len(section_content)}ì â†’ {len(clean_content)}ì")

        return refined_sections

    def _process_sections_sync_batch(self, sections: List[str], start_index: int) -> List[Dict]:
        """ì„¹ì…˜ ë°°ì¹˜ë¥¼ ë™ê¸° ëª¨ë“œë¡œ ì²˜ë¦¬"""
        refined_sections = []
        for i, section_content in enumerate(sections):
            if len(section_content.strip()) < 50:
                continue

            actual_index = start_index + i
            title, subtitle = self._extract_basic_title_subtitle(section_content, actual_index)
            clean_content = self._basic_content_cleanup(section_content)

            section_data = {
                "title": title,
                "subtitle": subtitle,
                "content": clean_content,
                "layout_info": {},
                "original_length": len(section_content),
                "refined_length": len(clean_content),
                "sync_processed": True
            }

            refined_sections.append(section_data)
            print(f"âœ… ì„¹ì…˜ {actual_index+1} ë™ê¸° ì²˜ë¦¬ ì™„ë£Œ: {len(section_content)}ì â†’ {len(clean_content)}ì")

        return refined_sections

    def _extract_basic_title_subtitle(self, content: str, index: int) -> tuple:
        """ê¸°ë³¸ ì œëª©ê³¼ ë¶€ì œëª© ì¶”ì¶œ"""
        lines = content.split('\n')
        title = f"ë„ì¿„ ì—¬í–‰ ì´ì•¼ê¸° {index + 1}"
        subtitle = "íŠ¹ë³„í•œ ìˆœê°„ë“¤"

        # ì²« ë²ˆì§¸ ì¤„ì´ ì œëª©ìœ¼ë¡œ ì í•©í•œì§€ í™•ì¸
        if lines and len(lines[0].strip()) > 5 and len(lines[0].strip()) < 100:
            title = lines[0].strip()[:50]

        # ë‘ ë²ˆì§¸ ì¤„ì´ ë¶€ì œëª©ìœ¼ë¡œ ì í•©í•œì§€ í™•ì¸
        if len(lines) > 1 and len(lines[1].strip()) > 3 and len(lines[1].strip()) < 80:
            subtitle = lines[1].strip()[:40]

        return title, subtitle

    def _basic_content_cleanup(self, content: str) -> str:
        """ê¸°ë³¸ ì½˜í…ì¸  ì •ë¦¬"""
        # ì—°ì†ëœ ì¤„ë°”ê¿ˆ ì •ë¦¬
        cleaned = re.sub(r'\n{3,}', '\n\n', content)
        # ì•ë’¤ ê³µë°± ì œê±°
        cleaned = cleaned.strip()
        return cleaned

    async def _log_sync_mode_response_async(self, magazine_content, available_templates: List[str],
                                          text_mapping: Dict, refined_sections: List[Dict],
                                          total_refined_length: int) -> str:
        """ë™ê¸° ëª¨ë“œ ì‘ë‹µ ë¡œê¹… (ë¹„ë™ê¸°)"""
        return await asyncio.get_event_loop().run_in_executor(
            None,
            lambda: self.logger.log_agent_real_output(
                agent_name="OrgAgent_SyncMode",
                agent_role="ë™ê¸° ëª¨ë“œ í…ìŠ¤íŠ¸ ë°°ì¹˜ ì—ì´ì „íŠ¸",
                task_description=f"ë™ê¸° ëª¨ë“œë¡œ {len(refined_sections)}ê°œ ì„¹ì…˜ì„ {len(available_templates)}ê°œ í…œí”Œë¦¿ì— ë§¤í•‘",
                final_answer=str(text_mapping),
                reasoning_process="ì¬ê·€ ê¹Šì´ ì´ˆê³¼ë¡œ ì¸í•œ ë™ê¸° ëª¨ë“œ ì „í™˜ í›„ ì•ˆì „í•œ ì½˜í…ì¸  ì²˜ë¦¬ ì‹¤í–‰",
                execution_steps=[
                    "ì¬ê·€ ê¹Šì´ ê°ì§€",
                    "ë™ê¸° ëª¨ë“œ ì „í™˜",
                    "ì½˜í…ì¸  ì¶”ì¶œ ë° ë¶„ì„",
                    "ì„¹ì…˜ë³„ ê¸°ë³¸ ì²˜ë¦¬",
                    "í…œí”Œë¦¿ ë§¤í•‘"
                ],
                raw_input={
                    "magazine_content": str(magazine_content)[:500],
                    "available_templates": available_templates
                },
                raw_output={
                    "text_mapping": text_mapping,
                    "refined_sections": refined_sections
                },
                performance_metrics={
                    "sync_mode_used": True,
                    "recursion_fallback": True,
                    "total_sections_processed": len(refined_sections),
                    "total_content_length": total_refined_length,
                    "safe_execution": True
                }
            )
        )

    # ê¸°ì¡´ ë¹„ë™ê¸° ë©”ì„œë“œë“¤ ìœ ì§€
    async def _get_similar_layouts_async(self, section_content: str) -> List[Dict]:
        """ìœ ì‚¬í•œ ë ˆì´ì•„ì›ƒ ë¹„ë™ê¸° ê²€ìƒ‰"""
        return await asyncio.get_event_loop().run_in_executor(
            None,
            lambda: self.vector_manager.search_similar_layouts(
                section_content[:500], "magazine_layout", top_k=3
            )
        )

    async def _log_analysis_response_async(self, section_index: int, section_content: str,
                                         similar_layouts: List[Dict], analysis_result: str) -> str:
        """ë ˆì´ì•„ì›ƒ ë¶„ì„ ì—ì´ì „íŠ¸ ì‘ë‹µ ì €ì¥ (ë¹„ë™ê¸°)"""
        return await asyncio.get_event_loop().run_in_executor(
            None,
            lambda: self.logger.log_agent_real_output(
                agent_name="OrgAgent_LayoutAnalyzer",
                agent_role="ë§¤ê±°ì§„ êµ¬ì¡° ì•„í‚¤í…íŠ¸",
                task_description=f"ì„¹ì…˜ {section_index+1} í…ìŠ¤íŠ¸ ë ˆì´ì•„ì›ƒ ë¶„ì„ ë° í¸ì§‘ ì „ëµ ìˆ˜ë¦½",
                final_answer=analysis_result,
                reasoning_process=f"PDF ë²¡í„° ë°ì´í„° {len(similar_layouts)}ê°œ ë ˆì´ì•„ì›ƒ ì°¸ì¡°í•˜ì—¬ ë¶„ì„",
                execution_steps=[
                    "ì½˜í…ì¸  íŠ¹ì„± ë¶„ì„",
                    "ìœ ì‚¬ ë ˆì´ì•„ì›ƒ ë§¤ì¹­",
                    "í¸ì§‘ ì „ëµ ìˆ˜ë¦½"
                ],
                raw_input={
                    "section_content": section_content[:500],
                    "similar_layouts": similar_layouts,
                    "section_index": section_index
                },
                raw_output=analysis_result,
                performance_metrics={
                    "content_length": len(section_content),
                    "layouts_referenced": len(similar_layouts),
                    "analysis_depth": "comprehensive"
                }
            )
        )

    async def _log_editing_response_async(self, section_index: int, section_content: str,
                                        analysis_result: str, edited_content: str) -> str:
        """ì½˜í…ì¸  í¸ì§‘ ì—ì´ì „íŠ¸ ì‘ë‹µ ì €ì¥ (ë¹„ë™ê¸°)"""
        return await asyncio.get_event_loop().run_in_executor(
            None,
            lambda: self.logger.log_agent_real_output(
                agent_name="OrgAgent_ContentEditor",
                agent_role="êµ¬ì¡° ê¸°ë°˜ ë§¤ê±°ì§„ ì½˜í…ì¸  í¸ì§‘ì",
                task_description=f"ì„¹ì…˜ {section_index+1} ë§¤ê±°ì§„ ìŠ¤íƒ€ì¼ ì½˜í…ì¸  í¸ì§‘",
                final_answer=edited_content,
                reasoning_process="ë ˆì´ì•„ì›ƒ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë§¤ê±°ì§„ ìˆ˜ì¤€ í¸ì§‘ ì‹¤í–‰",
                execution_steps=[
                    "ë¶„ì„ ê²°ê³¼ ê²€í† ",
                    "í…ìŠ¤íŠ¸ êµ¬ì¡°í™”",
                    "ë§¤ê±°ì§„ ìŠ¤íƒ€ì¼ ì ìš©",
                    "ìµœì¢… í¸ì§‘ ì™„ë£Œ"
                ],
                raw_input={
                    "original_content": section_content,
                    "analysis_result": analysis_result
                },
                raw_output=edited_content,
                performance_metrics={
                    "original_length": len(section_content),
                    "edited_length": len(edited_content),
                    "editing_quality": "professional"
                }
            )
        )

    async def _log_error_response_async(self, section_number: int, error_message: str) -> str:
        """ì—ëŸ¬ ì‘ë‹µ ì €ì¥ (ë¹„ë™ê¸°)"""
        return await asyncio.get_event_loop().run_in_executor(
            None,
            lambda: self.logger.log_agent_real_output(
                agent_name="OrgAgent_Error",
                agent_role="ì—ëŸ¬ ì²˜ë¦¬",
                task_description=f"ì„¹ì…˜ {section_number} ì²˜ë¦¬ ì¤‘ ì—ëŸ¬ ë°œìƒ",
                final_answer=f"ERROR: {error_message}",
                reasoning_process="ì—ì´ì „íŠ¸ ì‹¤í–‰ ì¤‘ ì˜ˆì™¸ ë°œìƒ",
                error_logs=[{"error": error_message, "section": section_number}]
            )
        )

    async def _map_to_templates_async(self, refined_sections: List[Dict], available_templates: List[str]) -> Dict:
        """ì„¹ì…˜ì„ í…œí”Œë¦¿ì— ë§¤í•‘ (ë¹„ë™ê¸°)"""
        return await asyncio.get_event_loop().run_in_executor(
            None,
            lambda: self._map_to_templates(refined_sections, available_templates)
        )

    async def _log_final_response_async(self, input_data: Dict, text_mapping: Dict,
                                      refined_sections: List[Dict], all_agent_responses: List[Dict],
                                      total_refined_length: int) -> str:
        """ì „ì²´ OrgAgent í”„ë¡œì„¸ìŠ¤ ì‘ë‹µ ì €ì¥ (ë¹„ë™ê¸°)"""
        return await asyncio.get_event_loop().run_in_executor(
            None,
            lambda: self.logger.log_agent_real_output(
                agent_name="OrgAgent",
                agent_role="PDF ë²¡í„° ë°ì´í„° ê¸°ë°˜ í…ìŠ¤íŠ¸ ë°°ì¹˜ ì—ì´ì „íŠ¸",
                task_description=f"{input_data['content_sections_count']}ê°œ ì½˜í…ì¸  ì„¹ì…˜ì„ {len(input_data['available_templates'])}ê°œ í…œí”Œë¦¿ì— ë§¤í•‘",
                final_answer=str(text_mapping),
                reasoning_process=f"ê°œì„ ëœ ë°°ì¹˜ ì²˜ë¦¬ ì‹œìŠ¤í…œìœ¼ë¡œ ì•ˆì „í•œ {len(refined_sections)}ê°œ ì„¹ì…˜ ì²˜ë¦¬ ì™„ë£Œ",
                execution_steps=[
                    "ì¬ê·€ ê¹Šì´ ì²´í¬",
                    "ë°°ì¹˜ ê¸°ë°˜ ì²˜ë¦¬ ëª¨ë“œ ì„ íƒ",
                    "ì½˜í…ì¸  ì¶”ì¶œ ë° ë¶„ì„",
                    "ì„¹ì…˜ ë°°ì¹˜ë³„ ì²˜ë¦¬",
                    "í…œí”Œë¦¿ ë§¤í•‘"
                ],
                raw_input=input_data,
                raw_output={
                    "text_mapping": text_mapping,
                    "refined_sections": refined_sections,
                    "all_agent_responses": all_agent_responses
                },
                performance_metrics={
                    "total_sections_processed": len(refined_sections),
                    "total_content_length": total_refined_length,
                    "successful_sections": len([s for s in refined_sections if "error_response_id" not in s]),
                    "agent_responses_collected": len(all_agent_responses),
                    "recursion_depth_check": True,
                    "safe_execution": True,
                    "batch_processing": True
                }
            )
        )

    # ê¸°ì¡´ ë™ê¸° ë©”ì„œë“œë“¤ ìœ ì§€ (í˜¸í™˜ì„± ë³´ì¥)
    def _extract_clean_title_subtitle(self, analysis_result: str, index: int) -> tuple:
        """ë¶„ì„ ê²°ê³¼ì—ì„œ ê¹¨ë—í•œ ì œëª©ê³¼ ë¶€ì œëª© ì¶”ì¶œ"""
        title_pattern = r'ì œëª©[:\s]*([^\n]+)'
        subtitle_pattern = r'ë¶€ì œëª©[:\s]*([^\n]+)'

        title_match = re.search(title_pattern, analysis_result)
        subtitle_match = re.search(subtitle_pattern, analysis_result)

        title = title_match.group(1).strip() if title_match else f"ë„ì¿„ ì—¬í–‰ ì´ì•¼ê¸° {index + 1}"
        subtitle = subtitle_match.group(1).strip() if subtitle_match else "íŠ¹ë³„í•œ ìˆœê°„ë“¤"

        # ì„¤ëª… í…ìŠ¤íŠ¸ ì œê±°
        title = self._clean_title_from_descriptions(title)
        subtitle = self._clean_title_from_descriptions(subtitle)

        # ì œëª© ê¸¸ì´ ì¡°ì •
        if len(title) > 40:
            title = title[:37] + "..."
        if len(subtitle) > 30:
            subtitle = subtitle[:27] + "..."

        return title, subtitle

    def _clean_title_from_descriptions(self, text: str) -> str:
        """ì œëª©ì—ì„œ ì„¤ëª… í…ìŠ¤íŠ¸ ì œê±°"""
        patterns_to_remove = [
            r'\(í—¤ë“œë¼ì¸\)', r'\(ì„¹ì…˜ íƒ€ì´í‹€\)', r'ë° ë¶€.*?ë°°ì¹˜.*?ìˆìŒ',
            r'í•„ì ì •ë³´.*?ìˆìŒ', r'í¬í†  í¬ë ˆë”§.*?ìˆìŒ', r'ê³„ì¸µì .*?ìˆìŒ',
            r'ê³¼ ë³¸ë¬¸.*?ê´€ê³„', r'ë°°ì¹˜.*?ê´€ê³„', r'ìƒë‹¨.*?ë°°ì¹˜',
            r'ì¢Œìƒë‹¨.*?ë°°ì¹˜', r'í˜¹ì€.*?ë°°ì¹˜', r'ì—†ì´.*?ì§‘ì¤‘',
            r'ê·¸ ì•„ë˜ë¡œ.*?ìˆìŠµë‹ˆë‹¤'
        ]

        clean_text = text
        for pattern in patterns_to_remove:
            clean_text = re.sub(pattern, '', clean_text, flags=re.IGNORECASE | re.DOTALL)

        # ì—°ì†ëœ ê³µë°±ê³¼ íŠ¹ìˆ˜ë¬¸ì ì •ë¦¬
        clean_text = re.sub(r'\s+', ' ', clean_text)
        clean_text = re.sub(r'^[,\s:]+|[,\s:]+$', '', clean_text)

        return clean_text.strip() if clean_text.strip() else "ë„ì¿„ ì—¬í–‰ ì´ì•¼ê¸°"

    def _remove_meta_descriptions(self, content: str) -> str:
        """ì½˜í…ì¸ ì—ì„œ ë©”íƒ€ ì„¤ëª… ì œê±°"""
        patterns_to_remove = [
            r'\*ì´ í˜ì´ì§€ì—ëŠ”.*?ì‚´ë ¸ìŠµë‹ˆë‹¤\.\*',
            r'ë¸”ë¡ì€ ê· í˜•.*?ì¤„ì—¬ì¤ë‹ˆë‹¤',
            r'\(ì‚¬ì§„ ìº¡ì…˜\)',
            r'ì‹œê°ì  ë¦¬ë“¬ê³¼.*?ì‚´ë ¸ìŠµë‹ˆë‹¤',
            r'ì¶©ë¶„í•œ ì—¬ë°±.*?ì™„ì„±í•©ë‹ˆë‹¤',
            r'ì‚¬ì§„ì€ ë³¸ë¬¸.*?ì™„ì„±í•©ë‹ˆë‹¤',
            r'ì´ ì½˜í…ì¸ ëŠ”.*?ë””ìì¸ë˜ì—ˆìŠµë‹ˆë‹¤'
        ]

        clean_content = content
        for pattern in patterns_to_remove:
            clean_content = re.sub(pattern, '', clean_content, flags=re.IGNORECASE | re.DOTALL)

        return clean_content.strip()

    def _format_layout_data(self, similar_layouts: List[Dict]) -> str:
        """ë ˆì´ì•„ì›ƒ ë°ì´í„°ë¥¼ í…ìŠ¤íŠ¸ë¡œ í¬ë§·íŒ…"""
        if not similar_layouts:
            return "ìœ ì‚¬í•œ ë ˆì´ì•„ì›ƒ ë°ì´í„° ì—†ìŒ"

        formatted_data = []
        for i, layout in enumerate(similar_layouts):
            formatted_data.append(f"""
ë ˆì´ì•„ì›ƒ {i+1} (ìœ ì‚¬ë„: {layout.get('score', 0):.2f}):
- ì¶œì²˜: {layout.get('pdf_name', 'unknown')} (í˜ì´ì§€ {layout.get('page_number', 0)})
- í…ìŠ¤íŠ¸ ìƒ˜í”Œ: {layout.get('text_content', '')[:200]}...
- ì´ë¯¸ì§€ ìˆ˜: {len(layout.get('image_info', []))}ê°œ
- ë ˆì´ì•„ì›ƒ íŠ¹ì§•: {self._summarize_layout_info(layout.get('layout_info', {}))}
""")

        return "\n".join(formatted_data)

    def _summarize_layout_info(self, layout_info: Dict) -> str:
        """ë ˆì´ì•„ì›ƒ ì •ë³´ ìš”ì•½"""
        text_blocks = layout_info.get('text_blocks', [])
        images = layout_info.get('images', [])
        tables = layout_info.get('tables', [])

        summary = []
        if text_blocks:
            summary.append(f"í…ìŠ¤íŠ¸ ë¸”ë¡ {len(text_blocks)}ê°œ")
        if images:
            summary.append(f"ì´ë¯¸ì§€ {len(images)}ê°œ")
        if tables:
            summary.append(f"í…Œì´ë¸” {len(tables)}ê°œ")

        return ", ".join(summary) if summary else "ê¸°ë³¸ ë ˆì´ì•„ì›ƒ"

    def _extract_all_text(self, magazine_content) -> str:
        """ëª¨ë“  í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        if isinstance(magazine_content, dict):
            all_text = ""
            # ìš°ì„ ìˆœìœ„ì— ë”°ë¥¸ í…ìŠ¤íŠ¸ ì¶”ì¶œ
            priority_fields = [
                "integrated_content", "essay_content", "interview_content",
                "sections", "content", "body", "text"
            ]

            for field in priority_fields:
                if field in magazine_content:
                    value = magazine_content[field]
                    if isinstance(value, str) and value.strip():
                        all_text += value + "\n\n"
                    elif isinstance(value, dict):
                        for sub_key, sub_value in value.items():
                            if isinstance(sub_value, str) and sub_value.strip():
                                all_text += sub_value + "\n\n"
                    elif isinstance(value, list):
                        for item in value:
                            if isinstance(item, dict):
                                for sub_key, sub_value in item.items():
                                    if isinstance(sub_value, str) and sub_value.strip():
                                        all_text += sub_value + "\n\n"
                            elif isinstance(item, str) and item.strip():
                                all_text += item + "\n\n"

            return all_text.strip()
        else:
            return str(magazine_content)

    def _analyze_content_structure(self, content: str) -> List[str]:
        """ì½˜í…ì¸  êµ¬ì¡° ë¶„ì„ ë° ì§€ëŠ¥ì  ë¶„í• """
        if not content:
            return []

        sections = []

        # 1. í—¤ë” ê¸°ë°˜ ë¶„í• 
        header_sections = self._split_by_headers(content)
        if len(header_sections) >= 3:
            sections.extend(header_sections)

        # 2. ë¬¸ë‹¨ ê¸°ë°˜ ë¶„í• 
        if len(sections) < 5:
            paragraph_sections = self._split_by_paragraphs(content)
            sections.extend(paragraph_sections)

        # 3. ì˜ë¯¸ ê¸°ë°˜ ë¶„í• 
        if len(sections) < 6:
            semantic_sections = self._split_by_semantics(content)
            sections.extend(semantic_sections)

        # ì¤‘ë³µ ì œê±° ë° ê¸¸ì´ í•„í„°ë§
        unique_sections = []
        seen_content = set()
        for section in sections:
            section_clean = re.sub(r'\s+', ' ', section.strip())
            if len(section_clean) >= 100 and section_clean not in seen_content:
                unique_sections.append(section)
                seen_content.add(section_clean)

        return unique_sections[:8]  # ìµœëŒ€ 8ê°œ ì„¹ì…˜

    def _split_by_headers(self, content: str) -> List[str]:
        """í—¤ë” ê¸°ë°˜ ë¶„í• """
        sections = []
        header_pattern = r'^(#{1,3})\s+(.+?)$'
        current_section = ""
        lines = content.split('\n')

        for line in lines:
            if re.match(header_pattern, line.strip()):
                if current_section.strip():
                    sections.append(current_section.strip())
                current_section = line + "\n"
            else:
                current_section += line + "\n"

        if current_section.strip():
            sections.append(current_section.strip())

        return [s for s in sections if len(s) >= 100]

    def _split_by_paragraphs(self, content: str) -> List[str]:
        """ë¬¸ë‹¨ ê¸°ë°˜ ë¶„í• """
        paragraphs = content.split('\n\n')
        sections = []
        current_section = ""

        for paragraph in paragraphs:
            paragraph = paragraph.strip()
            if not paragraph:
                continue

            if len(current_section + paragraph) > 800:
                if current_section:
                    sections.append(current_section.strip())
                current_section = paragraph + "\n\n"
            else:
                current_section += paragraph + "\n\n"

        if current_section.strip():
            sections.append(current_section.strip())

        return [s for s in sections if len(s) >= 100]

    def _split_by_semantics(self, content: str) -> List[str]:
        """ì˜ë¯¸ ê¸°ë°˜ ë¶„í• """
        sentences = re.split(r'[.!?]\s+', content)
        sections = []
        current_section = ""

        for sentence in sentences:
            sentence = sentence.strip()
            if not sentence:
                continue

            if len(current_section + sentence) > 600:
                if current_section:
                    sections.append(current_section.strip())
                current_section = sentence + ". "
            else:
                current_section += sentence + ". "

        if current_section.strip():
            sections.append(current_section.strip())

        return [s for s in sections if len(s) >= 100]

    def _map_to_templates(self, refined_sections: List[Dict], available_templates: List[str]) -> Dict:
        """ì„¹ì…˜ì„ í…œí”Œë¦¿ì— ë§¤í•‘"""
        text_mapping = []

        for i, section in enumerate(refined_sections):
            template_index = i % len(available_templates) if available_templates else 0
            template_name = available_templates[template_index] if available_templates else f"Section{i+1:02d}.jsx"

            text_mapping.append({
                "template": template_name,
                "title": section["title"],
                "subtitle": section["subtitle"],
                "body": section["content"],
                "tagline": "TRAVEL & CULTURE",
                "layout_source": section.get("layout_info", {}).get("pdf_name", "default"),
                "agent_responses": section.get("agent_responses", {})
            })

        return {"text_mapping": text_mapping}

    # ë™ê¸° ë²„ì „ ë©”ì„œë“œ (í˜¸í™˜ì„± ë³´ì¥)
    def process_content_sync(self, magazine_content, available_templates: List[str]) -> Dict:
        """ë™ê¸° ë²„ì „ ì½˜í…ì¸  ì²˜ë¦¬ (í˜¸í™˜ì„± ìœ ì§€)"""
        return asyncio.run(self.process_content(magazine_content, available_templates))
