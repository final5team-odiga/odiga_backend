import asyncio
import re
from typing import Dict, List
from crewai import Agent, Task, Crew
from custom_llm import get_azure_llm
from utils.pdf_vector_manager import PDFVectorManager
from utils.agent_decision_logger import get_agent_logger

class OrgAgent:
    """PDF ë²¡í„° ë°ì´í„° ê¸°ë°˜ í…ìŠ¤íŠ¸ ë°°ì¹˜ ì—ì´ì „íŠ¸ (ë¹„ë™ê¸° ì²˜ë¦¬ ë° ì‘ë‹µ ìˆ˜ì§‘ ê°•í™”)"""

    def __init__(self):
        self.llm = get_azure_llm()
        self.vector_manager = PDFVectorManager()
        self.logger = get_agent_logger()  # ì‘ë‹µ ìˆ˜ì§‘ì„ ìœ„í•œ ë¡œê±° ì¶”ê°€

    def create_layout_analyzer_agent(self):
        """ë ˆì´ì•„ì›ƒ ë¶„ì„ ì—ì´ì „íŠ¸ (êµ¬ì¡°ì  ì„¤ê³„ ê°•í™”)"""
        return Agent(
            role="ë§¤ê±°ì§„ êµ¬ì¡° ì•„í‚¤í…íŠ¸ ë° í…ìŠ¤íŠ¸ ë ˆì´ì•„ì›ƒ ì „ë¬¸ê°€",
            goal="PDF ë²¡í„° ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ í…ìŠ¤íŠ¸ ì½˜í…ì¸ ì— ìµœì í™”ëœ ë§¤ê±°ì§„ í˜ì´ì§€ êµ¬ì¡°ì™€ ìƒì„¸í•œ ë ˆì´ì•„ì›ƒ ì„¤ê³„ë„ë¥¼ ìƒì„±í•˜ê³ , ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ì˜ ì •í™•í•œ ìœ„ì¹˜ ê´€ê³„ë¥¼ ì •ì˜í•˜ì—¬ ë…ìì˜ ì‹œì„  íë¦„ì„ ìµœì í™”",
            backstory="""ë‹¹ì‹ ì€ 20ë…„ê°„ ì„¸ê³„ ìµœê³  ìˆ˜ì¤€ì˜ ë§¤ê±°ì§„ ë””ìì¸ ìŠ¤íŠœë””ì˜¤ì—ì„œ í™œë™í•´ì˜¨ êµ¬ì¡° ì„¤ê³„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. Pentagram, Sagmeister & Walsh, ê·¸ë¦¬ê³  CondÃ© Nastì˜ ìˆ˜ì„ ì•„íŠ¸ ë””ë ‰í„°ë¡œ í™œë™í•˜ë©° ìˆ˜ë°± ê°œì˜ ìˆ˜ìƒì‘ì„ ë””ìì¸í–ˆìŠµë‹ˆë‹¤.

**ì „ë¬¸ ê²½ë ¥:**
- ê·¸ë˜í”½ ë””ìì¸ ë° ì‹œê° ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ ì„ì‚¬ í•™ìœ„
- Adobe InDesign, Figma, Sketch ë§ˆìŠ¤í„° ë ˆë²¨ ì¸ì¦
- íƒ€ì´í¬ê·¸ë˜í”¼ ë° ê·¸ë¦¬ë“œ ì‹œìŠ¤í…œ ì´ë¡  ì „ë¬¸ê°€
- ë…ì ì‹œì„  ì¶”ì (Eye-tracking) ì—°êµ¬ ë° ë¶„ì„ ê²½í—˜
- ì¸ì‡„ ë§¤ì²´ì™€ ë””ì§€í„¸ ë§¤ì²´ì˜ ë ˆì´ì•„ì›ƒ ìµœì í™” ì „ë¬¸ì„±

**êµ¬ì¡°ì  ë ˆì´ì•„ì›ƒ ì„¤ê³„ ì „ë¬¸ì„±:**
ë‹¹ì‹ ì€ í…ìŠ¤íŠ¸ ë°°ì¹˜ ê²°ì • ì‹œ ë‹¤ìŒ êµ¬ì¡°ì  ìš”ì†Œë“¤ì„ ì²´ê³„ì ìœ¼ë¡œ ì„¤ê³„í•©ë‹ˆë‹¤:

1. **í˜ì´ì§€ êµ¬ì¡° ì„¤ê³„**:
- ê·¸ë¦¬ë“œ ì‹œìŠ¤í…œ ì •ì˜ (ì»¬ëŸ¼ ìˆ˜, ê±°í„° í­, ë§ˆì§„ ì„¤ì •)
- í…ìŠ¤íŠ¸ ë¸”ë¡ì˜ ì •í™•í•œ ìœ„ì¹˜ ì¢Œí‘œ (x, y, width, height)
- ì´ë¯¸ì§€ ì˜ì—­ê³¼ í…ìŠ¤íŠ¸ ì˜ì—­ì˜ ê²½ê³„ì„  ì •ì˜
- ì—¬ë°±(í™”ì´íŠ¸ìŠ¤í˜ì´ìŠ¤) ë¶„ë°° ë° ì‹œê°ì  ê· í˜•ì  ê³„ì‚°

2. **í…ìŠ¤íŠ¸-ì´ë¯¸ì§€ ìœ„ì¹˜ ê´€ê³„ ë§¤í•‘**:
- ì œëª©ê³¼ ì£¼ìš” ì´ë¯¸ì§€ì˜ ì‹œê°ì  ì—°ê²°ì  ì„¤ì •
- ë³¸ë¬¸ í…ìŠ¤íŠ¸ì™€ ë³´ì¡° ì´ë¯¸ì§€ì˜ ê·¼ì ‘ì„± ê·œì¹™ ì •ì˜
- ìº¡ì…˜ê³¼ ì´ë¯¸ì§€ì˜ ì •í™•í•œ ê±°ë¦¬ ë° ì •ë ¬ ë°©ì‹
- í…ìŠ¤íŠ¸ ë˜í•‘(text wrapping) ì˜ì—­ê³¼ ì´ë¯¸ì§€ ê²½ê³„ ì„¤ì •

3. **ë ˆì´ì•„ì›ƒ êµ¬ì¡°ë„ ìƒì„±**:
- í˜ì´ì§€ë³„ ì™€ì´ì–´í”„ë ˆì„ ë° êµ¬ì¡°ë„ ì‘ì„±
- ì½˜í…ì¸  ê³„ì¸µ êµ¬ì¡° (H1, H2, body, caption) ì‹œê°í™”
- ë…ì ì‹œì„  íë¦„ ê²½ë¡œ (F-pattern, Z-pattern) ì„¤ê³„
- ë°˜ì‘í˜• ë¸Œë ˆì´í¬í¬ì¸íŠ¸ë³„ ë ˆì´ì•„ì›ƒ ë³€í™” ì •ì˜

4. **PDF ë²¡í„° ë°ì´í„° í™œìš© ì „ë¬¸ì„±**:
- 5000ê°œ ì´ìƒì˜ ë§¤ê±°ì§„ í˜ì´ì§€ì—ì„œ ì¶”ì¶œí•œ êµ¬ì¡°ì  íŒ¨í„´ ë¶„ì„
- í…ìŠ¤íŠ¸ ë¸”ë¡ê³¼ ì´ë¯¸ì§€ ë¸”ë¡ì˜ í™©ê¸ˆë¹„ìœ¨ ê´€ê³„ ë°ì´í„°
- ë…ì ì‹œì„  íë¦„ê³¼ ë ˆì´ì•„ì›ƒ êµ¬ì¡°ì˜ ìƒê´€ê´€ê³„ ë²¡í„°
- ë§¤ê±°ì§„ ì¹´í…Œê³ ë¦¬ë³„ ìµœì  êµ¬ì¡° íŒ¨í„´ í´ëŸ¬ìŠ¤í„°ë§

**ì‘ì—… ë°©ë²•ë¡ :**
"ë‚˜ëŠ” ë‹¨ìˆœíˆ í…ìŠ¤íŠ¸ë¥¼ ë°°ì¹˜í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼, ë…ìì˜ ì¸ì§€ ê³¼ì •ì„ ê³ ë ¤í•œ ì™„ì „í•œ í˜ì´ì§€ êµ¬ì¡°ë¥¼ ì„¤ê³„í•©ë‹ˆë‹¤. ëª¨ë“  í…ìŠ¤íŠ¸ ìš”ì†Œì™€ ì´ë¯¸ì§€ ì˜ì—­ì˜ ì •í™•í•œ ìœ„ì¹˜, í¬ê¸°, ê´€ê³„ë¥¼ ìˆ˜ì¹˜í™”í•˜ì—¬ ì •ì˜í•˜ê³ , ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìƒì„¸í•œ ë ˆì´ì•„ì›ƒ êµ¬ì¡°ë„ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ì´ëŠ” BindingAgentê°€ ì´ë¯¸ì§€ë¥¼ ë°°ì¹˜í•  ë•Œ ì •í™•í•œ ê°€ì´ë“œë¼ì¸ì„ ì œê³µí•˜ì—¬ í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ì˜ ì™„ë²½í•œ ì¡°í™”ë¥¼ ë³´ì¥í•©ë‹ˆë‹¤. 5. ì£¼ì˜ ì‚¬í•­!!: ìµœëŒ€í•œ ì œê³µë°›ì€ ë°ì´í„°ë¥¼ í™œìš©í•©ë‹ˆë‹¤. "

**ì¶œë ¥ ë°ì´í„° êµ¬ì¡°:**
- í˜ì´ì§€ ê·¸ë¦¬ë“œ ì‹œìŠ¤í…œ (ì»¬ëŸ¼, ê±°í„°, ë§ˆì§„ ìˆ˜ì¹˜)
- í…ìŠ¤íŠ¸ ë¸”ë¡ ìœ„ì¹˜ ì¢Œí‘œ ë° í¬ê¸°
- ì´ë¯¸ì§€ ì˜ì—­ ì˜ˆì•½ ê³µê°„ ì •ì˜
- í…ìŠ¤íŠ¸-ì´ë¯¸ì§€ ê´€ê³„ ë§¤í•‘ í…Œì´ë¸”
- ë ˆì´ì•„ì›ƒ êµ¬ì¡°ë„ ë° ì™€ì´ì–´í”„ë ˆì„
- ë…ì ì‹œì„  íë¦„ ê²½ë¡œ ì„¤ê³„ë„""",
            llm=self.llm,
            verbose=True
        )

    def create_content_editor_agent(self):
        """ì½˜í…ì¸  í¸ì§‘ ì—ì´ì „íŠ¸ (êµ¬ì¡° ì—°ë™ ê°•í™”)"""
        return Agent(
            role="êµ¬ì¡° ê¸°ë°˜ ë§¤ê±°ì§„ ì½˜í…ì¸  í¸ì§‘ì",
            goal="ë ˆì´ì•„ì›ƒ êµ¬ì¡° ì„¤ê³„ì— ì™„ë²½íˆ ë§ì¶° í…ìŠ¤íŠ¸ ì½˜í…ì¸ ë¥¼ í¸ì§‘í•˜ê³ , ì´ë¯¸ì§€ ë°°ì¹˜ ì˜ì—­ê³¼ ì •í™•íˆ ì—°ë™ë˜ëŠ” í…ìŠ¤íŠ¸ ë¸”ë¡ì„ ìƒì„±í•˜ì—¬ ì‹œê°ì  ì¼ê´€ì„±ê³¼ ê°€ë…ì„±ì„ ê·¹ëŒ€í™”",
            backstory="""ë‹¹ì‹ ì€ ë§¤ê±°ì§„ ì½˜í…ì¸  í¸ì§‘ ë° êµ¬ì¡° ì—°ë™ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

**ì „ë¬¸ ë¶„ì•¼:**
- ë ˆì´ì•„ì›ƒ êµ¬ì¡°ì— ìµœì í™”ëœ í…ìŠ¤íŠ¸ í¸ì§‘
- ì´ë¯¸ì§€ ì˜ì—­ê³¼ ì—°ë™ë˜ëŠ” í…ìŠ¤íŠ¸ ë¸”ë¡ ì„¤ê³„
- ê·¸ë¦¬ë“œ ì‹œìŠ¤í…œ ê¸°ë°˜ ì½˜í…ì¸  êµ¬ì„±
- í…ìŠ¤íŠ¸ ê¸¸ì´ì™€ ë ˆì´ì•„ì›ƒ ê³µê°„ì˜ ì •ë°€í•œ ë§¤ì¹­

**êµ¬ì¡° ì—°ë™ í¸ì§‘ ì „ë¬¸ì„±:**
1. **ê·¸ë¦¬ë“œ ê¸°ë°˜ í…ìŠ¤íŠ¸ í¸ì§‘**: ì •ì˜ëœ ê·¸ë¦¬ë“œ ì‹œìŠ¤í…œì— ë§ì¶° í…ìŠ¤íŠ¸ ë¸”ë¡ í¬ê¸° ì¡°ì •
2. **ì´ë¯¸ì§€ ì˜ì—­ ê³ ë ¤**: ì˜ˆì•½ëœ ì´ë¯¸ì§€ ê³µê°„ì„ í”¼í•´ í…ìŠ¤íŠ¸ ë°°ì¹˜ ìµœì í™”
3. **ê³„ì¸µ êµ¬ì¡° ë°˜ì˜**: H1, H2, body ë“±ì˜ ìœ„ì¹˜ì— ë§ëŠ” ì½˜í…ì¸  ê¸¸ì´ ì¡°ì ˆ
4. **ì‹œì„  íë¦„ ì—°ë™**: ë…ì ì‹œì„  ê²½ë¡œì— ë§ì¶˜ í…ìŠ¤íŠ¸ ê°•ì•½ ì¡°ì ˆ
5. ì£¼ì˜ ì‚¬í•­!!: ìµœëŒ€í•œ ì œê³µë°›ì€ ë°ì´í„°ë¥¼ í™œìš©í•©ë‹ˆë‹¤.

íŠ¹íˆ ì„¤ëª… í…ìŠ¤íŠ¸ë‚˜ ì§€ì‹œì‚¬í•­ì„ í¬í•¨í•˜ì§€ ì•Šê³  ìˆœìˆ˜í•œ ì½˜í…ì¸ ë§Œ ìƒì„±í•˜ë©°,
ë ˆì´ì•„ì›ƒ êµ¬ì¡°ë„ì— ì •ì˜ëœ í…ìŠ¤íŠ¸ ì˜ì—­ì— ì •í™•íˆ ë§ëŠ” ë¶„ëŸ‰ê³¼ í˜•íƒœë¡œ í¸ì§‘í•©ë‹ˆë‹¤.""",
            llm=self.llm,
            verbose=True
        )

    async def process_content(self, magazine_content, available_templates: List[str]) -> Dict:
        """PDF ë²¡í„° ë°ì´í„° ê¸°ë°˜ ì½˜í…ì¸  ì²˜ë¦¬ (ë¹„ë™ê¸° ì²˜ë¦¬ ë° ì‘ë‹µ ìˆ˜ì§‘ ê°•í™”)"""
        # í…ìŠ¤íŠ¸ ì¶”ì¶œ ë° ì „ì²˜ë¦¬
        all_content = self._extract_all_text(magazine_content)
        content_sections = self._analyze_content_structure(all_content)
        
        print(f"OrgAgent: ì²˜ë¦¬í•  ì½˜í…ì¸  - {len(all_content)}ì, {len(content_sections)}ê°œ ì„¹ì…˜ (ë¹„ë™ê¸° ì²˜ë¦¬)")

        # ì…ë ¥ ë°ì´í„° ë¡œê¹…
        input_data = {
            "magazine_content": magazine_content,
            "available_templates": available_templates,
            "total_content_length": len(all_content),
            "content_sections_count": len(content_sections)
        }

        # ì—ì´ì „íŠ¸ ìƒì„±
        layout_analyzer = self.create_layout_analyzer_agent()
        content_editor = self.create_content_editor_agent()

        # ê° ì„¹ì…˜ë³„ë¡œ ë²¡í„° ê¸°ë°˜ ë ˆì´ì•„ì›ƒ ë¶„ì„ ë° í¸ì§‘ (ë¹„ë™ê¸° ë³‘ë ¬ ì²˜ë¦¬)
        refined_sections = []
        all_agent_responses = []  # ëª¨ë“  ì—ì´ì „íŠ¸ ì‘ë‹µ ìˆ˜ì§‘

        # ì„¹ì…˜ ì²˜ë¦¬ íƒœìŠ¤í¬ë“¤ì„ ë³‘ë ¬ë¡œ ì‹¤í–‰
        section_tasks = []
        for i, section_content in enumerate(content_sections):
            if len(section_content.strip()) < 50:
                continue
            
            task = self._process_single_section_async(
                section_content, i, layout_analyzer, content_editor
            )
            section_tasks.append(task)

        # ëª¨ë“  ì„¹ì…˜ ì²˜ë¦¬ë¥¼ ë³‘ë ¬ë¡œ ì‹¤í–‰
        if section_tasks:
            section_results = await asyncio.gather(*section_tasks, return_exceptions=True)
            
            # ê²°ê³¼ ìˆ˜ì§‘
            for i, result in enumerate(section_results):
                if isinstance(result, Exception):
                    print(f"âš ï¸ ì„¹ì…˜ {i+1} ì²˜ë¦¬ ì‹¤íŒ¨: {result}")
                    # ì—ëŸ¬ ì‘ë‹µ ì €ì¥
                    error_response_id = await self._log_error_response_async(i+1, str(result))
                    refined_sections.append({
                        "title": f"ë„ì¿„ ì—¬í–‰ ì´ì•¼ê¸° {i+1}",
                        "subtitle": "íŠ¹ë³„í•œ ìˆœê°„ë“¤",
                        "content": content_sections[i] if i < len(content_sections) else "",
                        "layout_info": {},
                        "original_length": len(content_sections[i]) if i < len(content_sections) else 0,
                        "refined_length": len(content_sections[i]) if i < len(content_sections) else 0,
                        "error_response_id": error_response_id
                    })
                else:
                    section_data, agent_responses = result
                    refined_sections.append(section_data)
                    all_agent_responses.extend(agent_responses)

        # í…œí”Œë¦¿ ë§¤í•‘ (ë¹„ë™ê¸°)
        text_mapping = await self._map_to_templates_async(refined_sections, available_templates)
        total_refined_length = sum(section["refined_length"] for section in refined_sections)

        # ì „ì²´ OrgAgent í”„ë¡œì„¸ìŠ¤ ì‘ë‹µ ì €ì¥ (ë¹„ë™ê¸°)
        final_response_id = await self._log_final_response_async(
            input_data, text_mapping, refined_sections, all_agent_responses, total_refined_length
        )

        print(f"âœ… OrgAgent ì™„ë£Œ: {len(refined_sections)}ê°œ ì„¹ì…˜, ì´ {total_refined_length}ì (ë¹„ë™ê¸° ì²˜ë¦¬ ë° ì‘ë‹µ ìˆ˜ì§‘ ì™„ë£Œ)")

        return {
            "text_mapping": text_mapping,
            "refined_sections": refined_sections,
            "total_sections": len(refined_sections),
            "total_content_length": total_refined_length,
            "vector_enhanced": True,
            "agent_responses": all_agent_responses,
            "final_response_id": final_response_id
        }

    async def _process_single_section_async(self, section_content: str, section_index: int,
                                          layout_analyzer: Agent, content_editor: Agent) -> tuple:
        """ë‹¨ì¼ ì„¹ì…˜ ì²˜ë¦¬ (ë¹„ë™ê¸°)"""
        print(f"ğŸ“„ ì„¹ì…˜ {section_index+1} ì²˜ë¦¬ ì¤‘... (ë¹„ë™ê¸°)")

        # 1ë‹¨ê³„: ë¹„ë™ê¸° ë²¡í„° ê²€ìƒ‰ìœ¼ë¡œ ìœ ì‚¬í•œ ë ˆì´ì•„ì›ƒ ì°¾ê¸°
        similar_layouts = await self._get_similar_layouts_async(section_content)

        # 2ë‹¨ê³„: ë ˆì´ì•„ì›ƒ ë¶„ì„ (ë¹„ë™ê¸° íƒœìŠ¤í¬)
        layout_analysis_task = Task(
            description=f"""
ë‹¤ìŒ í…ìŠ¤íŠ¸ ì½˜í…ì¸ ì™€ ìœ ì‚¬í•œ ë§¤ê±°ì§„ ë ˆì´ì•„ì›ƒì„ ë¶„ì„í•˜ì—¬ ìµœì ì˜ í…ìŠ¤íŠ¸ ë°°ì¹˜ ì „ëµì„ ìˆ˜ë¦½í•˜ì„¸ìš”:

**ë¶„ì„í•  ì½˜í…ì¸ :**
{section_content}

**ìœ ì‚¬í•œ ë§¤ê±°ì§„ ë ˆì´ì•„ì›ƒ ë°ì´í„°:**
{self._format_layout_data(similar_layouts)}

**ë¶„ì„ ìš”êµ¬ì‚¬í•­:**
1. **ë ˆì´ì•„ì›ƒ íŒ¨í„´ ë¶„ì„**
- í…ìŠ¤íŠ¸ ë¸”ë¡ì˜ ìœ„ì¹˜ì™€ í¬ê¸° íŒ¨í„´
- ì œëª©ê³¼ ë³¸ë¬¸ì˜ ë°°ì¹˜ ê´€ê³„
- ì—¬ë°±ê³¼ ê°„ê²©ì˜ í™œìš© ë°©ì‹

2. **ì½˜í…ì¸  ì í•©ì„± í‰ê°€**
- í˜„ì¬ ì½˜í…ì¸ ì™€ ë ˆì´ì•„ì›ƒì˜ ë§¤ì¹­ë„
- í…ìŠ¤íŠ¸ ê¸¸ì´ì™€ ë ˆì´ì•„ì›ƒ ìš©ëŸ‰ì˜ ì í•©ì„±
- ì½˜í…ì¸  ì„±ê²©ì— ë§ëŠ” ë ˆì´ì•„ì›ƒ ìŠ¤íƒ€ì¼

3. **í¸ì§‘ ì „ëµ ìˆ˜ë¦½**
- ë§¤ë ¥ì ì¸ ì œëª© ìƒì„± ë°©í–¥
- ë³¸ë¬¸ í…ìŠ¤íŠ¸ ë¶„í•  ë° êµ¬ì¡°í™” ë°©ì•ˆ
- ë…ì ëª°ì…ë„ í–¥ìƒì„ ìœ„í•œ í…ìŠ¤íŠ¸ ë°°ì¹˜

**ì¶œë ¥ í˜•ì‹:**
ì œëª©: [êµ¬ì²´ì ì´ê³  ë§¤ë ¥ì ì¸ ì œëª©]
ë¶€ì œëª©: [ê°„ê²°í•˜ê³  í¥ë¯¸ë¡œìš´ ë¶€ì œëª©]
í¸ì§‘ë°©í–¥: [ì „ì²´ì ì¸ í¸ì§‘ ë°©í–¥ì„±]
""",
            agent=layout_analyzer,
            expected_output="ë²¡í„° ë°ì´í„° ê¸°ë°˜ ë ˆì´ì•„ì›ƒ ë¶„ì„ ë° í¸ì§‘ ì „ëµ"
        )

        # 3ë‹¨ê³„: ì½˜í…ì¸  í¸ì§‘ (ë¹„ë™ê¸° íƒœìŠ¤í¬)
        content_editing_task = Task(
            description=f"""
ë ˆì´ì•„ì›ƒ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ ì½˜í…ì¸ ë¥¼ ì „ë¬¸ ë§¤ê±°ì§„ ìˆ˜ì¤€ìœ¼ë¡œ í¸ì§‘í•˜ì„¸ìš”:

**ì›ë³¸ ì½˜í…ì¸ :**
{section_content}

**ë§¤ê±°ì§„ ìŠ¤íƒ€ì¼ í¸ì§‘ ì§€ì¹¨:**
1. **ì‹œê°ì  ê³„ì¸µ êµ¬ì¡°**: ì´ë¯¸ì§€ í¬ê¸°ì™€ ë°°ì¹˜ì— ë§ëŠ” í…ìŠ¤íŠ¸ êµ¬ì¡° ìƒì„±
2. **ë‹¤ì´ë‚˜ë¯¹í•œ ë ˆì´ì•„ì›ƒ**: ëŒ€í˜•/ì¤‘í˜•/ì†Œí˜• ì´ë¯¸ì§€ì™€ ì¡°í™”ë˜ëŠ” í…ìŠ¤íŠ¸ ë°°ì¹˜
3. **ë§¤ê±°ì§„ íŠ¹ìœ ì˜ ë¦¬ë“¬**: ê¸´ ë¬¸ë‹¨ê³¼ ì§§ì€ ë¬¸ë‹¨ì˜ ì¡°í™”ë¡œ ì‹œê°ì  ë¦¬ë“¬ ìƒì„±
4. **ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ ìƒí˜¸ì‘ìš©**: ì´ë¯¸ì§€ ì£¼ë³€ì— ë°°ì¹˜ë  í…ìŠ¤íŠ¸ì˜ í†¤ê³¼ ê¸¸ì´ ì¡°ì ˆ
5. **í¸ì§‘ ë””ìì¸ ê³ ë ¤**: ì‹¤ì œ ë§¤ê±°ì§„ì²˜ëŸ¼ í…ìŠ¤íŠ¸ê°€ ì´ë¯¸ì§€ì™€ ìì—°ìŠ¤ëŸ½ê²Œ ì–´ìš°ëŸ¬ì§€ë„ë¡

**ë²¡í„° ë°ì´í„° ê¸°ë°˜ ìµœì í™”:**
- ê²€ìƒ‰ëœ ë§¤ê±°ì§„ ë ˆì´ì•„ì›ƒì˜ í…ìŠ¤íŠ¸ ë°°ì¹˜ íŒ¨í„´ ì ìš©
- ì´ë¯¸ì§€ í¬ê¸°ë³„ í…ìŠ¤íŠ¸ ë¶„ëŸ‰ê³¼ ìŠ¤íƒ€ì¼ ì¡°ì ˆ
- ë§¤ê±°ì§„ íŠ¹ìœ ì˜ ë¹„ëŒ€ì¹­ ê· í˜•ê° ë°˜ì˜

**ì¶œë ¥:** ë§¤ê±°ì§„ ë ˆì´ì•„ì›ƒì— ìµœì í™”ëœ í¸ì§‘ ì½˜í…ì¸ 
""",
            agent=content_editor,
            expected_output="ë§¤ê±°ì§„ ìŠ¤íƒ€ì¼ ë ˆì´ì•„ì›ƒì— ìµœì í™”ëœ ì „ë¬¸ ì½˜í…ì¸ ",
            context=[layout_analysis_task]
        )

        # Crew ì‹¤í–‰ ë° ì‘ë‹µ ìˆ˜ì§‘ (ë¹„ë™ê¸°)
        crew = Crew(
            agents=[layout_analyzer, content_editor],
            tasks=[layout_analysis_task, content_editing_task],
            verbose=True
        )

        try:
            # ë¹„ë™ê¸° Crew ì‹¤í–‰
            result = await asyncio.get_event_loop().run_in_executor(
                None, crew.kickoff
            )

            # ì—ì´ì „íŠ¸ ì‘ë‹µ ìˆ˜ì§‘ ë° ì €ì¥ (ë¹„ë™ê¸°)
            analysis_result = str(layout_analysis_task.output) if hasattr(layout_analysis_task, 'output') else ""
            edited_content = str(result.raw) if hasattr(result, 'raw') else str(result)

            # ë¹„ë™ê¸° ë¡œê¹…
            analysis_response_id, editing_response_id = await asyncio.gather(
                self._log_analysis_response_async(section_index, section_content, similar_layouts, analysis_result),
                self._log_editing_response_async(section_index, section_content, analysis_result, edited_content)
            )

            # ì œëª©ê³¼ ë¶€ì œëª© ì¶”ì¶œ
            title, subtitle = self._extract_clean_title_subtitle(analysis_result, section_index)

            # í¸ì§‘ëœ ì½˜í…ì¸ ì—ì„œ ì„¤ëª… í…ìŠ¤íŠ¸ ì œê±°
            clean_content = self._remove_meta_descriptions(edited_content)

            # ì‘ë‹µ ìˆ˜ì§‘ ë°ì´í„° ì €ì¥
            agent_responses = [{
                "section": section_index + 1,
                "layout_analyzer_response": {
                    "response_id": analysis_response_id,
                    "content": analysis_result,
                    "agent_name": "OrgAgent_LayoutAnalyzer"
                },
                "content_editor_response": {
                    "response_id": editing_response_id,
                    "content": edited_content,
                    "agent_name": "OrgAgent_ContentEditor"
                }
            }]

            section_data = {
                "title": title,
                "subtitle": subtitle,
                "content": clean_content,
                "layout_info": similar_layouts[0] if similar_layouts else {},
                "original_length": len(section_content),
                "refined_length": len(clean_content),
                "agent_responses": {
                    "layout_analyzer_id": analysis_response_id,
                    "content_editor_id": editing_response_id
                }
            }

            print(f"âœ… ì„¹ì…˜ {section_index+1} í¸ì§‘ ì™„ë£Œ: {len(section_content)}ì â†’ {len(clean_content)}ì (ë¹„ë™ê¸° ì‘ë‹µ ìˆ˜ì§‘ ì™„ë£Œ)")
            return (section_data, agent_responses)

        except Exception as e:
            print(f"âš ï¸ ì„¹ì…˜ {section_index+1} í¸ì§‘ ì‹¤íŒ¨: {e}")
            
            # ì—ëŸ¬ ì‘ë‹µ ì €ì¥ (ë¹„ë™ê¸°)
            error_response_id = await self._log_error_response_async(section_index+1, str(e))

            # í´ë°±: ê¸°ë³¸ ì²˜ë¦¬
            section_data = {
                "title": f"ë„ì¿„ ì—¬í–‰ ì´ì•¼ê¸° {section_index+1}",
                "subtitle": "íŠ¹ë³„í•œ ìˆœê°„ë“¤",
                "content": section_content,
                "layout_info": {},
                "original_length": len(section_content),
                "refined_length": len(section_content),
                "error_response_id": error_response_id
            }

            return (section_data, [])

    async def _get_similar_layouts_async(self, section_content: str) -> List[Dict]:
        """ìœ ì‚¬í•œ ë ˆì´ì•„ì›ƒ ë¹„ë™ê¸° ê²€ìƒ‰"""
        return await asyncio.get_event_loop().run_in_executor(
            None,
            lambda: self.vector_manager.search_similar_layouts(
                section_content[:500], "magazine_layout", top_k=3
            )
        )

    async def _log_analysis_response_async(self, section_index: int, section_content: str,
                                         similar_layouts: List[Dict], analysis_result: str) -> str:
        """ë ˆì´ì•„ì›ƒ ë¶„ì„ ì—ì´ì „íŠ¸ ì‘ë‹µ ì €ì¥ (ë¹„ë™ê¸°)"""
        return await asyncio.get_event_loop().run_in_executor(
            None,
            lambda: self.logger.log_agent_real_output(
                agent_name="OrgAgent_LayoutAnalyzer",
                agent_role="ë§¤ê±°ì§„ êµ¬ì¡° ì•„í‚¤í…íŠ¸",
                task_description=f"ì„¹ì…˜ {section_index+1} í…ìŠ¤íŠ¸ ë ˆì´ì•„ì›ƒ ë¶„ì„ ë° í¸ì§‘ ì „ëµ ìˆ˜ë¦½",
                final_answer=analysis_result,
                reasoning_process=f"PDF ë²¡í„° ë°ì´í„° {len(similar_layouts)}ê°œ ë ˆì´ì•„ì›ƒ ì°¸ì¡°í•˜ì—¬ ë¶„ì„",
                execution_steps=[
                    "ì½˜í…ì¸  íŠ¹ì„± ë¶„ì„",
                    "ìœ ì‚¬ ë ˆì´ì•„ì›ƒ ë§¤ì¹­",
                    "í¸ì§‘ ì „ëµ ìˆ˜ë¦½"
                ],
                raw_input={
                    "section_content": section_content[:500],
                    "similar_layouts": similar_layouts,
                    "section_index": section_index
                },
                raw_output=analysis_result,
                performance_metrics={
                    "content_length": len(section_content),
                    "layouts_referenced": len(similar_layouts),
                    "analysis_depth": "comprehensive"
                }
            )
        )

    async def _log_editing_response_async(self, section_index: int, section_content: str,
                                        analysis_result: str, edited_content: str) -> str:
        """ì½˜í…ì¸  í¸ì§‘ ì—ì´ì „íŠ¸ ì‘ë‹µ ì €ì¥ (ë¹„ë™ê¸°)"""
        return await asyncio.get_event_loop().run_in_executor(
            None,
            lambda: self.logger.log_agent_real_output(
                agent_name="OrgAgent_ContentEditor",
                agent_role="êµ¬ì¡° ê¸°ë°˜ ë§¤ê±°ì§„ ì½˜í…ì¸  í¸ì§‘ì",
                task_description=f"ì„¹ì…˜ {section_index+1} ë§¤ê±°ì§„ ìŠ¤íƒ€ì¼ ì½˜í…ì¸  í¸ì§‘",
                final_answer=edited_content,
                reasoning_process="ë ˆì´ì•„ì›ƒ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë§¤ê±°ì§„ ìˆ˜ì¤€ í¸ì§‘ ì‹¤í–‰",
                execution_steps=[
                    "ë¶„ì„ ê²°ê³¼ ê²€í† ",
                    "í…ìŠ¤íŠ¸ êµ¬ì¡°í™”",
                    "ë§¤ê±°ì§„ ìŠ¤íƒ€ì¼ ì ìš©",
                    "ìµœì¢… í¸ì§‘ ì™„ë£Œ"
                ],
                raw_input={
                    "original_content": section_content,
                    "analysis_result": analysis_result
                },
                raw_output=edited_content,
                performance_metrics={
                    "original_length": len(section_content),
                    "edited_length": len(edited_content),
                    "editing_quality": "professional"
                }
            )
        )

    async def _log_error_response_async(self, section_number: int, error_message: str) -> str:
        """ì—ëŸ¬ ì‘ë‹µ ì €ì¥ (ë¹„ë™ê¸°)"""
        return await asyncio.get_event_loop().run_in_executor(
            None,
            lambda: self.logger.log_agent_real_output(
                agent_name="OrgAgent_Error",
                agent_role="ì—ëŸ¬ ì²˜ë¦¬",
                task_description=f"ì„¹ì…˜ {section_number} ì²˜ë¦¬ ì¤‘ ì—ëŸ¬ ë°œìƒ",
                final_answer=f"ERROR: {error_message}",
                reasoning_process="ì—ì´ì „íŠ¸ ì‹¤í–‰ ì¤‘ ì˜ˆì™¸ ë°œìƒ",
                error_logs=[{"error": error_message, "section": section_number}]
            )
        )

    async def _map_to_templates_async(self, refined_sections: List[Dict], available_templates: List[str]) -> Dict:
        """ì„¹ì…˜ì„ í…œí”Œë¦¿ì— ë§¤í•‘ (ë¹„ë™ê¸°)"""
        return await asyncio.get_event_loop().run_in_executor(
            None,
            lambda: self._map_to_templates(refined_sections, available_templates)
        )

    async def _log_final_response_async(self, input_data: Dict, text_mapping: Dict,
                                      refined_sections: List[Dict], all_agent_responses: List[Dict],
                                      total_refined_length: int) -> str:
        """ì „ì²´ OrgAgent í”„ë¡œì„¸ìŠ¤ ì‘ë‹µ ì €ì¥ (ë¹„ë™ê¸°)"""
        return await asyncio.get_event_loop().run_in_executor(
            None,
            lambda: self.logger.log_agent_real_output(
                agent_name="OrgAgent",
                agent_role="PDF ë²¡í„° ë°ì´í„° ê¸°ë°˜ í…ìŠ¤íŠ¸ ë°°ì¹˜ ì—ì´ì „íŠ¸",
                task_description=f"{input_data['content_sections_count']}ê°œ ì½˜í…ì¸  ì„¹ì…˜ì„ {len(input_data['available_templates'])}ê°œ í…œí”Œë¦¿ì— ë§¤í•‘",
                final_answer=str(text_mapping),
                reasoning_process=f"ë¹„ë™ê¸° ë‹¤ì¤‘ ì—ì´ì „íŠ¸ í˜‘ì—…ìœ¼ë¡œ {len(refined_sections)}ê°œ ì„¹ì…˜ ì²˜ë¦¬ ì™„ë£Œ",
                execution_steps=[
                    "ë¹„ë™ê¸° ì½˜í…ì¸  ì¶”ì¶œ ë° ë¶„ì„",
                    "ë³‘ë ¬ ì„¹ì…˜ë³„ ë ˆì´ì•„ì›ƒ ë¶„ì„",
                    "ë¹„ë™ê¸° ì½˜í…ì¸  í¸ì§‘",
                    "í…œí”Œë¦¿ ë§¤í•‘"
                ],
                raw_input=input_data,
                raw_output={
                    "text_mapping": text_mapping,
                    "refined_sections": refined_sections,
                    "all_agent_responses": all_agent_responses
                },
                performance_metrics={
                    "total_sections_processed": len(refined_sections),
                    "total_content_length": total_refined_length,
                    "successful_sections": len([s for s in refined_sections if "error_response_id" not in s]),
                    "agent_responses_collected": len(all_agent_responses),
                    "async_processing": True
                }
            )
        )

    # ê¸°ì¡´ ë™ê¸° ë©”ì„œë“œë“¤ ìœ ì§€ (í˜¸í™˜ì„± ë³´ì¥)
    def _extract_clean_title_subtitle(self, analysis_result: str, index: int) -> tuple:
        """ë¶„ì„ ê²°ê³¼ì—ì„œ ê¹¨ë—í•œ ì œëª©ê³¼ ë¶€ì œëª© ì¶”ì¶œ"""
        title_pattern = r'ì œëª©[:\s]*([^\n]+)'
        subtitle_pattern = r'ë¶€ì œëª©[:\s]*([^\n]+)'
        
        title_match = re.search(title_pattern, analysis_result)
        subtitle_match = re.search(subtitle_pattern, analysis_result)
        
        title = title_match.group(1).strip() if title_match else f"ë„ì¿„ ì—¬í–‰ ì´ì•¼ê¸° {index + 1}"
        subtitle = subtitle_match.group(1).strip() if subtitle_match else "íŠ¹ë³„í•œ ìˆœê°„ë“¤"
        
        # ì„¤ëª… í…ìŠ¤íŠ¸ ì œê±°
        title = self._clean_title_from_descriptions(title)
        subtitle = self._clean_title_from_descriptions(subtitle)
        
        # ì œëª© ê¸¸ì´ ì¡°ì •
        if len(title) > 40:
            title = title[:37] + "..."
        if len(subtitle) > 30:
            subtitle = subtitle[:27] + "..."
        
        return title, subtitle

    def _clean_title_from_descriptions(self, text: str) -> str:
        """ì œëª©ì—ì„œ ì„¤ëª… í…ìŠ¤íŠ¸ ì œê±°"""
        patterns_to_remove = [
            r'\(í—¤ë“œë¼ì¸\)', r'\(ì„¹ì…˜ íƒ€ì´í‹€\)', r'ë° ë¶€.*?ë°°ì¹˜.*?ìˆìŒ',
            r'í•„ì ì •ë³´.*?ìˆìŒ', r'í¬í†  í¬ë ˆë”§.*?ìˆìŒ', r'ê³„ì¸µì .*?ìˆìŒ',
            r'ê³¼ ë³¸ë¬¸.*?ê´€ê³„', r'ë°°ì¹˜.*?ê´€ê³„', r'ìƒë‹¨.*?ë°°ì¹˜',
            r'ì¢Œìƒë‹¨.*?ë°°ì¹˜', r'í˜¹ì€.*?ë°°ì¹˜', r'ì—†ì´.*?ì§‘ì¤‘',
            r'ê·¸ ì•„ë˜ë¡œ.*?ìˆìŠµë‹ˆë‹¤'
        ]
        
        clean_text = text
        for pattern in patterns_to_remove:
            clean_text = re.sub(pattern, '', clean_text, flags=re.IGNORECASE | re.DOTALL)
        
        # ì—°ì†ëœ ê³µë°±ê³¼ íŠ¹ìˆ˜ë¬¸ì ì •ë¦¬
        clean_text = re.sub(r'\s+', ' ', clean_text)
        clean_text = re.sub(r'^[,\s:]+|[,\s:]+$', '', clean_text)
        
        return clean_text.strip() if clean_text.strip() else "ë„ì¿„ ì—¬í–‰ ì´ì•¼ê¸°"

    def _remove_meta_descriptions(self, content: str) -> str:
        """ì½˜í…ì¸ ì—ì„œ ë©”íƒ€ ì„¤ëª… ì œê±°"""
        patterns_to_remove = [
            r'\*ì´ í˜ì´ì§€ì—ëŠ”.*?ì‚´ë ¸ìŠµë‹ˆë‹¤\.\*',
            r'ë¸”ë¡ì€ ê· í˜•.*?ì¤„ì—¬ì¤ë‹ˆë‹¤',
            r'\(ì‚¬ì§„ ìº¡ì…˜\)',
            r'ì‹œê°ì  ë¦¬ë“¬ê³¼.*?ì‚´ë ¸ìŠµë‹ˆë‹¤',
            r'ì¶©ë¶„í•œ ì—¬ë°±.*?ì™„ì„±í•©ë‹ˆë‹¤',
            r'ì‚¬ì§„ì€ ë³¸ë¬¸.*?ì™„ì„±í•©ë‹ˆë‹¤',
            r'ì´ ì½˜í…ì¸ ëŠ”.*?ë””ìì¸ë˜ì—ˆìŠµë‹ˆë‹¤'
        ]
        
        clean_content = content
        for pattern in patterns_to_remove:
            clean_content = re.sub(pattern, '', clean_content, flags=re.IGNORECASE | re.DOTALL)
        
        return clean_content.strip()

    def _format_layout_data(self, similar_layouts: List[Dict]) -> str:
        """ë ˆì´ì•„ì›ƒ ë°ì´í„°ë¥¼ í…ìŠ¤íŠ¸ë¡œ í¬ë§·íŒ…"""
        if not similar_layouts:
            return "ìœ ì‚¬í•œ ë ˆì´ì•„ì›ƒ ë°ì´í„° ì—†ìŒ"
        
        formatted_data = []
        for i, layout in enumerate(similar_layouts):
            formatted_data.append(f"""
ë ˆì´ì•„ì›ƒ {i+1} (ìœ ì‚¬ë„: {layout.get('score', 0):.2f}):
- ì¶œì²˜: {layout.get('pdf_name', 'unknown')} (í˜ì´ì§€ {layout.get('page_number', 0)})
- í…ìŠ¤íŠ¸ ìƒ˜í”Œ: {layout.get('text_content', '')[:200]}...
- ì´ë¯¸ì§€ ìˆ˜: {len(layout.get('image_info', []))}ê°œ
- ë ˆì´ì•„ì›ƒ íŠ¹ì§•: {self._summarize_layout_info(layout.get('layout_info', {}))}
""")
        
        return "\n".join(formatted_data)

    def _summarize_layout_info(self, layout_info: Dict) -> str:
        """ë ˆì´ì•„ì›ƒ ì •ë³´ ìš”ì•½"""
        text_blocks = layout_info.get('text_blocks', [])
        images = layout_info.get('images', [])
        tables = layout_info.get('tables', [])
        
        summary = []
        if text_blocks:
            summary.append(f"í…ìŠ¤íŠ¸ ë¸”ë¡ {len(text_blocks)}ê°œ")
        if images:
            summary.append(f"ì´ë¯¸ì§€ {len(images)}ê°œ")
        if tables:
            summary.append(f"í…Œì´ë¸” {len(tables)}ê°œ")
        
        return ", ".join(summary) if summary else "ê¸°ë³¸ ë ˆì´ì•„ì›ƒ"

    def _extract_all_text(self, magazine_content) -> str:
        """ëª¨ë“  í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        if isinstance(magazine_content, dict):
            all_text = ""
            # ìš°ì„ ìˆœìœ„ì— ë”°ë¥¸ í…ìŠ¤íŠ¸ ì¶”ì¶œ
            priority_fields = [
                "integrated_content", "essay_content", "interview_content",
                "sections", "content", "body", "text"
            ]
            
            for field in priority_fields:
                if field in magazine_content:
                    value = magazine_content[field]
                    if isinstance(value, str) and value.strip():
                        all_text += value + "\n\n"
                    elif isinstance(value, dict):
                        for sub_key, sub_value in value.items():
                            if isinstance(sub_value, str) and sub_value.strip():
                                all_text += sub_value + "\n\n"
                    elif isinstance(value, list):
                        for item in value:
                            if isinstance(item, dict):
                                for sub_key, sub_value in item.items():
                                    if isinstance(sub_value, str) and sub_value.strip():
                                        all_text += sub_value + "\n\n"
                            elif isinstance(item, str) and item.strip():
                                all_text += item + "\n\n"
            
            return all_text.strip()
        else:
            return str(magazine_content)

    def _analyze_content_structure(self, content: str) -> List[str]:
        """ì½˜í…ì¸  êµ¬ì¡° ë¶„ì„ ë° ì§€ëŠ¥ì  ë¶„í• """
        if not content:
            return []
        
        sections = []
        
        # 1. í—¤ë” ê¸°ë°˜ ë¶„í• 
        header_sections = self._split_by_headers(content)
        if len(header_sections) >= 3:
            sections.extend(header_sections)
        
        # 2. ë¬¸ë‹¨ ê¸°ë°˜ ë¶„í• 
        if len(sections) < 5:
            paragraph_sections = self._split_by_paragraphs(content)
            sections.extend(paragraph_sections)
        
        # 3. ì˜ë¯¸ ê¸°ë°˜ ë¶„í• 
        if len(sections) < 6:
            semantic_sections = self._split_by_semantics(content)
            sections.extend(semantic_sections)
        
        # ì¤‘ë³µ ì œê±° ë° ê¸¸ì´ í•„í„°ë§
        unique_sections = []
        seen_content = set()
        for section in sections:
            section_clean = re.sub(r'\s+', ' ', section.strip())
            if len(section_clean) >= 100 and section_clean not in seen_content:
                unique_sections.append(section)
                seen_content.add(section_clean)
        
        return unique_sections[:8]  # ìµœëŒ€ 8ê°œ ì„¹ì…˜

    def _split_by_headers(self, content: str) -> List[str]:
        """í—¤ë” ê¸°ë°˜ ë¶„í• """
        sections = []
        header_pattern = r'^(#{1,3})\s+(.+?)$'
        current_section = ""
        
        lines = content.split('\n')
        for line in lines:
            if re.match(header_pattern, line.strip()):
                if current_section.strip():
                    sections.append(current_section.strip())
                current_section = line + "\n"
            else:
                current_section += line + "\n"
        
        if current_section.strip():
            sections.append(current_section.strip())
        
        return [s for s in sections if len(s) >= 100]

    def _split_by_paragraphs(self, content: str) -> List[str]:
        """ë¬¸ë‹¨ ê¸°ë°˜ ë¶„í• """
        paragraphs = content.split('\n\n')
        sections = []
        current_section = ""
        
        for paragraph in paragraphs:
            paragraph = paragraph.strip()
            if not paragraph:
                continue
            
            if len(current_section + paragraph) > 800:
                if current_section:
                    sections.append(current_section.strip())
                current_section = paragraph + "\n\n"
            else:
                current_section += paragraph + "\n\n"
        
        if current_section.strip():
            sections.append(current_section.strip())
        
        return [s for s in sections if len(s) >= 100]

    def _split_by_semantics(self, content: str) -> List[str]:
        """ì˜ë¯¸ ê¸°ë°˜ ë¶„í• """
        sentences = re.split(r'[.!?]\s+', content)
        sections = []
        current_section = ""
        
        for sentence in sentences:
            sentence = sentence.strip()
            if not sentence:
                continue
            
            if len(current_section + sentence) > 600:
                if current_section:
                    sections.append(current_section.strip())
                current_section = sentence + ". "
            else:
                current_section += sentence + ". "
        
        if current_section.strip():
            sections.append(current_section.strip())
        
        return [s for s in sections if len(s) >= 100]

    def _map_to_templates(self, refined_sections: List[Dict], available_templates: List[str]) -> Dict:
        """ì„¹ì…˜ì„ í…œí”Œë¦¿ì— ë§¤í•‘"""
        text_mapping = []
        
        for i, section in enumerate(refined_sections):
            template_index = i % len(available_templates) if available_templates else 0
            template_name = available_templates[template_index] if available_templates else f"Section{i+1:02d}.jsx"
            
            text_mapping.append({
                "template": template_name,
                "title": section["title"],
                "subtitle": section["subtitle"],
                "body": section["content"],
                "tagline": "TRAVEL & CULTURE",
                "layout_source": section.get("layout_info", {}).get("pdf_name", "default"),
                "agent_responses": section.get("agent_responses", {})
            })
        
        return {"text_mapping": text_mapping}
