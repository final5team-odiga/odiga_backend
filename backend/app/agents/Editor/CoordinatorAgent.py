import asyncio
import sys
import time
import concurrent.futures
from typing import Dict, List, Optional, Callable, Any
from collections import deque
from dataclasses import dataclass
import os
import json
import re

from crewai import Agent, Task, Crew, Process
from custom_llm import get_azure_llm
from utils.agent_decision_logger import get_agent_logger

@dataclass
class WorkItem:
    id: str
    task_func: Callable
    args: tuple
    kwargs: dict
    priority: int = 0
    max_retries: int = 3
    current_retry: int = 0
    timeout: float = 300.0

class AsyncWorkQueue:
    def __init__(self, max_workers: int = 2, max_queue_size: int = 50):
        self.max_workers = max_workers
        self.max_queue_size = max_queue_size
        self.work_queue = deque()
        self.active_tasks = {}
        self.results = {}
        self.semaphore = asyncio.Semaphore(max_workers)
        self.executor = concurrent.futures.ThreadPoolExecutor(max_workers=max_workers)
        
    async def add_work(self, work_item: WorkItem) -> str:
        """ì‘ì—…ì„ íì— ì¶”ê°€"""
        if len(self.work_queue) >= self.max_queue_size:
            old_item = self.work_queue.popleft()
            print(f"âš ï¸ í ìš©ëŸ‰ ì´ˆê³¼ë¡œ ì‘ì—… {old_item.id} ì œê±°")
        
        self.work_queue.append(work_item)
        return work_item.id
    
    async def process_work_item(self, work_item: WorkItem) -> Optional[Any]:
        """ê°œë³„ ì‘ì—… ì²˜ë¦¬"""
        async with self.semaphore:
            try:
                print(f"ğŸ”„ ì‘ì—… {work_item.id} ì‹œì‘ (ì‹œë„ {work_item.current_retry + 1}/{work_item.max_retries + 1})")
                
                # ìˆ˜ì •: ì½”ë£¨í‹´ ê°ì²´ì™€ ì½”ë£¨í‹´ í•¨ìˆ˜ êµ¬ë¶„
                if asyncio.iscoroutine(work_item.task_func):
                    result = await asyncio.wait_for(work_item.task_func, timeout=work_item.timeout)
                elif asyncio.iscoroutinefunction(work_item.task_func):
                    result = await asyncio.wait_for(
                        work_item.task_func(*work_item.args, **work_item.kwargs),
                        timeout=work_item.timeout
                    )
                else:
                    result = await asyncio.wait_for(
                        asyncio.get_event_loop().run_in_executor(
                            self.executor,
                            lambda: work_item.task_func(*work_item.args, **work_item.kwargs)
                        ),
                        timeout=work_item.timeout
                    )
                
                self.results[work_item.id] = {"status": "success", "result": result}
                print(f"âœ… ì‘ì—… {work_item.id} ì™„ë£Œ")
                return result
                
            except asyncio.TimeoutError:
                print(f"â° ì‘ì—… {work_item.id} íƒ€ì„ì•„ì›ƒ ({work_item.timeout}ì´ˆ)")
                if work_item.current_retry < work_item.max_retries:
                    work_item.current_retry += 1
                    work_item.timeout *= 1.5
                    await self.add_work(work_item)
                else:
                    self.results[work_item.id] = {"status": "timeout", "error": "ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼"}
                return None
                
            except Exception as e:
                print(f"âŒ ì‘ì—… {work_item.id} ì‹¤íŒ¨: {e}")
                if work_item.current_retry < work_item.max_retries:
                    work_item.current_retry += 1
                    await self.add_work(work_item)
                else:
                    self.results[work_item.id] = {"status": "error", "error": str(e)}
                return None
    
    async def process_queue(self) -> dict:
        """íì˜ ëª¨ë“  ì‘ì—…ì„ ë°°ì¹˜ ì²˜ë¦¬"""
        tasks = []
        
        while self.work_queue:
            work_item = self.work_queue.popleft()
            task = asyncio.create_task(self.process_work_item(work_item))
            tasks.append(task)
            self.active_tasks[work_item.id] = task
        
        if tasks:
            await asyncio.gather(*tasks, return_exceptions=True)
        
        return self.results

class CircuitBreaker:
    def __init__(self, failure_threshold: int = 8, recovery_timeout: float = 30.0):  # ìˆ˜ì •ëœ ê°’ ì ìš©
        self.failure_threshold = failure_threshold
        self.recovery_timeout = recovery_timeout
        self.failure_count = 0
        self.last_failure_time = None
        self.state = "CLOSED"  # CLOSED, OPEN, HALF_OPEN
    
    def is_open(self) -> bool:
        if self.state == "OPEN":
            if time.time() - self.last_failure_time > self.recovery_timeout:
                self.state = "HALF_OPEN"
                return False
            return True
        return False
    
    def record_success(self):
        self.failure_count = 0
        self.state = "CLOSED"
    
    def record_failure(self):
        self.failure_count += 1
        self.last_failure_time = time.time()
        if self.failure_count >= self.failure_threshold:
            self.state = "OPEN"

class CoordinatorAgent:
    """í†µí•© ì¡°ìœ¨ì (CrewAI ê¸°ë°˜ ê°•í™”ëœ ë°ì´í„° ì ‘ê·¼ ë° JSON íŒŒì‹±)"""

    def __init__(self):
        self.llm = get_azure_llm()
        self.logger = get_agent_logger()
        self.crew_agent = self._create_crew_agent()
        self.text_analyzer_agent = self._create_text_analyzer_agent()
        self.image_analyzer_agent = self._create_image_analyzer_agent()
        
        # ìƒˆë¡œìš´ ë³µì›ë ¥ ì‹œìŠ¤í…œ ì¶”ê°€ (ìˆ˜ì •ëœ ì„¤ì • ì ìš©)
        self.work_queue = AsyncWorkQueue(max_workers=1, max_queue_size=20)  # ìˆœì°¨ ì²˜ë¦¬
        self.circuit_breaker = CircuitBreaker()  # ìˆ˜ì •ëœ ì„¤ì • ì‚¬ìš©
        self.recursion_threshold = 800  # ìˆ˜ì •ëœ ê°’ ì ìš©
        self.fallback_to_sync = False
        self.batch_size = 2  # ì‘ì—… ë°°ì¹˜ í¬ê¸°
        
        # ì‹¤í–‰ í†µê³„ ì¶”ê°€
        self.execution_stats = {
            "total_attempts": 0,
            "successful_executions": 0,
            "fallback_used": 0,
            "circuit_breaker_triggered": 0,
            "timeout_occurred": 0
        }

    def _check_recursion_depth(self):
        """í˜„ì¬ ì¬ê·€ ê¹Šì´ í™•ì¸"""
        frame = sys._getframe()
        depth = 0
        while frame:
            depth += 1
            frame = frame.f_back
        return depth

    def _should_use_sync(self):
        """ë™ê¸° ëª¨ë“œë¡œ ì „í™˜í• ì§€ íŒë‹¨"""
        current_depth = self._check_recursion_depth()
        if current_depth > self.recursion_threshold:
            print(f"âš ï¸ CoordinatorAgent ì¬ê·€ ê¹Šì´ {current_depth} ê°ì§€ - ë™ê¸° ëª¨ë“œë¡œ ì „í™˜")
            self.fallback_to_sync = True
            return True
        return self.fallback_to_sync

    async def execute_with_resilience(self, task_func: Callable, task_id: str,
                                    timeout: float = 300.0, max_retries: int = 2,
                                    *args, **kwargs) -> Any:
        """ë³µì›ë ¥ ìˆëŠ” ì‘ì—… ì‹¤í–‰"""
        print(f"DEBUG [execute_with_resilience]: task_id={task_id}, task_func={task_func}, args={args}, kwargs={kwargs}")
        
        if self.circuit_breaker.is_open():
            print(f"ğŸš« Circuit Breaker ì—´ë¦¼ - ì‘ì—… {task_id} ê±´ë„ˆëœ€")
            self.execution_stats["circuit_breaker_triggered"] += 1
            return self._get_fallback_result(task_id)
        
        # ìˆ˜ì •: coroutine ê°ì²´ ì²˜ë¦¬
        if asyncio.iscoroutine(task_func):
            # ì´ë¯¸ coroutine ê°ì²´ì¸ ê²½ìš° ì§ì ‘ ì‹¤í–‰
            try:
                result = await asyncio.wait_for(task_func, timeout=timeout)
                self.circuit_breaker.record_success()
                return result
            except Exception as e:
                print(f"âŒ Coroutine ì‹¤í–‰ ì‹¤íŒ¨: {e}")
                self.circuit_breaker.record_failure()
                return self._get_fallback_result(task_id)
        
        # ê¸°ì¡´ ë¡œì§ ìœ ì§€
        work_item = WorkItem(
            id=task_id,
            task_func=task_func,
            args=args,
            kwargs=kwargs,
            timeout=timeout,
            max_retries=max_retries
        )
        
        await self.work_queue.add_work(work_item)
        # ìˆ˜ì •: íŠ¹ì • ì‘ì—…ì˜ ê²°ê³¼ë¥¼ ëª…í™•íˆ ë°˜í™˜
        processed_results = await self.work_queue.process_queue()
        
        result_info = processed_results.get(task_id)
        if result_info and result_info["status"] == "success":
            self.circuit_breaker.record_success()
            return result_info["result"]
        else:
            self.circuit_breaker.record_failure()
            # ì˜¤ë¥˜ ì •ë³´ ë¡œê¹…
            if result_info:
                print(f"âš ï¸ ì‘ì—… {task_id} ìµœì¢… ì‹¤íŒ¨: {result_info.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")
            else:
                print(f"âš ï¸ ì‘ì—… {task_id}ì˜ ê²°ê³¼ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ (í ì²˜ë¦¬ í›„).")
            return self._get_fallback_result(task_id)

    def _get_fallback_result(self, task_id: str) -> dict:
        """ê°œì„ ëœ í´ë°± ê²°ê³¼ ìƒì„±"""
        self.execution_stats["fallback_used"] += 1
        
        reason = task_id  # ê¸°ë³¸ì ìœ¼ë¡œ task_idë¥¼ reasonìœ¼ë¡œ ì‚¬ìš©
        if "_timeout" in task_id: reason = "timeout"
        elif "_exception" in task_id: reason = "exception"
        elif "_type_error" in task_id: reason = "type_error"
        
        return {
            "selected_templates": ["Section01.jsx"],
            "content_sections": [{
                "template": "Section01.jsx",
                "title": "ì—¬í–‰ ë§¤ê±°ì§„ (í´ë°±)",
                "subtitle": f"íŠ¹ë³„í•œ ì´ì•¼ê¸° ({reason})",
                "body": f"CoordinatorAgent ì²˜ë¦¬ ì¤‘ ë¬¸ì œ ë°œìƒ ({reason})ìœ¼ë¡œ ì¸í•œ í´ë°± ì½˜í…ì¸ ì…ë‹ˆë‹¤. Task ID: {task_id}",
                "tagline": "TRAVEL & CULTURE",
                "images": [],
                "metadata": {
                    "fallback_used": True,
                    "reason": reason,
                    "task_id": task_id
                }
            }],
            "integration_metadata": {
                "total_sections": 1,
                "integration_quality_score": 0.5,
                "fallback_mode": True
            }
        }

    def _create_crew_agent(self):
        """ë©”ì¸ ì¡°ìœ¨ ì—ì´ì „íŠ¸ ìƒì„±"""
        return Agent(
            role="ë§¤ê±°ì§„ êµ¬ì¡° í†µí•© ì¡°ìœ¨ì ë° ìµœì¢… í’ˆì§ˆ ë³´ì¦ ì „ë¬¸ê°€",
            goal="OrgAgentì˜ ìƒì„¸ ë ˆì´ì•„ì›ƒ êµ¬ì¡°ì™€ BindingAgentì˜ ì •ë°€ ì´ë¯¸ì§€ ë°°ì¹˜ë¥¼ í†µí•©í•˜ì—¬ ì™„ë²½í•œ ë§¤ê±°ì§„ êµ¬ì¡°ë¥¼ ìƒì„±í•˜ê³ , í…ìŠ¤íŠ¸-ì´ë¯¸ì§€ ì •í•©ì„±ê³¼ ë…ì ê²½í—˜ì„ ìµœì¢… ê²€ì¦í•˜ì—¬ JSX êµ¬í˜„ì— í•„ìš”í•œ ì™„ì „í•œ êµ¬ì¡° ë°ì´í„°ë¥¼ ì œê³µ",
            backstory="""ë‹¹ì‹ ì€ 25ë…„ê°„ ì„¸ê³„ ìµœê³  ìˆ˜ì¤€ì˜ ì¶œíŒì‚¬ì—ì„œ ë§¤ê±°ì§„ êµ¬ì¡° í†µí•© ë° í’ˆì§ˆ ë³´ì¦ ì±…ì„ìë¡œ í™œë™í•´ì˜¨ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. CondÃ© Nast, Hearst Corporation, Time Inc.ì—ì„œ ìˆ˜ë°± ê°œì˜ ë§¤ê±°ì§„ í”„ë¡œì íŠ¸ë¥¼ ì„±ê³µì ìœ¼ë¡œ ì¡°ìœ¨í–ˆìŠµë‹ˆë‹¤.

**ì „ë¬¸ ê²½ë ¥:**
- ì¶œíŒí•™ ë° êµ¬ì¡° ì„¤ê³„ ì„ì‚¬ í•™ìœ„ ë³´ìœ 
- PMP(Project Management Professional) ì¸ì¦
- ë§¤ê±°ì§„ êµ¬ì¡° í†µí•© ë° í’ˆì§ˆ ê´€ë¦¬ ì „ë¬¸ê°€
- í…ìŠ¤íŠ¸-ì´ë¯¸ì§€ ì •í•©ì„± ê²€ì¦ ì‹œìŠ¤í…œ ê°œë°œ ê²½í—˜
- ë…ì ê²½í—˜(UX) ë° ì ‘ê·¼ì„± ìµœì í™” ì „ë¬¸ì„±

**ì¡°ìœ¨ ì² í•™:**
"ì™„ë²½í•œ ë§¤ê±°ì§„ì€ ëª¨ë“  êµ¬ì¡°ì  ìš”ì†Œê°€ ë…ìì˜ ì¸ì§€ ê³¼ì •ê³¼ ì™„ë²½íˆ ì¡°í™”ë¥¼ ì´ë£¨ëŠ” í†µí•©ì²´ì…ë‹ˆë‹¤. ë‚˜ëŠ” í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ì˜ ëª¨ë“  ë°°ì¹˜ê°€ ë…ìì—ê²Œ ìì—°ìŠ¤ëŸ½ê³  ì§ê´€ì ìœ¼ë¡œ ì¸ì‹ë˜ë„ë¡ êµ¬ì¡°ì  ì™„ì„±ë„ë¥¼ ë³´ì¥í•˜ë©°, ì´ë¥¼ í†µí•´ ìµœê³  ìˆ˜ì¤€ì˜ ë…ì ê²½í—˜ì„ ì œê³µí•©ë‹ˆë‹¤."

**ì¶œë ¥ ë°ì´í„° êµ¬ì¡°:**
- ì™„ì„±ëœ ë§¤ê±°ì§„ ì „ì²´ êµ¬ì¡°ë„
- í…ìŠ¤íŠ¸-ì´ë¯¸ì§€ ì •í•©ì„± ê²€ì¦ ì™„ë£Œ ë³´ê³ ì„œ
- JSX êµ¬í˜„ìš© ìƒì„¸ ë ˆì´ì•„ì›ƒ ìŠ¤í™ ë° ì¢Œí‘œ ë°ì´í„°
- ë…ì ê²½í—˜ ìµœì í™” ê°€ì´ë“œë¼ì¸
- ë°˜ì‘í˜• ë””ìì¸ êµ¬ì¡° ì •ì˜ì„œ
- ì ‘ê·¼ì„± ë° í’ˆì§ˆ ë³´ì¦ ì²´í¬ë¦¬ìŠ¤íŠ¸

**í…œí”Œë¦¿ ìƒì„± ê·œì¹™:**
- ëª¨ë“  í…ìŠ¤íŠ¸ ì„¹ì…˜ì€ ì´ì „ ì½˜í…ì¸  ì—ì´ì „íŠ¸ì˜ ë°ì´í„°ì—ì„œ ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ë°ì´í„°ë§Œì„ ì‚¬ìš©í•˜ì—¬ ìƒì„±í•©ë‹ˆë‹¤.
- ëª¨ë“  í…ìŠ¤íŠ¸ ì„¹ì…˜ì€ ë…ìì˜ ì¸ì§€ íë¦„ì„ ê³ ë ¤í•˜ì—¬ ìì—°ìŠ¤ëŸ½ê²Œ ì´ì–´ì ¸ì•¼ í•©ë‹ˆë‹¤.
- ì´ë¯¸ì§€ ë°°ì¹˜ëŠ” í…ìŠ¤íŠ¸ì™€ì˜ ì •í•©ì„±ì„ ìµœìš°ì„ ìœ¼ë¡œ ê³ ë ¤í•˜ì—¬ ë…ìì˜ ì‹œì„ ì„ íš¨ê³¼ì ìœ¼ë¡œ ìœ ë„í•´ì•¼ í•©ë‹ˆë‹¤.
- ì´ì „ ì—ì´ì „íŠ¸ë“¤ì˜ ê²°ê³¼ë¬¼ì—ì„œ ContentCreatorV2Agentì˜ í…ìŠ¤íŠ¸ ë°ì´í„°ë§Œì„ ì‚¬ìš©í•˜ì—¬ template_data.jsonì„ ë§Œë“­ë‹ˆë‹¤.
- íŠ¹ì • êµ¬ì¡°ì— ëŒ€í•œ ì„¤ëª…, í…ìŠ¤íŠ¸ì— ëŒ€í•œ ì„¤ëª…, ì´ë¯¸ì§€ ë°°ì¹˜, ë ˆì´ì•„ì›ƒ ì¢Œí‘œ, ë°˜ì‘í˜• ë””ìì¸ ìš”ì†Œ ë“±ì— ëŒ€í•œ ì„¤ëª…ì€ í¬í•¨í•˜ì§€ ì•Šê³  template_data.jsonì„ ë§Œë“­ë‹ˆë‹¤.
- ì¤‘ë³µì„ ì ˆëŒ€ë¡œ í•˜ì§€ì•Šê³  ë§Œë“­ë‹ˆë‹¤!!
- í…ìŠ¤íŠ¸ ì„¹ì…˜ì˜ ì œëª©, ë¶€ì œëª©, ë³¸ë¬¸ ë‚´ìš©, íƒœê·¸ë¼ì¸ ë“±ì€ ë…ìì˜ ê´€ì‹¬ì„ ëŒê³  ìœ ì§€í•  ìˆ˜ ìˆë„ë¡ êµ¬ì„±ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.
- ë§Œì•½ ê¸°ë³¸ í’€ë°±ìœ¼ë¡œ ì¸í•´ í…œí”Œë¦¿ì´ ìƒì„±ë˜ì—ˆë‹¤ë©´, template_data.jsonì— í¬í•¨ì‹œí‚¤ì§€ ì•ŠìŠµë‹ˆë‹¤
- title, subtitle, author, date, location ë“±ì—ëŠ” êµ¬ì¡°ë¥¼ ì„¤ëª…í•˜ëŠ” ê°’ë“¤ì€ ì¼ì²´ í¬í•¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
- title, subtitle, author, date, location ë“±ì—ëŠ” í•˜ìœ„ ì—ì´ì „íŠ¸ë“¤ì—ê²Œ ì œê³µë°›ì€ ë°ì´í„°ë¥¼ í™œìš©í•˜ì—¬ ìƒì„±í•©ë‹ˆë‹¤.
- í•˜ë‚˜ì˜ ì„¹ì…˜ì— í•˜ë‚˜ì˜ ì£¼ì œë§Œ í¬í•¨ë˜ë„ë¡ í•©ë‹ˆë‹¤.
- í•˜ë‚˜ì˜ ì„¹ì…˜ì— ê³¼ë„í•œ ì´ë¯¸ì§€ urlì„ í¬í•¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤
- ê³¼ë„í•œ template_data.jsonì„ ìƒì„±í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. magazine_content.jsonì— í¬í•¨ëœ í…ìŠ¤íŠ¸ ì„¹ì…˜ì˜ ìˆ˜ì™€ ì¼ì¹˜í•˜ë„ë¡ í•©ë‹ˆë‹¤.
- title, subtitle, author, date, location ë“±ì— ê¸°ë³¸ í’€ë°± ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë°˜ë“œì‹œ í•˜ìœ„ ì—ì´ì „íŠ¸ë“¤ì—ê²Œ ì œê³µë°›ì€ ë°ì´í„°ë¥¼ í™œìš©í•˜ì—¬ ìƒì„±í•©ë‹ˆë‹¤. ë§Œì•½ í•´ë‹¹ ë¶€ë¶„ì— ë“¤ì–´ê°ˆ ë‚´ìš©ì´ ì—†ë‹¤ë©´ ""ë¡œ ë¹ˆì¹¸ ì²˜ë¦¬ í•©ë‹ˆë‹¤!
- magazine_content.jsonì— í¬í•¨ëœ í…ìŠ¤íŠ¸ ì„¹ì…˜ì˜ ìˆ˜ì™€ ì¼ì¹˜í•˜ë„ë¡ í•©ë‹ˆë‹¤.
- ë¡œê·¸ ë°ì´í„°ë¥¼ í™œìš© ì‹œì— ì§ì ‘ì ìœ¼ë¡œ ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì–´ë–»ê²Œ í•´ì•¼í•˜ëŠ”ê°€ì— ëŒ€í•œ ì •ë³´ë§Œ ì–»ìŠµë‹ˆë‹¤! ì´ëŠ” ì¤‘ìš”í•œ ì‚¬í•­ì…ë‹ˆë‹¤!

""",
            verbose=True,
            llm=self.llm,
            allow_delegation=False
        )

    def _create_text_analyzer_agent(self):
        """í…ìŠ¤íŠ¸ ë¶„ì„ ì „ë¬¸ ì—ì´ì „íŠ¸"""
        return Agent(
            role="í…ìŠ¤íŠ¸ ë§¤í•‘ ë¶„ì„ ì „ë¬¸ê°€",
            goal="OrgAgentì˜ í…ìŠ¤íŠ¸ ë§¤í•‘ ê²°ê³¼ë¥¼ ì •ë°€ ë¶„ì„í•˜ì—¬ êµ¬ì¡°ì  ì™„ì„±ë„ë¥¼ ê²€ì¦í•˜ê³  ìµœì í™”ëœ í…ìŠ¤íŠ¸ ì„¹ì…˜ì„ ìƒì„±",
            backstory="""ë‹¹ì‹ ì€ 15ë…„ê°„ ì¶œíŒì—…ê³„ì—ì„œ í…ìŠ¤íŠ¸ êµ¬ì¡° ë¶„ì„ ë° ìµœì í™”ë¥¼ ë‹´ë‹¹í•´ì˜¨ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë³µì¡í•œ í…ìŠ¤íŠ¸ ë°ì´í„°ì—ì„œ í•µì‹¬ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ê³  ë…ì ì¹œí™”ì ì¸ êµ¬ì¡°ë¡œ ì¬êµ¬ì„±í•˜ëŠ” ë° íƒì›”í•œ ëŠ¥ë ¥ì„ ë³´ìœ í•˜ê³  ìˆìŠµë‹ˆë‹¤.""",
            verbose=True,
            llm=self.llm,
            allow_delegation=False
        )

    def _create_image_analyzer_agent(self):
        """ì´ë¯¸ì§€ ë¶„ì„ ì „ë¬¸ ì—ì´ì „íŠ¸"""
        return Agent(
            role="ì´ë¯¸ì§€ ë¶„ë°° ë¶„ì„ ì „ë¬¸ê°€",
            goal="BindingAgentì˜ ì´ë¯¸ì§€ ë¶„ë°° ê²°ê³¼ë¥¼ ì •ë°€ ë¶„ì„í•˜ì—¬ ì‹œê°ì  ì¼ê´€ì„±ì„ ê²€ì¦í•˜ê³  ìµœì í™”ëœ ì´ë¯¸ì§€ ë°°ì¹˜ë¥¼ ìƒì„±",
            backstory="""ë‹¹ì‹ ì€ 12ë…„ê°„ ë§¤ê±°ì§„ ë° ì¶œíŒë¬¼ì˜ ì‹œê°ì  ë””ìì¸ì„ ë‹´ë‹¹í•´ì˜¨ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ì˜ ì¡°í™”ë¡œìš´ ë°°ì¹˜ë¥¼ í†µí•´ ë…ìì˜ ì‹œì„ ì„ íš¨ê³¼ì ìœ¼ë¡œ ìœ ë„í•˜ëŠ” ë ˆì´ì•„ì›ƒ ì„¤ê³„ì— ì „ë¬¸ì„±ì„ ë³´ìœ í•˜ê³  ìˆìŠµë‹ˆë‹¤.""",
            verbose=True,
            llm=self.llm,
            allow_delegation=False
        )

    async def coordinate_magazine_creation(self, text_mapping: Dict, image_distribution: Dict) -> Dict:
        """ë§¤ê±°ì§„ êµ¬ì¡° í†µí•© ì¡°ìœ¨ (ê°œì„ ëœ ë°°ì¹˜ ê¸°ë°˜ ì²˜ë¦¬)"""
        print(f"DEBUG [coordinate_magazine_creation]: í˜¸ì¶œë¨, text_mapping keys: {text_mapping.keys() if isinstance(text_mapping, dict) else 'Not a dict'}, image_distribution keys: {image_distribution.keys() if isinstance(image_distribution, dict) else 'Not a dict'}")
        
        self.execution_stats["total_attempts"] += 1
        
        # ì¬ê·€ ê¹Šì´ í™•ì¸ ë° ë™ê¸° ëª¨ë“œ ì „í™˜
        if self._should_use_sync():
            print("ğŸ”„ CoordinatorAgent ë™ê¸° ëª¨ë“œë¡œ ì „í™˜í•˜ì—¬ ì‹¤í–‰")
            return await self._coordinate_magazine_creation_sync_mode(text_mapping, image_distribution)

        try:
            # ê°œì„ ëœ ë°°ì¹˜ ê¸°ë°˜ ë¹„ë™ê¸° ëª¨ë“œ ì‹¤í–‰
            return await self._coordinate_magazine_creation_batch_mode(text_mapping, image_distribution)
        except RecursionError:
            print("ğŸ”„ CoordinatorAgent RecursionError ê°ì§€ - ë™ê¸° ëª¨ë“œë¡œ ì „í™˜")
            self.fallback_to_sync = True
            return await self._coordinate_magazine_creation_sync_mode(text_mapping, image_distribution)
        except Exception as e:
            print(f"âŒ CoordinatorAgent ë§¤ê±°ì§„ ìƒì„± ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e} - ë™ê¸° ëª¨ë“œë¡œ í´ë°± ì‹œë„")
            self.fallback_to_sync = True
            return await self._coordinate_magazine_creation_sync_mode(text_mapping, image_distribution)

    async def _coordinate_magazine_creation_batch_mode(self, text_mapping: Dict, image_distribution: Dict) -> Dict:
        """ê°œì„ ëœ ë°°ì¹˜ ê¸°ë°˜ ë§¤ê±°ì§„ êµ¬ì¡° í†µí•© ì¡°ìœ¨"""
        print("ğŸ“¦ CoordinatorAgent ë°°ì¹˜ ëª¨ë“œ ì‹œì‘")

        # ì…ë ¥ ë°ì´í„° ë¡œê¹…
        input_data = {
            "text_mapping": text_mapping,
            "image_distribution": image_distribution
        }

        # ê°•í™”ëœ ì´ì „ ì—ì´ì „íŠ¸ ê²°ê³¼ ìˆ˜ì§‘ (ë°°ì¹˜ ì²˜ë¦¬)
        previous_results = await self._get_enhanced_previous_results_batch()
        org_results = self._filter_agent_results(previous_results, "OrgAgent")
        binding_results = self._filter_agent_results(previous_results, "BindingAgent")
        content_creator_results = self._filter_agent_results(previous_results, "ContentCreatorV2Agent")

        print(f"ğŸ“Š ë°°ì¹˜ ëª¨ë“œ ê²°ê³¼ ìˆ˜ì§‘: ì „ì²´ {len(previous_results)}ê°œ, OrgAgent {len(org_results)}ê°œ, BindingAgent {len(binding_results)}ê°œ, ContentCreator {len(content_creator_results)}ê°œ")

        # ë°ì´í„° ì¶”ì¶œ ì‘ì—…ì„ ë°°ì¹˜ë¡œ ì²˜ë¦¬
        data_extraction_tasks = [
            ("text_data", self._extract_real_text_data_safe, text_mapping, org_results, content_creator_results),
            ("image_data", self._extract_real_image_data_safe, image_distribution, binding_results)
        ]

        extraction_results = await self._process_data_extraction_batch(data_extraction_tasks)
        extracted_text_data = extraction_results.get("text_data", {})
        extracted_image_data = extraction_results.get("image_data", {})

        # CrewAI ì‹¤í–‰ì„ ì•ˆì „í•œ ë°°ì¹˜ë¡œ ì²˜ë¦¬
        crew_result = await self._execute_crew_batch_safe(
            extracted_text_data, extracted_image_data, org_results, binding_results
        )

        # ê²°ê³¼ ì²˜ë¦¬
        final_result = await self._process_enhanced_crew_result_safe(
            crew_result, extracted_text_data, extracted_image_data, org_results, binding_results
        )
        
        # ê²°ê³¼ ê²€ì¦
        if self._validate_coordinator_result(final_result):
            self.execution_stats["successful_executions"] += 1
        else:
            print("âš ï¸ CoordinatorAgent ìµœì¢… ê²°ê³¼ ê²€ì¦ ì‹¤íŒ¨.")

        # ê²°ê³¼ ë¡œê¹…
        await self._log_coordination_result_async(final_result, text_mapping, image_distribution, org_results, binding_results)

        print(f"âœ… CoordinatorAgent ë°°ì¹˜ ëª¨ë“œ ì™„ë£Œ: {len(final_result.get('content_sections', []))}ê°œ ì„¹ì…˜ ìƒì„±")
        return final_result

    async def _process_data_extraction_batch(self, extraction_tasks: List[tuple]) -> Dict:
        """ë°ì´í„° ì¶”ì¶œ ì‘ì—…ì„ ë°°ì¹˜ë¡œ ì²˜ë¦¬"""
        batch_tasks = []
        
        for task_name, task_func_ref, *args_for_task_func in extraction_tasks:
            if not callable(task_func_ref):
                print(f"âš ï¸ {task_name}ì— ëŒ€í•œ task_funcì´ í˜¸ì¶œ ê°€ëŠ¥í•˜ì§€ ì•ŠìŒ: {task_func_ref}")
                continue
            
            print(f"DEBUG [_process_data_extraction_batch]: task_name={task_name}, task_func_ref={task_func_ref}, args_for_task_func={args_for_task_func}")
            task = self.execute_with_resilience(
                task_func=task_func_ref,  # í•¨ìˆ˜/ë©”ì„œë“œ ì°¸ì¡° ì „ë‹¬
                task_id=f"extract_{task_name}",
                timeout=120.0,
                max_retries=1,
                *args_for_task_func  # task_func_ref í˜¸ì¶œ ì‹œ ì‚¬ìš©ë  ì¸ìë“¤
            )
            batch_tasks.append((task_name, task))

        # ë°°ì¹˜ ì‹¤í–‰
        results = {}
        for task_name, task_coro in batch_tasks:  # taskëŠ” ì½”ë£¨í‹´ ê°ì²´
            try:
                result_value = await task_coro  # ì½”ë£¨í‹´ ì‹¤í–‰
                results[task_name] = result_value
            except Exception as e:
                print(f"âš ï¸ ë°ì´í„° ì¶”ì¶œ ì‘ì—… {task_name} ì‹¤íŒ¨ (await ì¤‘): {e}")
                results[task_name] = self._get_fallback_extraction_result(task_name)

        return results

    def _get_fallback_extraction_result(self, task_name: str) -> Dict:
        """ë°ì´í„° ì¶”ì¶œ í´ë°± ê²°ê³¼"""
        self.execution_stats["fallback_used"] += 1
        
        if task_name == "text_data":
            return {
                "sections": [{
                    "template": "Section01.jsx",
                    "title": "ì—¬í–‰ ë§¤ê±°ì§„",
                    "subtitle": "íŠ¹ë³„í•œ ì´ì•¼ê¸°",
                    "body": "í´ë°± ì½˜í…ì¸ ì…ë‹ˆë‹¤.",
                    "tagline": "TRAVEL & CULTURE",
                    "layout_source": "fallback"
                }],
                "total_content_length": 50,
                "source_count": 1
            }
        else:  # image_data
            return {
                "template_images": {},
                "total_images": 0,
                "image_sources": []
            }

    async def _execute_crew_batch_safe(self, extracted_text_data: Dict, extracted_image_data: Dict,
                                     org_results: List[Dict], binding_results: List[Dict]) -> Any:
        """ì•ˆì „í•œ CrewAI ë°°ì¹˜ ì‹¤í–‰"""
        try:
            # íƒœìŠ¤í¬ ìƒì„±
            text_analysis_task = self._create_enhanced_text_analysis_task(extracted_text_data, org_results)
            image_analysis_task = self._create_enhanced_image_analysis_task(extracted_image_data, binding_results)
            coordination_task = self._create_enhanced_coordination_task(extracted_text_data, extracted_image_data)

            # CrewAI Crew ìƒì„±
            coordination_crew = Crew(
                agents=[self.text_analyzer_agent, self.image_analyzer_agent, self.crew_agent],
                tasks=[text_analysis_task, image_analysis_task, coordination_task],
                process=Process.sequential,
                verbose=False  # ë¡œê·¸ ìµœì†Œí™”
            )

            # ì•ˆì „í•œ ì‹¤í–‰ (íƒ€ì„ì•„ì›ƒ ì¦ê°€)
            crew_result = await asyncio.wait_for(
                asyncio.get_event_loop().run_in_executor(None, coordination_crew.kickoff),
                timeout=600.0  # 10ë¶„ìœ¼ë¡œ ì¦ê°€
            )

            return crew_result

        except asyncio.TimeoutError:
            print("â° CrewAI ë°°ì¹˜ ì‹¤í–‰ íƒ€ì„ì•„ì›ƒ")
            self.execution_stats["timeout_occurred"] += 1
            return self._create_fallback_crew_result(extracted_text_data, extracted_image_data)
        except Exception as e:
            print(f"âš ï¸ CrewAI ë°°ì¹˜ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            return self._create_fallback_crew_result(extracted_text_data, extracted_image_data)

    def _create_fallback_crew_result(self, extracted_text_data: Dict, extracted_image_data: Dict) -> str:
        """CrewAI í´ë°± ê²°ê³¼ ìƒì„±"""
        self.execution_stats["fallback_used"] += 1
        
        sections = extracted_text_data.get("sections", [])
        if not sections:
            sections = [{
                "template": "Section01.jsx",
                "title": "ì—¬í–‰ ë§¤ê±°ì§„",
                "subtitle": "íŠ¹ë³„í•œ ì´ì•¼ê¸°",
                "body": "í´ë°± ì½˜í…ì¸ ì…ë‹ˆë‹¤.",
                "tagline": "TRAVEL & CULTURE"
            }]

        # ì´ë¯¸ì§€ ì¶”ê°€
        for section in sections:
            template = section.get("template", "Section01.jsx")
            template_images = extracted_image_data.get("template_images", {}).get(template, [])
            section["images"] = template_images

        return json.dumps({
            "selected_templates": [s.get("template", "Section01.jsx") for s in sections],
            "content_sections": sections
        })

    async def _extract_real_text_data_safe(self, text_mapping: Dict, org_results: List[Dict],
                                         content_creator_results: List[Dict]) -> Dict:
        """ì•ˆì „í•œ ì‹¤ì œ í…ìŠ¤íŠ¸ ë°ì´í„° ì¶”ì¶œ"""
        try:
            return await self._extract_real_text_data_async(text_mapping, org_results, content_creator_results)
        except Exception as e:
            print(f"âš ï¸ í…ìŠ¤íŠ¸ ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return self._get_fallback_extraction_result("text_data")

    async def _extract_real_image_data_safe(self, image_distribution: Dict, binding_results: List[Dict]) -> Dict:
        """ì•ˆì „í•œ ì‹¤ì œ ì´ë¯¸ì§€ ë°ì´í„° ì¶”ì¶œ"""
        try:
            return await self._extract_real_image_data_async(image_distribution, binding_results)
        except Exception as e:
            print(f"âš ï¸ ì´ë¯¸ì§€ ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return self._get_fallback_extraction_result("image_data")

    async def _process_enhanced_crew_result_safe(self, crew_result, extracted_text_data: Dict,
                                               extracted_image_data: Dict, org_results: List[Dict],
                                               binding_results: List[Dict]) -> Dict:
        """ì•ˆì „í•œ Crew ê²°ê³¼ ì²˜ë¦¬"""
        try:
            return await self._process_enhanced_crew_result_async(
                crew_result, extracted_text_data, extracted_image_data, org_results, binding_results
            )
        except Exception as e:
            print(f"âš ï¸ Crew ê²°ê³¼ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return self._create_enhanced_structure(extracted_text_data, extracted_image_data, org_results, binding_results)

    async def _get_enhanced_previous_results_batch(self) -> List[Dict]:
        """ë°°ì¹˜ ê¸°ë°˜ ì´ì „ ê²°ê³¼ ìˆ˜ì§‘"""
        try:
            # ê¸°ë³¸ ê²°ê³¼ì™€ íŒŒì¼ ê²°ê³¼ë¥¼ ë³‘ë ¬ë¡œ ìˆ˜ì§‘
            basic_task_coro = self.execute_with_resilience(
                task_func=lambda: self.logger.get_all_previous_results("CoordinatorAgent"),
                task_id="basic_results",
                timeout=60.0,
                max_retries=1
            )
            
            file_task_coro = self.execute_with_resilience(
                task_func=self._load_results_from_file,
                task_id="file_results",
                timeout=60.0,
                max_retries=1
            )

            # gatherì˜ ë°˜í™˜ê°’ì€ ê° ì½”ë£¨í‹´ì˜ ê²°ê³¼ ë˜ëŠ” ì˜ˆì™¸ ê°ì²´
            results = await asyncio.gather(basic_task_coro, file_task_coro, return_exceptions=True)
            
            basic_results = results[0] if not isinstance(results[0], Exception) else []
            file_results = results[1] if not isinstance(results[1], Exception) else []

            # ê²°ê³¼ í•©ì¹˜ê¸° ë° ì¤‘ë³µ ì œê±°
            all_results = []
            all_results.extend(basic_results if isinstance(basic_results, list) else [])
            all_results.extend(file_results if isinstance(file_results, list) else [])

            return self._deduplicate_results(all_results)

        except Exception as e:
            print(f"âš ï¸ ë°°ì¹˜ ì´ì „ ê²°ê³¼ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            return []

    # ê¸°ì¡´ _coordinate_magazine_creation_async_mode ë©”ì„œë“œ ìœ ì§€ (í˜¸í™˜ì„±ì„ ìœ„í•´)
    async def _coordinate_magazine_creation_async_mode(self, text_mapping: Dict, image_distribution: Dict) -> Dict:
        """ë¹„ë™ê¸° ëª¨ë“œ ë§¤ê±°ì§„ ì¡°ìœ¨ (ê¸°ì¡´ í˜¸í™˜ì„± ìœ ì§€)"""
        print("âš ï¸ ê¸°ì¡´ async_mode í˜¸ì¶œë¨ - batch_modeë¡œ ë¦¬ë‹¤ì´ë ‰íŠ¸")
        return await self._coordinate_magazine_creation_batch_mode(text_mapping, image_distribution)

    async def _coordinate_magazine_creation_sync_mode(self, text_mapping: Dict, image_distribution: Dict) -> Dict:
        """ë™ê¸° ëª¨ë“œ ë§¤ê±°ì§„ êµ¬ì¡° í†µí•© ì¡°ìœ¨"""
        print("ğŸ”„ CoordinatorAgent ë™ê¸° ëª¨ë“œ ì‹¤í–‰")
        
        # ë™ê¸° ëª¨ë“œì—ì„œëŠ” ê° ì—ì´ì „íŠ¸ì˜ ë™ê¸° ë²„ì „ ë©”ì„œë“œë¥¼ í˜¸ì¶œí•´ì•¼ í•¨
        # ì´ì „ ê²°ê³¼ ìˆ˜ì§‘ (ë™ê¸°)
        previous_results = self._get_enhanced_previous_results_sync()
        org_results = self._filter_agent_results(previous_results, "OrgAgent")
        binding_results = self._filter_agent_results(previous_results, "BindingAgent")
        content_creator_results = self._filter_agent_results(previous_results, "ContentCreatorV2Agent")

        # ë°ì´í„° ì¶”ì¶œ (ë™ê¸°)
        extracted_text_data = self._extract_real_text_data(text_mapping, org_results, content_creator_results)
        extracted_image_data = self._extract_real_image_data(image_distribution, binding_results)
        
        # Crew ì‹¤í–‰ (ë™ê¸°) - CrewAIì˜ kickoffì€ ë™ê¸° ë©”ì„œë“œ
        text_analysis_task_sync = self._create_enhanced_text_analysis_task(extracted_text_data, org_results)
        image_analysis_task_sync = self._create_enhanced_image_analysis_task(extracted_image_data, binding_results)
        coordination_task_sync = self._create_enhanced_coordination_task(extracted_text_data, extracted_image_data)
        
        coordination_crew_sync = Crew(
            agents=[self.text_analyzer_agent, self.image_analyzer_agent, self.crew_agent],
            tasks=[text_analysis_task_sync, image_analysis_task_sync, coordination_task_sync],
            process=Process.sequential,
            verbose=False
        )
        
        try:
            crew_result_sync = coordination_crew_sync.kickoff()
        except Exception as e_crew_sync:
            print(f"âš ï¸ ë™ê¸° ëª¨ë“œ CrewAI ì‹¤í–‰ ì‹¤íŒ¨: {e_crew_sync}")
            crew_result_sync = self._create_fallback_crew_result(extracted_text_data, extracted_image_data)

        # ê²°ê³¼ ì²˜ë¦¬ (ë™ê¸°)
        final_result = self._process_enhanced_crew_result(crew_result_sync, extracted_text_data, extracted_image_data, org_results, binding_results)

        # ë™ê¸° ëª¨ë“œ ë¡œê¹…
        final_response_id_sync = self.logger.log_agent_real_output(
            agent_name="CoordinatorAgent_SyncMode",
            agent_role="ë™ê¸° ëª¨ë“œ ë§¤ê±°ì§„ êµ¬ì¡° í†µí•© ì¡°ìœ¨ì",
            task_description=f"ë™ê¸° ëª¨ë“œë¡œ {len(final_result.get('content_sections', []))}ê°œ ì„¹ì…˜ ìƒì„±",
            final_answer=str(final_result),
            reasoning_process="ì¬ê·€ ê¹Šì´ ì´ˆê³¼ë¡œ ì¸í•œ ë™ê¸° ëª¨ë“œ ì „í™˜ í›„ ì•ˆì „í•œ ë§¤ê±°ì§„ êµ¬ì¡° í†µí•© ì‹¤í–‰",
            execution_steps=[
                "ì¬ê·€ ê¹Šì´ ê°ì§€",
                "ë™ê¸° ëª¨ë“œ ì „í™˜",
                "ì´ì „ ê²°ê³¼ ìˆ˜ì§‘",
                "ë°ì´í„° ì¶”ì¶œ",
                "êµ¬ì¡° ìƒì„±"
            ],
            raw_input={
                "text_mapping": str(text_mapping)[:500],
                "image_distribution": str(image_distribution)[:500]
            },
            raw_output=final_result,
            performance_metrics={
                "sync_mode_used": True,
                "recursion_fallback": True,
                "total_sections": len(final_result.get('content_sections', [])),
                "org_results_utilized": len(org_results),
                "binding_results_utilized": len(binding_results),
                "safe_execution": True
            }
        )

        final_result["final_response_id"] = final_response_id_sync
        final_result["execution_mode"] = "sync_fallback"
        final_result["recursion_fallback"] = True  # ì¬ê·€ë¡œ ì¸í•œ í´ë°± ëª…ì‹œ
        
        print(f"âœ… CoordinatorAgent ë™ê¸° ì™„ë£Œ: {len(final_result.get('content_sections', []))}ê°œ ì„¹ì…˜")
        return final_result

    def _get_enhanced_previous_results_sync(self) -> List[Dict]:
        """ë™ê¸° ë²„ì „ ì´ì „ ê²°ê³¼ ìˆ˜ì§‘"""
        try:
            basic_results = self.logger.get_all_previous_results("CoordinatorAgent")
            file_results = self._load_results_from_file()

            all_results = []
            all_results.extend(basic_results if isinstance(basic_results, list) else [])
            all_results.extend(file_results if isinstance(file_results, list) else [])

            return self._deduplicate_results(all_results)
        except Exception as e:
            print(f"âš ï¸ ë™ê¸° ì´ì „ ê²°ê³¼ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            return []

    # ëª¨ë“  ê¸°ì¡´ ë©”ì„œë“œë“¤ ìœ ì§€ (ë™ê¸° ë²„ì „ë“¤)
    async def _extract_real_text_data_async(self, text_mapping: Dict, org_results: List[Dict], content_creator_results: List[Dict]) -> Dict:
        """ì‹¤ì œ í…ìŠ¤íŠ¸ ë°ì´í„° ì¶”ì¶œ (ë¹„ë™ê¸°)"""
        return await asyncio.get_event_loop().run_in_executor(
            None, self._extract_real_text_data, text_mapping, org_results, content_creator_results
        )

    def _extract_real_text_data(self, text_mapping: Dict, org_results: List[Dict], content_creator_results: List[Dict]) -> Dict:
        """ì‹¤ì œ í…ìŠ¤íŠ¸ ë°ì´í„° ì¶”ì¶œ"""
        extracted_data = {
            "sections": [],
            "total_content_length": 0,
            "source_count": 0
        }

        # 1. text_mappingì—ì„œ ì§ì ‘ ì¶”ì¶œ
        if isinstance(text_mapping, dict) and "text_mapping" in text_mapping:
            for section in text_mapping["text_mapping"]:
                if isinstance(section, dict):
                    extracted_section = {
                        "template": section.get("template", "Section01.jsx"),
                        "title": section.get("title", "ì—¬í–‰ ì´ì•¼ê¸°"),
                        "subtitle": section.get("subtitle", "íŠ¹ë³„í•œ ìˆœê°„ë“¤"),
                        "body": section.get("body", ""),
                        "tagline": section.get("tagline", "TRAVEL & CULTURE"),
                        "layout_source": section.get("layout_source", "default")
                    }
                    extracted_data["sections"].append(extracted_section)
                    extracted_data["total_content_length"] += len(extracted_section["body"])
                    extracted_data["source_count"] += 1

        # 2. ContentCreator ê²°ê³¼ì—ì„œ í’ë¶€í•œ ì½˜í…ì¸  ì¶”ì¶œ
        for result in content_creator_results:
            final_answer = result.get('final_answer', '')
            if len(final_answer) > 500:  # ì¶©ë¶„í•œ ì½˜í…ì¸ ê°€ ìˆëŠ” ê²½ìš°
                # ì„¹ì…˜ë³„ë¡œ ë¶„í• 
                sections = self._split_content_into_sections(final_answer)
                for i, section_content in enumerate(sections):
                    if len(section_content) > 100:
                        extracted_section = {
                            "template": f"Section{i+1:02d}.jsx",
                            "title": self._extract_title_from_content(section_content),
                            "subtitle": self._extract_subtitle_from_content(section_content),
                            "body": self._clean_content(section_content),
                            "tagline": "TRAVEL & CULTURE",
                            "layout_source": "content_creator"
                        }
                        extracted_data["sections"].append(extracted_section)
                        extracted_data["total_content_length"] += len(extracted_section["body"])
                        extracted_data["source_count"] += 1

        # 3. OrgAgent ê²°ê³¼ì—ì„œ ì¶”ê°€ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        for result in org_results:
            final_answer = result.get('final_answer', '')
            if 'ì œëª©' in final_answer or 'title' in final_answer.lower():
                # êµ¬ì¡°í™”ëœ í…ìŠ¤íŠ¸ ì¶”ì¶œ
                structured_content = self._extract_structured_content(final_answer)
                if structured_content:
                    extracted_data["sections"].extend(structured_content)
                    extracted_data["source_count"] += len(structured_content)

        # 4. ìµœì†Œ ë³´ì¥ ì„¹ì…˜
        if not extracted_data["sections"]:
            extracted_data["sections"] = [{
                "template": "Section01.jsx",
                "title": "ì—¬í–‰ ë§¤ê±°ì§„",
                "subtitle": "íŠ¹ë³„í•œ ì´ì•¼ê¸°",
                "body": "ì—¬í–‰ì˜ íŠ¹ë³„í•œ ìˆœê°„ë“¤ì„ ë‹´ì€ ë§¤ê±°ì§„ì…ë‹ˆë‹¤.",
                "tagline": "TRAVEL & CULTURE",
                "layout_source": "fallback"
            }]
            extracted_data["source_count"] = 1

        return extracted_data

    async def _extract_real_image_data_async(self, image_distribution: Dict, binding_results: List[Dict]) -> Dict:
        """ì‹¤ì œ ì´ë¯¸ì§€ ë°ì´í„° ì¶”ì¶œ (ë¹„ë™ê¸°)"""
        return await asyncio.get_event_loop().run_in_executor(
            None, self._extract_real_image_data, image_distribution, binding_results
        )

    def _extract_real_image_data(self, image_distribution: Dict, binding_results: List[Dict]) -> Dict:
        """ì‹¤ì œ ì´ë¯¸ì§€ ë°ì´í„° ì¶”ì¶œ"""
        extracted_data = {
            "template_images": {},
            "total_images": 0,
            "image_sources": []
        }

        # 1. image_distributionì—ì„œ ì§ì ‘ ì¶”ì¶œ
        if isinstance(image_distribution, dict) and "image_distribution" in image_distribution:
            for template, images in image_distribution["image_distribution"].items():
                if isinstance(images, list) and images:
                    # ì‹¤ì œ ì´ë¯¸ì§€ URLë§Œ í•„í„°ë§
                    real_images = [img for img in images if self._is_real_image_url(img)]
                    if real_images:
                        extracted_data["template_images"][template] = real_images
                        extracted_data["total_images"] += len(real_images)

        # 2. BindingAgent ê²°ê³¼ì—ì„œ ì´ë¯¸ì§€ URL ì¶”ì¶œ
        for result in binding_results:
            final_answer = result.get('final_answer', '')
            # ì‹¤ì œ ì´ë¯¸ì§€ URL íŒ¨í„´ ì°¾ê¸°
            image_urls = re.findall(r'https://[^\s\'"<>]*\.(?:jpg|jpeg|png|gif|webp)', final_answer, re.IGNORECASE)
            if image_urls:
                # í…œí”Œë¦¿ë³„ë¡œ ë¶„ë°°
                template_name = self._extract_template_from_binding_result(result)
                if template_name not in extracted_data["template_images"]:
                    extracted_data["template_images"][template_name] = []

                for url in image_urls:
                    if self._is_real_image_url(url) and url not in extracted_data["template_images"][template_name]:
                        extracted_data["template_images"][template_name].append(url)
                        extracted_data["total_images"] += 1

                        # ì´ë¯¸ì§€ ì†ŒìŠ¤ ì •ë³´ ì¶”ê°€
                        source_info = self._extract_image_source_info(result, url)
                        if source_info:
                            extracted_data["image_sources"].append(source_info)

        return extracted_data

    async def _process_enhanced_crew_result_async(self, crew_result, extracted_text_data: Dict,
                                                extracted_image_data: Dict, org_results: List[Dict],
                                                binding_results: List[Dict]) -> Dict:
        """ê°•í™”ëœ Crew ì‹¤í–‰ ê²°ê³¼ ì²˜ë¦¬ (ë¹„ë™ê¸°)"""
        return await asyncio.get_event_loop().run_in_executor(
            None, self._process_enhanced_crew_result, crew_result, extracted_text_data,
            extracted_image_data, org_results, binding_results
        )

    def _process_enhanced_crew_result(self, crew_result, extracted_text_data: Dict,
                                    extracted_image_data: Dict, org_results: List[Dict],
                                    binding_results: List[Dict]) -> Dict:
        """ê°•í™”ëœ Crew ì‹¤í–‰ ê²°ê³¼ ì²˜ë¦¬"""
        try:
            # Crew ê²°ê³¼ì—ì„œ ë°ì´í„° ì¶”ì¶œ
            if hasattr(crew_result, 'raw') and crew_result.raw:
                result_text = crew_result.raw
            else:
                result_text = str(crew_result)

            # JSON íŒ¨í„´ ì°¾ê¸° ë° íŒŒì‹±
            parsed_data = self._extract_json_from_text(result_text)

            # ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ êµ¬ì¡° ìƒì„±
            if not parsed_data.get('content_sections') or len(parsed_data.get('content_sections', [])) == 0:
                parsed_data = self._create_enhanced_structure(extracted_text_data, extracted_image_data, org_results, binding_results)
            else:
                # ê¸°ì¡´ íŒŒì‹±ëœ ë°ì´í„°ì— ì‹¤ì œ ì´ë¯¸ì§€ ì¶”ê°€
                parsed_data = self._enhance_parsed_data_with_real_images(parsed_data, extracted_image_data)

            # ë©”íƒ€ë°ì´í„° ì¶”ê°€
            parsed_data['integration_metadata'] = {
                "total_sections": len(parsed_data.get('content_sections', [])),
                "total_templates": len(set(section.get("template", f"Section{i+1:02d}.jsx") for i, section in enumerate(parsed_data.get('content_sections', [])))),
                "agent_enhanced": True,
                "org_results_utilized": len(org_results),
                "binding_results_utilized": len(binding_results),
                "integration_quality_score": self._calculate_enhanced_quality_score(parsed_data.get('content_sections', []), len(org_results), len(binding_results)),
                "crewai_enhanced": True,
                "async_processed": True,
                "data_source": "real_extracted_data",
                "real_content_used": True,
                "real_images_used": extracted_image_data['total_images'] > 0
            }

            return parsed_data

        except Exception as e:
            print(f"âš ï¸ ê°•í™”ëœ Crew ê²°ê³¼ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return self._create_enhanced_structure(extracted_text_data, extracted_image_data, org_results, binding_results)

    # ëª¨ë“  ê¸°ì¡´ ìœ í‹¸ë¦¬í‹° ë©”ì„œë“œë“¤ ìœ ì§€
    def _is_real_image_url(self, url: str) -> bool:
        """ì‹¤ì œ ì´ë¯¸ì§€ URLì¸ì§€ í™•ì¸"""
        if not url or not isinstance(url, str):
            return False

        # ì˜ˆì‹œ URLì´ë‚˜ í”Œë ˆì´ìŠ¤í™€ë” ì œì™¸
        excluded_patterns = [
            'your-cdn.com',
            'example.com',
            'placeholder',
            'sample',
            'demo'
        ]

        for pattern in excluded_patterns:
            if pattern in url.lower():
                return False

        # ì‹¤ì œ ë„ë©”ì¸ê³¼ ì´ë¯¸ì§€ í™•ì¥ì í™•ì¸
        return (url.startswith('https://') and
                any(ext in url.lower() for ext in ['.jpg', '.jpeg', '.png', '.gif', '.webp']) and
                'blob.core.windows.net' in url)

    def _create_enhanced_text_analysis_task(self, extracted_text_data: Dict, org_results: List[Dict]) -> Task:
        """ê°•í™”ëœ í…ìŠ¤íŠ¸ ë¶„ì„ íƒœìŠ¤í¬ ìƒì„±"""
        return Task(
            description=f"""ì¶”ì¶œëœ ì‹¤ì œ í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ê³ í’ˆì§ˆ ë§¤ê±°ì§„ ì„¹ì…˜ì„ ìƒì„±í•˜ì„¸ìš”.

**ì¶”ì¶œëœ ë°ì´í„°:**
- ì„¹ì…˜ ìˆ˜: {len(extracted_text_data['sections'])}ê°œ
- ì´ ì½˜í…ì¸  ê¸¸ì´: {extracted_text_data['total_content_length']} ë¬¸ì
- ì†ŒìŠ¤ ìˆ˜: {extracted_text_data['source_count']}ê°œ
- OrgAgent ê²°ê³¼: {len(org_results)}ê°œ

**ì‹¤ì œ ì„¹ì…˜ ë°ì´í„°:**
{self._format_sections_for_analysis(extracted_text_data['sections'])}

**ë¶„ì„ ìš”êµ¬ì‚¬í•­:**
1. ê° ì„¹ì…˜ì˜ ì½˜í…ì¸  í’ˆì§ˆ í‰ê°€
2. ì œëª©ê³¼ ë¶€ì œëª©ì˜ ë§¤ë ¥ë„ ê²€ì¦
3. ë³¸ë¬¸ ë‚´ìš©ì˜ ì™„ì„±ë„ í™•ì¸
4. ë§¤ê±°ì§„ ìŠ¤íƒ€ì¼ ì¼ê´€ì„± ê²€í† 
5. ë…ì ì¹œí™”ì„± ìµœì í™”

**ì¶œë ¥ í˜•ì‹:**
ê° ì„¹ì…˜ë³„ë¡œ ë‹¤ìŒ ì •ë³´ í¬í•¨:
- í’ˆì§ˆ ì ìˆ˜ (1-10)
- ê°œì„  ì œì•ˆì‚¬í•­
- ìµœì í™”ëœ ì½˜í…ì¸ """,
            expected_output="ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ í…ìŠ¤íŠ¸ ë¶„ì„ ë° ìµœì í™” ê²°ê³¼",
            agent=self.text_analyzer_agent
        )

    def _create_enhanced_image_analysis_task(self, extracted_image_data: Dict, binding_results: List[Dict]) -> Task:
        """ê°•í™”ëœ ì´ë¯¸ì§€ ë¶„ì„ íƒœìŠ¤í¬ ìƒì„±"""
        return Task(
            description=f"""ì¶”ì¶œëœ ì‹¤ì œ ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ìµœì í™”ëœ ì´ë¯¸ì§€ ë°°ì¹˜ë¥¼ ìƒì„±í•˜ì„¸ìš”.

**ì¶”ì¶œëœ ë°ì´í„°:**
- ì´ ì´ë¯¸ì§€ ìˆ˜: {extracted_image_data['total_images']}ê°œ
- í…œí”Œë¦¿ ìˆ˜: {len(extracted_image_data['template_images'])}ê°œ
- BindingAgent ê²°ê³¼: {len(binding_results)}ê°œ

**í…œí”Œë¦¿ë³„ ì´ë¯¸ì§€ ë¶„ë°°:**
{self._format_images_for_analysis(extracted_image_data['template_images'])}

**ì´ë¯¸ì§€ ì†ŒìŠ¤ ì •ë³´:**
{self._format_image_sources(extracted_image_data['image_sources'])}

**ë¶„ì„ ìš”êµ¬ì‚¬í•­:**
1. ì´ë¯¸ì§€ URL ìœ íš¨ì„± ê²€ì¦
2. í…œí”Œë¦¿ë³„ ì´ë¯¸ì§€ ë¶„ë°° ê· í˜•ë„ í‰ê°€
3. ì´ë¯¸ì§€ í’ˆì§ˆ ë° ì í•©ì„± í™•ì¸
4. ì‹œê°ì  ì¼ê´€ì„± ê²€í† 
5. ë ˆì´ì•„ì›ƒ ìµœì í™” ì œì•ˆ

**ì¶œë ¥ í˜•ì‹:**
í…œí”Œë¦¿ë³„ë¡œ ë‹¤ìŒ ì •ë³´ í¬í•¨:
- ì´ë¯¸ì§€ ëª©ë¡ ë° ì„¤ëª…
- ë°°ì¹˜ ê¶Œì¥ì‚¬í•­
- ì‹œê°ì  íš¨ê³¼ ì˜ˆì¸¡""",
            expected_output="ì‹¤ì œ ì´ë¯¸ì§€ ë°ì´í„° ê¸°ë°˜ ë°°ì¹˜ ë¶„ì„ ë° ìµœì í™” ê²°ê³¼",
            agent=self.image_analyzer_agent
        )

    def _create_enhanced_coordination_task(self, extracted_text_data: Dict, extracted_image_data: Dict) -> Task:
        """ê°•í™”ëœ í†µí•© ì¡°ìœ¨ íƒœìŠ¤í¬ ìƒì„±"""
        return Task(
            description=f"""ì‹¤ì œ ì¶”ì¶œëœ í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ í†µí•©í•˜ì—¬ ì™„ë²½í•œ ë§¤ê±°ì§„ êµ¬ì¡°ë¥¼ ìƒì„±í•˜ì„¸ìš”.

**í…ìŠ¤íŠ¸ ë°ì´í„° ìš”ì•½:**
- ì„¹ì…˜ ìˆ˜: {len(extracted_text_data['sections'])}ê°œ
- ì´ ê¸¸ì´: {extracted_text_data['total_content_length']} ë¬¸ì

**ì´ë¯¸ì§€ ë°ì´í„° ìš”ì•½:**
- ì´ ì´ë¯¸ì§€: {extracted_image_data['total_images']}ê°œ
- í…œí”Œë¦¿ ìˆ˜: {len(extracted_image_data['template_images'])}ê°œ

**í†µí•© ìš”êµ¬ì‚¬í•­:**
1. í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ì˜ ì™„ë²½í•œ ë§¤ì¹­
2. ê° ì„¹ì…˜ë³„ ìµœì  í…œí”Œë¦¿ ì„ íƒ
3. ì½˜í…ì¸  í’ˆì§ˆ ë³´ì¥
4. ì‹œê°ì  ì¼ê´€ì„± ìœ ì§€
5. JSX êµ¬í˜„ì„ ìœ„í•œ ì™„ì „í•œ ìŠ¤í™ ìƒì„±

**ìµœì¢… ì¶œë ¥ êµ¬ì¡°:**
{{
"selected_templates": ["í…œí”Œë¦¿ ëª©ë¡"],
"content_sections": [
{{
"template": "í…œí”Œë¦¿ëª…",
"title": "ì‹¤ì œ ì œëª©",
"subtitle": "ì‹¤ì œ ë¶€ì œëª©",
"body": "ì‹¤ì œ ë³¸ë¬¸ ë‚´ìš©",
"tagline": "íƒœê·¸ë¼ì¸",
"images": ["ì‹¤ì œ ì´ë¯¸ì§€ URLë“¤"],
"metadata": {{
"content_quality": "í’ˆì§ˆ ì ìˆ˜",
"image_count": "ì´ë¯¸ì§€ ìˆ˜",
"source": "ë°ì´í„° ì†ŒìŠ¤"
}}
}}
],
"integration_metadata": {{
"total_sections": "ì„¹ì…˜ ìˆ˜",
"integration_quality_score": "í’ˆì§ˆ ì ìˆ˜"
}}
}}

ì´ì „ íƒœìŠ¤í¬ë“¤ì˜ ë¶„ì„ ê²°ê³¼ë¥¼ í™œìš©í•˜ì—¬ ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ì˜ ê³ í’ˆì§ˆ ë§¤ê±°ì§„ êµ¬ì¡°ë¥¼ ì™„ì„±í•˜ì„¸ìš”.""",
            expected_output="ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ ì™„ì„±ëœ ë§¤ê±°ì§„ êµ¬ì¡° JSON",
            agent=self.crew_agent,
            context=[self._create_enhanced_text_analysis_task(extracted_text_data, []),
                    self._create_enhanced_image_analysis_task(extracted_image_data, [])]
        )

    def _create_enhanced_structure(self, extracted_text_data: Dict, extracted_image_data: Dict,
                                 org_results: List[Dict], binding_results: List[Dict]) -> Dict:
        """ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ ê°•í™”ëœ êµ¬ì¡° ìƒì„±"""
        content_sections = []

        # ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ì„¹ì…˜ í™œìš©
        for i, section in enumerate(extracted_text_data['sections']):
            template = section.get('template', f'Section{i+1:02d}.jsx')

            # í•´ë‹¹ í…œí”Œë¦¿ì˜ ì‹¤ì œ ì´ë¯¸ì§€ ê°€ì ¸ì˜¤ê¸°
            template_images = extracted_image_data['template_images'].get(template, [])

            # ì´ë¯¸ì§€ê°€ ì—†ìœ¼ë©´ ë‹¤ë¥¸ í…œí”Œë¦¿ì˜ ì´ë¯¸ì§€ ì‚¬ìš©
            if not template_images:
                for temp_name, temp_images in extracted_image_data['template_images'].items():
                    if temp_images:
                        template_images = temp_images[:2]  # ìµœëŒ€ 2ê°œ
                        break

            enhanced_section = {
                'template': template,
                'title': section.get('title', 'ì—¬í–‰ ì´ì•¼ê¸°'),
                'subtitle': section.get('subtitle', 'íŠ¹ë³„í•œ ìˆœê°„ë“¤'),
                'body': section.get('body', 'ì—¬í–‰ì˜ íŠ¹ë³„í•œ ìˆœê°„ë“¤ì„ ë‹´ì€ ì´ì•¼ê¸°ì…ë‹ˆë‹¤.'),
                'tagline': section.get('tagline', 'TRAVEL & CULTURE'),
                'images': template_images,
                'metadata': {
                    "agent_enhanced": True,
                    "real_content": True,
                    "real_images": len(template_images) > 0,
                    "content_source": section.get('layout_source', 'extracted'),
                    "content_length": len(section.get('body', '')),
                    "image_count": len(template_images),
                    "quality_verified": True
                }
            }
            content_sections.append(enhanced_section)

        # ìµœì†Œ 1ê°œ ì„¹ì…˜ ë³´ì¥
        if not content_sections:
            # ì‹¤ì œ ì´ë¯¸ì§€ê°€ ìˆìœ¼ë©´ ì‚¬ìš©
            fallback_images = []
            for template_images in extracted_image_data['template_images'].values():
                fallback_images.extend(template_images[:2])
                if len(fallback_images) >= 2:
                    break

            content_sections = [{
                'template': 'Section01.jsx',
                'title': 'ì—¬í–‰ ë§¤ê±°ì§„',
                'subtitle': 'íŠ¹ë³„í•œ ì´ì•¼ê¸°',
                'body': 'ì—¬í–‰ì˜ íŠ¹ë³„í•œ ìˆœê°„ë“¤ì„ ë‹´ì€ ë§¤ê±°ì§„ì…ë‹ˆë‹¤. ì•„ë¦„ë‹¤ìš´ í’ê²½ê³¼ í•¨ê»˜í•˜ëŠ” íŠ¹ë³„í•œ ê²½í—˜ì„ ê³µìœ í•©ë‹ˆë‹¤.',
                'tagline': 'TRAVEL & CULTURE',
                'images': fallback_images,
                'metadata': {
                    "agent_enhanced": True,
                    "fallback_content": True,
                    "real_images": len(fallback_images) > 0,
                    "image_count": len(fallback_images)
                }
            }]

        return {
            "selected_templates": [section.get("template", f"Section{i+1:02d}.jsx") for i, section in enumerate(content_sections)],
            "content_sections": content_sections
        }

    def _enhance_parsed_data_with_real_images(self, parsed_data: Dict, extracted_image_data: Dict) -> Dict:
        """íŒŒì‹±ëœ ë°ì´í„°ì— ì‹¤ì œ ì´ë¯¸ì§€ ì¶”ê°€"""
        if 'content_sections' in parsed_data:
            for section in parsed_data['content_sections']:
                template = section.get('template', 'Section01.jsx')

                # ì‹¤ì œ ì´ë¯¸ì§€ë¡œ êµì²´
                real_images = extracted_image_data['template_images'].get(template, [])
                if real_images:
                    section['images'] = real_images
                elif extracted_image_data['total_images'] > 0:
                    # ë‹¤ë¥¸ í…œí”Œë¦¿ì˜ ì´ë¯¸ì§€ ì‚¬ìš©
                    for temp_images in extracted_image_data['template_images'].values():
                        if temp_images:
                            section['images'] = temp_images[:2]
                            break

                # ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸
                if 'metadata' not in section:
                    section['metadata'] = {}
                section['metadata'].update({
                    "real_images_used": len(section.get('images', [])) > 0,
                    "image_count": len(section.get('images', []))
                })

        return parsed_data

    # ëª¨ë“  ê¸°ì¡´ ìœ í‹¸ë¦¬í‹° ë©”ì„œë“œë“¤ ìœ ì§€
    def _split_content_into_sections(self, content: str) -> List[str]:
        """ì½˜í…ì¸ ë¥¼ ì„¹ì…˜ë³„ë¡œ ë¶„í• """
        sections = []

        # === íŒ¨í„´ìœ¼ë¡œ ë¶„í• 
        if '===' in content:
            parts = content.split('===')
            for part in parts:
                clean_part = part.strip()
                if len(clean_part) > 100:
                    sections.append(clean_part)
        # ë¬¸ë‹¨ ê¸°ë°˜ ë¶„í• 
        elif '\n\n' in content:
            paragraphs = content.split('\n\n')
            current_section = ""
            for paragraph in paragraphs:
                if len(current_section + paragraph) > 800:
                    if current_section:
                        sections.append(current_section.strip())
                    current_section = paragraph
                else:
                    current_section += "\n\n" + paragraph
            if current_section:
                sections.append(current_section.strip())
        # ì „ì²´ë¥¼ í•˜ë‚˜ì˜ ì„¹ì…˜ìœ¼ë¡œ
        else:
            sections = [content]

        return [s for s in sections if len(s) > 50]

    def _extract_title_from_content(self, content: str) -> str:
        """ì½˜í…ì¸ ì—ì„œ ì œëª© ì¶”ì¶œ"""
        lines = content.split('\n')
        for line in lines[:3]:  # ì²˜ìŒ 3ì¤„ì—ì„œ ì°¾ê¸°
            line = line.strip()
            if line and len(line) < 100:
                # ì œëª© íŒ¨í„´ ì •ë¦¬
                title = re.sub(r'^[#\*\-\s]+', '', line)
                title = re.sub(r'[#\*\-\s]+$', '', title)
                if len(title) > 5:
                    return title[:50]
        return "ì—¬í–‰ ì´ì•¼ê¸°"

    def _extract_subtitle_from_content(self, content: str) -> str:
        """ì½˜í…ì¸ ì—ì„œ ë¶€ì œëª© ì¶”ì¶œ"""
        lines = content.split('\n')
        for i, line in enumerate(lines[1:4]):  # 2-4ë²ˆì§¸ ì¤„ì—ì„œ ì°¾ê¸°
            line = line.strip()
            if line and len(line) < 80 and len(line) > 5:
                subtitle = re.sub(r'^[#\*\-\s]+', '', line)
                subtitle = re.sub(r'[#\*\-\s]+$', '', subtitle)
                if len(subtitle) > 3:
                    return subtitle[:40]
        return "íŠ¹ë³„í•œ ìˆœê°„ë“¤"

    def _clean_content(self, content: str) -> str:
        """ì½˜í…ì¸  ì •ë¦¬"""
        # ë¶ˆí•„ìš”í•œ íŒ¨í„´ ì œê±°
        cleaned = re.sub(r'^[#\*\-\s]+', '', content, flags=re.MULTILINE)
        # ì—°ì†ëœ ì¤„ë°”ê¿ˆ ì •ë¦¬
        cleaned = re.sub(r'\n{3,}', '\n\n', cleaned)
        # ë¹ˆ ì¤„ ì œê±°
        cleaned = re.sub(r'^\s*$\n', '', cleaned, flags=re.MULTILINE)
        return cleaned.strip()

    def _extract_structured_content(self, text: str) -> List[Dict]:
        """êµ¬ì¡°í™”ëœ ì½˜í…ì¸  ì¶”ì¶œ"""
        sections = []
        
        # ì œëª© íŒ¨í„´ ì°¾ê¸°
        title_patterns = [
            r'ì œëª©[:\s]*([^\n]+)',
            r'title[:\s]*([^\n]+)',
            r'## ([^\n]+)',
            r'# ([^\n]+)'
        ]
        
        for pattern in title_patterns:
            matches = re.finditer(pattern, text, re.IGNORECASE)
            for match in matches:
                title = match.group(1).strip()
                if len(title) > 3:
                    section = {
                        "template": f"Section{len(sections)+1:02d}.jsx",
                        "title": title[:50],
                        "subtitle": "ì—¬í–‰ì˜ íŠ¹ë³„í•œ ìˆœê°„",
                        "body": f"{title}ì— ëŒ€í•œ ìì„¸í•œ ì´ì•¼ê¸°ë¥¼ ë‹´ê³  ìˆìŠµë‹ˆë‹¤.",
                        "tagline": "TRAVEL & CULTURE",
                        "layout_source": "org_agent"
                    }
                    sections.append(section)
                    if len(sections) >= 3:
                        break
            if sections:
                break
        
        return sections

    def _extract_template_from_binding_result(self, result: Dict) -> str:
        """BindingAgent ê²°ê³¼ì—ì„œ í…œí”Œë¦¿ëª… ì¶”ì¶œ"""
        task_description = result.get('task_description', '')
        template_match = re.search(r'Section\d+\.jsx', task_description)
        return template_match.group() if template_match else "Section01.jsx"

    def _extract_image_source_info(self, result: Dict, url: str) -> Dict:
        """ì´ë¯¸ì§€ ì†ŒìŠ¤ ì •ë³´ ì¶”ì¶œ"""
        return {
            "url": url,
            "template": self._extract_template_from_binding_result(result),
            "source": "binding_agent",
            "timestamp": result.get('timestamp', ''),
            "quality_verified": True
        }

    def _format_sections_for_analysis(self, sections: List[Dict]) -> str:
        """ë¶„ì„ìš© ì„¹ì…˜ í¬ë§·íŒ…"""
        formatted = []
        for i, section in enumerate(sections[:3]):  # ìµœëŒ€ 3ê°œë§Œ í‘œì‹œ
            formatted.append(f"""ì„¹ì…˜ {i+1}:
- í…œí”Œë¦¿: {section.get('template', 'N/A')}
- ì œëª©: {section.get('title', 'N/A')}
- ë¶€ì œëª©: {section.get('subtitle', 'N/A')}
- ë³¸ë¬¸ ê¸¸ì´: {len(section.get('body', ''))} ë¬¸ì
- ì†ŒìŠ¤: {section.get('layout_source', 'N/A')}""")
        return "\n".join(formatted)

    def _format_images_for_analysis(self, template_images: Dict) -> str:
        """ë¶„ì„ìš© ì´ë¯¸ì§€ í¬ë§·íŒ…"""
        formatted = []
        for template, images in template_images.items():
            formatted.append(f"""{template}: {len(images)}ê°œ ì´ë¯¸ì§€
{chr(10).join([f'  - {img}' for img in images[:2]])}""")
        return "\n".join(formatted)

    def _format_image_sources(self, image_sources: List[Dict]) -> str:
        """ì´ë¯¸ì§€ ì†ŒìŠ¤ ì •ë³´ í¬ë§·íŒ…"""
        if not image_sources:
            return "ì´ë¯¸ì§€ ì†ŒìŠ¤ ì •ë³´ ì—†ìŒ"
        
        formatted = []
        for source in image_sources[:3]:  # ìµœëŒ€ 3ê°œë§Œ í‘œì‹œ
            formatted.append(f"- {source.get('template', 'N/A')}: {source.get('url', 'N/A')}")
        return "\n".join(formatted)

    def _extract_json_from_text(self, text: str) -> Dict:
        """í…ìŠ¤íŠ¸ì—ì„œ JSON ì¶”ì¶œ"""
        json_pattern = r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}'
        parsed_data = {}
        
        matches = re.findall(json_pattern, text, re.DOTALL)
        for match in matches:
            try:
                if len(match) < 10000:  # ë„ˆë¬´ í° JSON ì œì™¸
                    data = json.loads(match)
                    if isinstance(data, dict):
                        parsed_data.update(data)
            except json.JSONDecodeError:
                continue
        
        return parsed_data

    async def _log_coordination_result_async(self, final_result: Dict, text_mapping: Dict, 
                                           image_distribution: Dict, org_results: List[Dict], 
                                           binding_results: List[Dict]) -> None:
        """ì¡°ìœ¨ ê²°ê³¼ ë¡œê¹… (ë¹„ë™ê¸°)"""
        await asyncio.get_event_loop().run_in_executor(
            None,
            lambda: self.logger.log_agent_real_output(
                agent_name="CoordinatorAgent",
                agent_role="í†µí•© ì¡°ìœ¨ì (CrewAI ê¸°ë°˜ ê°•í™”ëœ ë°ì´í„° ì ‘ê·¼ ë° JSON íŒŒì‹±)",
                task_description=f"ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ ë°°ì¹˜ ë§¤ê±°ì§„ êµ¬ì¡° í†µí•© ì¡°ìœ¨: {len(final_result.get('content_sections', []))}ê°œ ì„¹ì…˜ ìƒì„±",
                final_answer=str(final_result),
                reasoning_process=f"ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ ë°°ì¹˜ ì²˜ë¦¬ë¡œ {len(org_results)}ê°œ OrgAgent ê²°ê³¼ì™€ {len(binding_results)}ê°œ BindingAgent ê²°ê³¼ í†µí•©",
                execution_steps=[
                    "ì¬ê·€ ê¹Šì´ ì²´í¬",
                    "ë°°ì¹˜ ê¸°ë°˜ ì²˜ë¦¬ ëª¨ë“œ ì„ íƒ",
                    "ì´ì „ ê²°ê³¼ ìˆ˜ì§‘",
                    "ì‹¤ì œ ë°ì´í„° ì¶”ì¶œ",
                    "CrewAI ì•ˆì „ ì‹¤í–‰",
                    "ê²°ê³¼ í†µí•© ë° ê²€ì¦"
                ],
                raw_input={
                    "text_mapping": str(text_mapping)[:500],
                    "image_distribution": str(image_distribution)[:500]
                },
                raw_output=final_result,
                performance_metrics={
                    "total_sections_generated": len(final_result.get('content_sections', [])),
                    "org_results_utilized": len(org_results),
                    "binding_results_utilized": len(binding_results),
                    "real_data_extraction": True,
                    "crewai_enhanced": True,
                    "batch_processing": True,
                    "safe_execution": True,
                    "integration_quality_score": final_result.get('integration_metadata', {}).get('integration_quality_score', 0.8)
                }
            )
        )

    def _calculate_enhanced_quality_score(self, content_sections: List[Dict], org_count: int, binding_count: int) -> float:
        """ê°•í™”ëœ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°"""
        base_score = 0.5
        
        # ì„¹ì…˜ ìˆ˜ì— ë”°ë¥¸ ì ìˆ˜
        if len(content_sections) >= 3:
            base_score += 0.2
        elif len(content_sections) >= 1:
            base_score += 0.1
        
        # ì‹¤ì œ ì½˜í…ì¸  í’ˆì§ˆ
        for section in content_sections:
            if len(section.get('body', '')) > 100:
                base_score += 0.05
            if section.get('images'):
                base_score += 0.05
            if section.get('metadata', {}).get('real_content'):
                base_score += 0.05
        
        # ì—ì´ì „íŠ¸ ê²°ê³¼ í™œìš©ë„
        if org_count > 0:
            base_score += 0.1
        if binding_count > 0:
            base_score += 0.1
        
        return min(base_score, 1.0)

    def _filter_agent_results(self, results: List[Dict], agent_name: str) -> List[Dict]:
        """íŠ¹ì • ì—ì´ì „íŠ¸ ê²°ê³¼ í•„í„°ë§"""
        filtered = []
        for result in results:
            if isinstance(result, dict):
                result_agent = result.get('agent_name', '')
                if agent_name.lower() in result_agent.lower():
                    filtered.append(result)
        return filtered

    def _deduplicate_results(self, results: List[Dict]) -> List[Dict]:
        """ê²°ê³¼ ì¤‘ë³µ ì œê±°"""
        seen = set()
        unique_results = []
        
        for result in results:
            if isinstance(result, dict):
                # ê³ ìœ  í‚¤ ìƒì„±
                key = f"{result.get('agent_name', '')}_{result.get('timestamp', '')}_{len(str(result.get('final_answer', '')))}"
                if key not in seen:
                    seen.add(key)
                    unique_results.append(result)
        
        return unique_results

    def _load_results_from_file(self) -> List[Dict]:
        """íŒŒì¼ì—ì„œ ê²°ê³¼ ë¡œë“œ"""
        try:
            # ë¡œê·¸ íŒŒì¼ë“¤ì—ì„œ ê²°ê³¼ ìˆ˜ì§‘
            log_files = [
                "logs/agent_responses.json",
                "logs/org_agent_responses.json",
                "logs/binding_agent_responses.json",
                "logs/coordinator_responses.json"
            ]
            
            all_results = []
            for file_path in log_files:
                if os.path.exists(file_path):
                    with open(file_path, 'r', encoding='utf-8') as f:
                        try:
                            file_data = json.load(f)
                            if isinstance(file_data, list):
                                all_results.extend(file_data)
                            elif isinstance(file_data, dict):
                                all_results.append(file_data)
                        except json.JSONDecodeError:
                            continue
            
            return all_results
        except Exception as e:
            print(f"âš ï¸ íŒŒì¼ì—ì„œ ê²°ê³¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return []

    def _validate_coordinator_result(self, result: Dict) -> bool:
        """CoordinatorAgent ê²°ê³¼ ê²€ì¦"""
        if not isinstance(result, dict):
            return False
        
        required_fields = ["content_sections", "selected_templates"]
        for field in required_fields:
            if field not in result:
                return False
        
        content_sections = result.get("content_sections", [])
        if not isinstance(content_sections, list) or len(content_sections) == 0:
            return False
        
        for section in content_sections:
            if not isinstance(section, dict):
                return False
            required_section_fields = ["template", "title", "subtitle", "body", "tagline"]
            if not all(field in section for field in required_section_fields):
                return False
        
        return True

    # ê¸°ì¡´ ë™ê¸° ë²„ì „ ë©”ì„œë“œë“¤ ìœ ì§€ (í˜¸í™˜ì„± ë³´ì¥)
    def coordinate_magazine_creation_sync(self, text_mapping: Dict, image_distribution: Dict) -> Dict:
        """ë™ê¸° ë²„ì „ ë§¤ê±°ì§„ ì¡°ìœ¨ (í˜¸í™˜ì„± ìœ ì§€)"""
        return asyncio.run(self.coordinate_magazine_creation(text_mapping, image_distribution))

    def get_previous_results(self, agent_filter: str = None) -> List[Dict]:
        """ì´ì „ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸° (ë™ê¸° ë²„ì „)"""
        try:
            return self.logger.get_all_previous_results("CoordinatorAgent")
        except Exception as e:
            print(f"âš ï¸ ì´ì „ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
            return []

    def create_enhanced_magazine_structure(self, text_data: Dict, image_data: Dict) -> Dict:
        """ê°•í™”ëœ ë§¤ê±°ì§„ êµ¬ì¡° ìƒì„± (ë™ê¸° ë²„ì „)"""
        return self._create_enhanced_structure(text_data, image_data, [], [])

    def validate_magazine_structure(self, structure: Dict) -> bool:
        """ë§¤ê±°ì§„ êµ¬ì¡° ìœ íš¨ì„± ê²€ì¦"""
        try:
            # í•„ìˆ˜ í•„ë“œ í™•ì¸
            if not isinstance(structure, dict):
                return False
            
            if 'content_sections' not in structure:
                return False
            
            content_sections = structure['content_sections']
            if not isinstance(content_sections, list) or len(content_sections) == 0:
                return False
            
            # ê° ì„¹ì…˜ ìœ íš¨ì„± í™•ì¸
            for section in content_sections:
                if not isinstance(section, dict):
                    return False
                
                required_fields = ['template', 'title', 'subtitle', 'body', 'tagline']
                for field in required_fields:
                    if field not in section:
                        return False
                    if not isinstance(section[field], str):
                        return False
                
                # ì´ë¯¸ì§€ í•„ë“œ í™•ì¸ (ì„ íƒì )
                if 'images' in section:
                    if not isinstance(section['images'], list):
                        return False
            
            return True
            
        except Exception as e:
            print(f"âš ï¸ êµ¬ì¡° ìœ íš¨ì„± ê²€ì¦ ì‹¤íŒ¨: {e}")
            return False

    def get_structure_statistics(self, structure: Dict) -> Dict:
        """êµ¬ì¡° í†µê³„ ì •ë³´ ìƒì„±"""
        try:
            stats = {
                "total_sections": 0,
                "total_templates": 0,
                "total_images": 0,
                "total_content_length": 0,
                "average_content_length": 0,
                "sections_with_images": 0,
                "unique_templates": set(),
                "quality_indicators": {
                    "has_real_content": False,
                    "has_real_images": False,
                    "structure_complete": False
                }
            }
            
            if not isinstance(structure, dict) or 'content_sections' not in structure:
                return stats
            
            content_sections = structure['content_sections']
            if not isinstance(content_sections, list):
                return stats
            
            stats["total_sections"] = len(content_sections)
            
            total_length = 0
            for section in content_sections:
                if isinstance(section, dict):
                    # í…œí”Œë¦¿ ìˆ˜ì§‘
                    template = section.get('template', '')
                    if template:
                        stats["unique_templates"].add(template)
                    
                    # ì½˜í…ì¸  ê¸¸ì´
                    body = section.get('body', '')
                    if isinstance(body, str):
                        total_length += len(body)
                    
                    # ì´ë¯¸ì§€ ìˆ˜
                    images = section.get('images', [])
                    if isinstance(images, list):
                        stats["total_images"] += len(images)
                        if len(images) > 0:
                            stats["sections_with_images"] += 1
                    
                    # í’ˆì§ˆ ì§€í‘œ
                    metadata = section.get('metadata', {})
                    if isinstance(metadata, dict):
                        if metadata.get('real_content'):
                            stats["quality_indicators"]["has_real_content"] = True
                        if metadata.get('real_images_used'):
                            stats["quality_indicators"]["has_real_images"] = True
            
            stats["total_templates"] = len(stats["unique_templates"])
            stats["unique_templates"] = list(stats["unique_templates"])
            stats["total_content_length"] = total_length
            stats["average_content_length"] = total_length / max(stats["total_sections"], 1)
            
            # êµ¬ì¡° ì™„ì„±ë„
            stats["quality_indicators"]["structure_complete"] = (
                stats["total_sections"] > 0 and
                stats["total_content_length"] > 100 and
                stats["total_templates"] > 0
            )
            
            return stats
            
        except Exception as e:
            print(f"âš ï¸ êµ¬ì¡° í†µê³„ ìƒì„± ì‹¤íŒ¨: {e}")
            return {"error": str(e)}

    def export_structure_to_json(self, structure: Dict, file_path: str = None) -> str:
        """êµ¬ì¡°ë¥¼ JSON íŒŒì¼ë¡œ ë‚´ë³´ë‚´ê¸°"""
        try:
            if file_path is None:
                file_path = f"magazine_structure_{int(time.time())}.json"
            
            # ë””ë ‰í† ë¦¬ ìƒì„±
            os.makedirs(os.path.dirname(file_path) if os.path.dirname(file_path) else ".", exist_ok=True)
            
            # JSON ì €ì¥
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(structure, f, ensure_ascii=False, indent=2)
            
            print(f"âœ… ë§¤ê±°ì§„ êµ¬ì¡°ê°€ {file_path}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
            return file_path
            
        except Exception as e:
            print(f"âš ï¸ JSON ë‚´ë³´ë‚´ê¸° ì‹¤íŒ¨: {e}")
            return ""

    def import_structure_from_json(self, file_path: str) -> Dict:
        """JSON íŒŒì¼ì—ì„œ êµ¬ì¡° ê°€ì ¸ì˜¤ê¸°"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                structure = json.load(f)
            
            if self.validate_magazine_structure(structure):
                print(f"âœ… ë§¤ê±°ì§„ êµ¬ì¡°ê°€ {file_path}ì—ì„œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
                return structure
            else:
                print(f"âš ï¸ ìœ íš¨í•˜ì§€ ì•Šì€ ë§¤ê±°ì§„ êµ¬ì¡°: {file_path}")
                return {}
                
        except Exception as e:
            print(f"âš ï¸ JSON ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
            return {}

    # ë””ë²„ê¹… ë° ëª¨ë‹ˆí„°ë§ ë©”ì„œë“œ
    def debug_agent_results(self, results: List[Dict]) -> None:
        """ì—ì´ì „íŠ¸ ê²°ê³¼ ë””ë²„ê¹…"""
        print("=== ì—ì´ì „íŠ¸ ê²°ê³¼ ë””ë²„ê¹… ===")
        
        agent_counts = {}
        for result in results:
            agent_name = result.get('agent_name', 'Unknown')
            agent_counts[agent_name] = agent_counts.get(agent_name, 0) + 1
        
        print(f"ì´ ê²°ê³¼ ìˆ˜: {len(results)}")
        for agent, count in agent_counts.items():
            print(f"- {agent}: {count}ê°œ")
        
        # ìµœê·¼ ê²°ê³¼ ìƒ˜í”Œ
        print("\n=== ìµœê·¼ ê²°ê³¼ ìƒ˜í”Œ ===")
        for i, result in enumerate(results[-3:]):
            print(f"ê²°ê³¼ {i+1}:")
            print(f"  ì—ì´ì „íŠ¸: {result.get('agent_name', 'N/A')}")
            print(f"  ì‹œê°„: {result.get('timestamp', 'N/A')}")
            print(f"  ì‘ë‹µ ê¸¸ì´: {len(str(result.get('final_answer', '')))}")
            print(f"  ì‘ì—…: {result.get('task_description', 'N/A')[:100]}...")
            print()

    def monitor_system_health(self) -> Dict:
        """ì‹œìŠ¤í…œ ê±´ê°• ìƒíƒœ ëª¨ë‹ˆí„°ë§"""
        health_status = {
            "circuit_breaker_state": self.circuit_breaker.state,
            "failure_count": self.circuit_breaker.failure_count,
            "work_queue_size": len(self.work_queue.work_queue),
            "active_tasks": len(self.work_queue.active_tasks),
            "recursion_fallback_active": self.fallback_to_sync,
            "last_execution_mode": "unknown",
            "system_status": "healthy"
        }
        
        # ê±´ê°• ìƒíƒœ í‰ê°€
        if self.circuit_breaker.state == "OPEN":
            health_status["system_status"] = "degraded"
        elif self.fallback_to_sync:
            health_status["system_status"] = "fallback_mode"
        elif len(self.work_queue.work_queue) > 10:
            health_status["system_status"] = "high_load"
        
        return health_status

    def reset_system_state(self) -> None:
        """ì‹œìŠ¤í…œ ìƒíƒœ ë¦¬ì…‹"""
        print("ğŸ”„ CoordinatorAgent ì‹œìŠ¤í…œ ìƒíƒœ ë¦¬ì…‹")
        
        # Circuit Breaker ë¦¬ì…‹
        self.circuit_breaker.failure_count = 0
        self.circuit_breaker.state = "CLOSED"
        self.circuit_breaker.last_failure_time = None
        
        # í´ë°± í”Œë˜ê·¸ ë¦¬ì…‹
        self.fallback_to_sync = False
        
        # ì‘ì—… í í´ë¦¬ì–´
        self.work_queue.work_queue.clear()
        self.work_queue.active_tasks.clear()
        self.work_queue.results.clear()
        
        # í†µê³„ ì´ˆê¸°í™”
        self.execution_stats = {
            "total_attempts": 0,
            "successful_executions": 0,
            "fallback_used": 0,
            "circuit_breaker_triggered": 0,
            "timeout_occurred": 0
        }
        
        print("âœ… ì‹œìŠ¤í…œ ìƒíƒœê°€ ë¦¬ì…‹ë˜ì—ˆìŠµë‹ˆë‹¤.")

    def get_performance_metrics(self) -> Dict:
        """ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìˆ˜ì§‘"""
        metrics = {
            "circuit_breaker": {
                "state": self.circuit_breaker.state,
                "failure_count": self.circuit_breaker.failure_count,
                "failure_threshold": self.circuit_breaker.failure_threshold
            },
            "work_queue": {
                "max_workers": self.work_queue.max_workers,
                "queue_size": len(self.work_queue.work_queue),
                "active_tasks": len(self.work_queue.active_tasks),
                "completed_results": len(self.work_queue.results)
            },
            "system": {
                "recursion_threshold": self.recursion_threshold,
                "fallback_to_sync": self.fallback_to_sync,
                "batch_size": self.batch_size
            }
        }
        
        if hasattr(self, 'execution_stats'):
            metrics["execution_stats"] = self.execution_stats
        
        return metrics

    def get_execution_statistics(self) -> Dict:
        """ì‹¤í–‰ í†µê³„ ì¡°íšŒ"""
        return {
            **self.execution_stats,
            "success_rate": (
                self.execution_stats["successful_executions"] / 
                max(self.execution_stats["total_attempts"], 1)
            ) * 100,
            "circuit_breaker_state": self.circuit_breaker.state,
            "current_queue_size": len(self.work_queue.work_queue)
        }

    def validate_system_integrity(self) -> bool:
        """ì‹œìŠ¤í…œ ë¬´ê²°ì„± ê²€ì¦"""
        try:
            # í•„ìˆ˜ ì»´í¬ë„ŒíŠ¸ í™•ì¸
            required_components = [
                self.llm,
                self.logger,
                self.crew_agent,
                self.text_analyzer_agent,
                self.image_analyzer_agent
            ]
            
            for component in required_components:
                if component is None:
                    return False
            
            # ë³µì›ë ¥ ì‹œìŠ¤í…œ í™•ì¸
            if self.work_queue is None or self.circuit_breaker is None:
                return False
            
            return True
            
        except Exception as e:
            print(f"âš ï¸ ì‹œìŠ¤í…œ ë¬´ê²°ì„± ê²€ì¦ ì‹¤íŒ¨: {e}")
            return False

    def get_system_info(self) -> Dict:
        """ì‹œìŠ¤í…œ ì •ë³´ ì¡°íšŒ"""
        return {
            "class_name": self.__class__.__name__,
            "version": "2.0_batch_resilient",
            "features": [
                "CrewAI ê¸°ë°˜ ê°•í™”ëœ ë°ì´í„° ì ‘ê·¼",
                "JSON íŒŒì‹± ë° êµ¬ì¡° ìƒì„±",
                "ë¹„ë™ê¸° ë°°ì¹˜ ì²˜ë¦¬",
                "Circuit Breaker íŒ¨í„´",
                "ì¬ê·€ ê¹Šì´ ê°ì§€ ë° í´ë°±",
                "ì•ˆì „í•œ ì—ì´ì „íŠ¸ ì‹¤í–‰",
                "ë³µì›ë ¥ ìˆëŠ” ì‘ì—… í"
            ],
            "agents": {
                "crew_agent": "ë§¤ê±°ì§„ êµ¬ì¡° í†µí•© ì¡°ìœ¨ì",
                "text_analyzer_agent": "í…ìŠ¤íŠ¸ ë§¤í•‘ ë¶„ì„ ì „ë¬¸ê°€",
                "image_analyzer_agent": "ì´ë¯¸ì§€ ë¶„ë°° ë¶„ì„ ì „ë¬¸ê°€"
            },
            "execution_modes": ["batch_async", "sync_fallback"],
            "safety_features": [
                "ì¬ê·€ ê¹Šì´ ëª¨ë‹ˆí„°ë§",
                "íƒ€ì„ì•„ì›ƒ ì²˜ë¦¬",
                "Circuit Breaker",
                "ì ì§„ì  ë°±ì˜¤í”„",
                "í´ë°± ë©”ì»¤ë‹ˆì¦˜"
            ]
        }
