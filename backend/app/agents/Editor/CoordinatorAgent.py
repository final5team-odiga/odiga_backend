import asyncio
import sys
import time
import concurrent.futures
from typing import Dict, List, Optional, Callable, Any
from collections import deque
from dataclasses import dataclass
import os
import json
import re
from crewai import Agent, Task, Crew, Process
from custom_llm import get_azure_llm
from utils.agent_decision_logger import get_agent_logger

@dataclass
class WorkItem:
    id: str
    task_func: Callable
    args: tuple
    kwargs: dict
    priority: int = 0
    max_retries: int = 3
    current_retry: int = 0
    timeout: float = 300.0

class AsyncWorkQueue:
    def __init__(self, max_workers: int = 2, max_queue_size: int = 50):
        self.max_workers = max_workers
        self.max_queue_size = max_queue_size
        self.work_queue = deque()
        self.active_tasks = {}
        self.results = {}
        self.semaphore = asyncio.Semaphore(max_workers)
        self.executor = concurrent.futures.ThreadPoolExecutor(max_workers=max_workers)

    async def add_work(self, work_item: WorkItem) -> str:
        """ì‘ì—…ì„ íì— ì¶”ê°€"""
        if len(self.work_queue) >= self.max_queue_size:
            old_item = self.work_queue.popleft()
            print(f"âš ï¸ í ìš©ëŸ‰ ì´ˆê³¼ë¡œ ì‘ì—… {old_item.id} ì œê±°")
        
        self.work_queue.append(work_item)
        return work_item.id

    async def process_work_item(self, work_item: WorkItem) -> Optional[Any]:
        """ê°œë³„ ì‘ì—… ì²˜ë¦¬"""
        async with self.semaphore:
            try:
                print(f"ğŸ”„ ì‘ì—… {work_item.id} ì‹œì‘ (ì‹œë„ {work_item.current_retry + 1}/{work_item.max_retries + 1})")
                
                # ìˆ˜ì •: ì½”ë£¨í‹´ ê°ì²´ì™€ ì½”ë£¨í‹´ í•¨ìˆ˜ êµ¬ë¶„
                if asyncio.iscoroutine(work_item.task_func):
                    result = await asyncio.wait_for(work_item.task_func, timeout=work_item.timeout)
                elif asyncio.iscoroutinefunction(work_item.task_func):
                    result = await asyncio.wait_for(
                        work_item.task_func(*work_item.args, **work_item.kwargs),
                        timeout=work_item.timeout
                    )
                else:
                    result = await asyncio.wait_for(
                        asyncio.get_event_loop().run_in_executor(
                            self.executor,
                            lambda: work_item.task_func(*work_item.args, **work_item.kwargs)
                        ),
                        timeout=work_item.timeout
                    )
                
                self.results[work_item.id] = {"status": "success", "result": result}
                print(f"âœ… ì‘ì—… {work_item.id} ì™„ë£Œ")
                return result
                
            except asyncio.TimeoutError:
                print(f"â° ì‘ì—… {work_item.id} íƒ€ì„ì•„ì›ƒ ({work_item.timeout}ì´ˆ)")
                if work_item.current_retry < work_item.max_retries:
                    work_item.current_retry += 1
                    work_item.timeout *= 1.5
                    await self.add_work(work_item)
                else:
                    self.results[work_item.id] = {"status": "timeout", "error": "ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼"}
                return None
                
            except Exception as e:
                print(f"âŒ ì‘ì—… {work_item.id} ì‹¤íŒ¨: {e}")
                if work_item.current_retry < work_item.max_retries:
                    work_item.current_retry += 1
                    await self.add_work(work_item)
                else:
                    self.results[work_item.id] = {"status": "error", "error": str(e)}
                return None

    async def process_queue(self) -> dict:
        """íì˜ ëª¨ë“  ì‘ì—…ì„ ë°°ì¹˜ ì²˜ë¦¬"""
        tasks = []
        while self.work_queue:
            work_item = self.work_queue.popleft()
            task = asyncio.create_task(self.process_work_item(work_item))
            tasks.append(task)
            self.active_tasks[work_item.id] = task
        
        if tasks:
            await asyncio.gather(*tasks, return_exceptions=True)
        
        return self.results

class CircuitBreaker:
    def __init__(self, failure_threshold: int = 10, recovery_timeout: float = 120.0):
        self.failure_threshold = failure_threshold
        self.recovery_timeout = recovery_timeout
        self.failure_count = 0
        self.last_failure_time = None
        self.state = "CLOSED"  # CLOSED, OPEN, HALF_OPEN

    def is_open(self) -> bool:
        if self.state == "OPEN":
            if time.time() - self.last_failure_time > self.recovery_timeout:
                self.state = "HALF_OPEN"
                return False
            return True
        return False

    def record_success(self):
        self.failure_count = 0
        self.state = "CLOSED"

    def record_failure(self):
        self.failure_count += 1
        self.last_failure_time = time.time()
        if self.failure_count >= self.failure_threshold:
            self.state = "OPEN"





TIMEOUT_CONFIGS = {
    'org_agent': 900,      # 15ë¶„
    'binding_agent': 1200, # 20ë¶„  
    'coordinator_agent': 600, # 10ë¶„
    'vector_init': 600,    # 10ë¶„
    'crew_execution': 900  # 15ë¶„
}


class CoordinatorAgent:
    """í†µí•© ì¡°ìœ¨ì (CrewAI ê¸°ë°˜ ê°•í™”ëœ ë°ì´í„° ì ‘ê·¼ ë° JSON íŒŒì‹±)"""
    
    def __init__(self):
        self.llm = get_azure_llm()
        self.logger = get_agent_logger()
        self.crew_agent = self._create_crew_agent()
        self.text_analyzer_agent = self._create_text_analyzer_agent()
        self.image_analyzer_agent = self._create_image_analyzer_agent()
        
        # ìƒˆë¡œìš´ ë³µì›ë ¥ ì‹œìŠ¤í…œ ì¶”ê°€
        self.work_queue = AsyncWorkQueue(max_workers=1, max_queue_size=20)
        self.circuit_breaker = CircuitBreaker()
        self.recursion_threshold = 600
        self.fallback_to_sync = False
        self.batch_size = 2
        
        # ì‹¤í–‰ í†µê³„ ì¶”ê°€
        self.execution_stats = {
            "total_attempts": 0,
            "successful_executions": 0,
            "fallback_used": 0,
            "circuit_breaker_triggered": 0,
            "timeout_occurred": 0
        }

    def _check_recursion_depth(self):
        """í˜„ì¬ ì¬ê·€ ê¹Šì´ í™•ì¸"""
        frame = sys._getframe()
        depth = 0
        while frame:
            depth += 1
            frame = frame.f_back
        return depth

    def _should_use_sync(self):
        """ë™ê¸° ëª¨ë“œë¡œ ì „í™˜í• ì§€ íŒë‹¨"""
        current_depth = self._check_recursion_depth()
        if current_depth > self.recursion_threshold:
            print(f"âš ï¸ CoordinatorAgent ì¬ê·€ ê¹Šì´ {current_depth} ê°ì§€ - ë™ê¸° ëª¨ë“œë¡œ ì „í™˜")
            self.fallback_to_sync = True
            return True
        return self.fallback_to_sync



    async def execute_with_resilience(self, task_func: Callable, task_id: str,
                                    timeout: float = None, max_retries: int = 2,
                                    *args, **kwargs) -> Any:
        if timeout is None:
            for task_type, default_timeout in TIMEOUT_CONFIGS.items():
                if task_type in task_id.lower():
                    timeout = default_timeout
                    break
            else:
                timeout = 300

        # ì½”ë£¨í‹´ ê°ì²´ ì²˜ë¦¬ ê°œì„ 
        if asyncio.iscoroutine(task_func):
            try:
                result = await asyncio.wait_for(task_func, timeout=timeout)
                self.circuit_breaker.record_success()
                return result
            except Exception as e:
                print(f"âŒ Coroutine ì‹¤í–‰ ì‹¤íŒ¨: {e}")
                self.circuit_breaker.record_failure()
                return self._get_fallback_result(task_id)
        
        # ì½”ë£¨í‹´ í•¨ìˆ˜ì™€ ì¼ë°˜ í•¨ìˆ˜ êµ¬ë¶„ ì²˜ë¦¬
        if asyncio.iscoroutinefunction(task_func):
            coro = task_func(*args, **kwargs)
        else:
            # ì¼ë°˜ í•¨ìˆ˜ëŠ” executorì—ì„œ ì‹¤í–‰
            loop = asyncio.get_event_loop()
            coro = loop.run_in_executor(None, lambda: task_func(*args, **kwargs))
        
        # WorkItem ìƒì„± ì‹œ ì´ë¯¸ ìƒì„±ëœ ì½”ë£¨í‹´ ê°ì²´ ì „ë‹¬
        work_item = WorkItem(
            id=task_id,
            task_func=coro,  # ì½”ë£¨í‹´ ê°ì²´ ì§ì ‘ ì „ë‹¬
            args=(),  # ë¹ˆ íŠœí”Œ
            kwargs={},  # ë¹ˆ ë”•ì…”ë„ˆë¦¬
            timeout=timeout,
            max_retries=max_retries
        )

        
        await self.work_queue.add_work(work_item)
        
        # ìˆ˜ì •: íŠ¹ì • ì‘ì—…ì˜ ê²°ê³¼ë¥¼ ëª…í™•íˆ ë°˜í™˜
        processed_results = await self.work_queue.process_queue()
        result_info = processed_results.get(task_id)
        
        if result_info and result_info["status"] == "success":
            self.circuit_breaker.record_success()
            return result_info["result"]
        else:
            self.circuit_breaker.record_failure()
            # ì˜¤ë¥˜ ì •ë³´ ë¡œê¹…
            if result_info:
                print(f"âš ï¸ ì‘ì—… {task_id} ìµœì¢… ì‹¤íŒ¨: {result_info.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")
            else:
                print(f"âš ï¸ ì‘ì—… {task_id}ì˜ ê²°ê³¼ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ (í ì²˜ë¦¬ í›„).")
            return self._get_fallback_result(task_id)

    def _get_fallback_result(self, task_id: str) -> dict:
        """ê°œì„ ëœ í´ë°± ê²°ê³¼ ìƒì„±"""
        self.execution_stats["fallback_used"] += 1
        reason = task_id  # ê¸°ë³¸ì ìœ¼ë¡œ task_idë¥¼ reasonìœ¼ë¡œ ì‚¬ìš©
        
        if "_timeout" in task_id:
            reason = "timeout"
        elif "_exception" in task_id:
            reason = "exception"
        elif "_type_error" in task_id:
            reason = "type_error"
        
        return {
            "selected_templates": ["Section01.jsx"],
            "content_sections": [{
                "template": "Section01.jsx",
                "title": "ì—¬í–‰ ë§¤ê±°ì§„ (í´ë°±)",
                "subtitle": f"íŠ¹ë³„í•œ ì´ì•¼ê¸° ({reason})",
                "body": f"CoordinatorAgent ì²˜ë¦¬ ì¤‘ ë¬¸ì œ ë°œìƒ ({reason})ìœ¼ë¡œ ì¸í•œ í´ë°± ì½˜í…ì¸ ì…ë‹ˆë‹¤. Task ID: {task_id}",
                "tagline": "TRAVEL & CULTURE",
                "images": [],
                "metadata": {
                    "fallback_used": True,
                    "reason": reason,
                    "task_id": task_id
                }
            }],
            "integration_metadata": {
                "total_sections": 1,
                "integration_quality_score": 0.5,
                "fallback_mode": True
            }
        }

    def _create_crew_agent(self):
        """ë©”ì¸ ì¡°ìœ¨ ì—ì´ì „íŠ¸ ìƒì„±"""
        return Agent(
            role="ë§¤ê±°ì§„ êµ¬ì¡° í†µí•© ì¡°ìœ¨ì ë° ìµœì¢… í’ˆì§ˆ ë³´ì¦ ì „ë¬¸ê°€",
            goal="ContentCreatorV2Agentì˜ ì‹¤ì œ í…ìŠ¤íŠ¸ ë°ì´í„°ì™€ BindingAgentì˜ ì •ë°€ ì´ë¯¸ì§€ ë°°ì¹˜ë¥¼ í†µí•©í•˜ì—¬ ì™„ë²½í•œ ë§¤ê±°ì§„ êµ¬ì¡°ë¥¼ ìƒì„±í•˜ê³ , magazine_content.jsonì˜ ì„¹ì…˜ ìˆ˜ì— ë§ì¶° ìµœì í™”ëœ template_data.jsonì„ ì œê³µ",
            backstory="""ë‹¹ì‹ ì€ 25ë…„ê°„ ì„¸ê³„ ìµœê³  ìˆ˜ì¤€ì˜ ì¶œíŒì‚¬ì—ì„œ ë§¤ê±°ì§„ êµ¬ì¡° í†µí•© ë° í’ˆì§ˆ ë³´ì¦ ì±…ì„ìë¡œ í™œë™í•´ì˜¨ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. CondÃ© Nast, Hearst Corporation, Time Inc.ì—ì„œ ìˆ˜ë°± ê°œì˜ ë§¤ê±°ì§„ í”„ë¡œì íŠ¸ë¥¼ ì„±ê³µì ìœ¼ë¡œ ì¡°ìœ¨í–ˆìŠµë‹ˆë‹¤.

**ì „ë¬¸ ê²½ë ¥:**
- ì¶œíŒí•™ ë° êµ¬ì¡° ì„¤ê³„ ì„ì‚¬ í•™ìœ„ ë³´ìœ 
- PMP(Project Management Professional) ì¸ì¦
- ë§¤ê±°ì§„ êµ¬ì¡° í†µí•© ë° í’ˆì§ˆ ê´€ë¦¬ ì „ë¬¸ê°€
- í…ìŠ¤íŠ¸-ì´ë¯¸ì§€ ì •í•©ì„± ê²€ì¦ ì‹œìŠ¤í…œ ê°œë°œ ê²½í—˜
- ë…ì ê²½í—˜(UX) ë° ì ‘ê·¼ì„± ìµœì í™” ì „ë¬¸ì„±

**ì¡°ìœ¨ ì² í•™:**
"ì™„ë²½í•œ ë§¤ê±°ì§„ì€ ëª¨ë“  êµ¬ì¡°ì  ìš”ì†Œê°€ ë…ìì˜ ì¸ì§€ ê³¼ì •ê³¼ ì™„ë²½íˆ ì¡°í™”ë¥¼ ì´ë£¨ëŠ” í†µí•©ì²´ì…ë‹ˆë‹¤. ë‚˜ëŠ” í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ì˜ ëª¨ë“  ë°°ì¹˜ê°€ ë…ìì—ê²Œ ìì—°ìŠ¤ëŸ½ê³  ì§ê´€ì ìœ¼ë¡œ ì¸ì‹ë˜ë„ë¡ êµ¬ì¡°ì  ì™„ì„±ë„ë¥¼ ë³´ì¥í•˜ë©°, ì´ë¥¼ í†µí•´ ìµœê³  ìˆ˜ì¤€ì˜ ë…ì ê²½í—˜ì„ ì œê³µí•©ë‹ˆë‹¤."

**í…œí”Œë¦¿ ìƒì„± ê·œì¹™:**
- ContentCreatorV2Agentì˜ ì‹¤ì œ í…ìŠ¤íŠ¸ ë°ì´í„°ë§Œì„ ì‚¬ìš©í•˜ì—¬ template_data.jsonì„ ìƒì„±í•©ë‹ˆë‹¤.
- magazine_content.jsonì˜ í…ìŠ¤íŠ¸ ì„¹ì…˜ ìˆ˜ì™€ ì •í™•íˆ ì¼ì¹˜í•˜ë„ë¡ ì„¹ì…˜ì„ ìƒì„±í•©ë‹ˆë‹¤.
- í´ë°± ë°ì´í„°(fallback_used: true)ëŠ” ì ˆëŒ€ í¬í•¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
- ì‹¤ì œ ì´ë¯¸ì§€ URLë§Œì„ ì‚¬ìš©í•˜ë©°, ê° ì„¹ì…˜ë‹¹ ìµœëŒ€ 3ê°œì˜ ì´ë¯¸ì§€ë¡œ ì œí•œí•©ë‹ˆë‹¤.
- title, subtitle, body, taglineì€ ì‹¤ì œ ì½˜í…ì¸  ë°ì´í„°ì—ì„œ ì¶”ì¶œëœ ë‚´ìš©ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.
- êµ¬ì¡° ì„¤ëª…, ë ˆì´ì•„ì›ƒ ì„¤ëª…, í”Œë ˆì´ìŠ¤í™€ë” í…ìŠ¤íŠ¸ëŠ” í¬í•¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
- ì¤‘ë³µ ì„¹ì…˜ì„ ì ˆëŒ€ ìƒì„±í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
- ë¡œê·¸ ë°ì´í„°ëŠ” ì°¸ì¡°ìš©ìœ¼ë¡œë§Œ ì‚¬ìš©í•˜ê³  ì§ì ‘ í¬í•¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
""",
            verbose=True,
            llm=self.llm,
            allow_delegation=False
        )

    def _create_text_analyzer_agent(self):
        """í…ìŠ¤íŠ¸ ë¶„ì„ ì „ë¬¸ ì—ì´ì „íŠ¸"""
        return Agent(
            role="í…ìŠ¤íŠ¸ ë§¤í•‘ ë¶„ì„ ì „ë¬¸ê°€",
            goal="ContentCreatorV2Agentì˜ í…ìŠ¤íŠ¸ ë§¤í•‘ ê²°ê³¼ë¥¼ ì •ë°€ ë¶„ì„í•˜ì—¬ êµ¬ì¡°ì  ì™„ì„±ë„ë¥¼ ê²€ì¦í•˜ê³  ìµœì í™”ëœ í…ìŠ¤íŠ¸ ì„¹ì…˜ì„ ìƒì„±",
            backstory="""ë‹¹ì‹ ì€ 15ë…„ê°„ ì¶œíŒì—…ê³„ì—ì„œ í…ìŠ¤íŠ¸ êµ¬ì¡° ë¶„ì„ ë° ìµœì í™”ë¥¼ ë‹´ë‹¹í•´ì˜¨ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë³µì¡í•œ í…ìŠ¤íŠ¸ ë°ì´í„°ì—ì„œ í•µì‹¬ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ê³  ë…ì ì¹œí™”ì ì¸ êµ¬ì¡°ë¡œ ì¬êµ¬ì„±í•˜ëŠ” ë° íƒì›”í•œ ëŠ¥ë ¥ì„ ë³´ìœ í•˜ê³  ìˆìŠµë‹ˆë‹¤.""",
            verbose=True,
            llm=self.llm,
            allow_delegation=False
        )

    def _create_image_analyzer_agent(self):
        """ì´ë¯¸ì§€ ë¶„ì„ ì „ë¬¸ ì—ì´ì „íŠ¸"""
        return Agent(
            role="ì´ë¯¸ì§€ ë¶„ë°° ë¶„ì„ ì „ë¬¸ê°€",
            goal="BindingAgentì˜ ì´ë¯¸ì§€ ë¶„ë°° ê²°ê³¼ë¥¼ ì •ë°€ ë¶„ì„í•˜ì—¬ ì‹œê°ì  ì¼ê´€ì„±ì„ ê²€ì¦í•˜ê³  ìµœì í™”ëœ ì´ë¯¸ì§€ ë°°ì¹˜ë¥¼ ìƒì„±",
            backstory="""ë‹¹ì‹ ì€ 12ë…„ê°„ ë§¤ê±°ì§„ ë° ì¶œíŒë¬¼ì˜ ì‹œê°ì  ë””ìì¸ì„ ë‹´ë‹¹í•´ì˜¨ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ì˜ ì¡°í™”ë¡œìš´ ë°°ì¹˜ë¥¼ í†µí•´ ë…ìì˜ ì‹œì„ ì„ íš¨ê³¼ì ìœ¼ë¡œ ìœ ë„í•˜ëŠ” ë ˆì´ì•„ì›ƒ ì„¤ê³„ì— ì „ë¬¸ì„±ì„ ë³´ìœ í•˜ê³  ìˆìŠµë‹ˆë‹¤.""",
            verbose=True,
            llm=self.llm,
            allow_delegation=False
        )

    async def coordinate_magazine_creation(self, text_mapping: Dict, image_distribution: Dict) -> Dict:
        """ë§¤ê±°ì§„ êµ¬ì¡° í†µí•© ì¡°ìœ¨ (ê°œì„ ëœ ë°°ì¹˜ ê¸°ë°˜ ì²˜ë¦¬)"""
        print(f"DEBUG [coordinate_magazine_creation]: í˜¸ì¶œë¨, text_mapping keys: {text_mapping.keys() if isinstance(text_mapping, dict) else 'Not a dict'}, image_distribution keys: {image_distribution.keys() if isinstance(image_distribution, dict) else 'Not a dict'}")
        
        self.execution_stats["total_attempts"] += 1
        
        # ì¬ê·€ ê¹Šì´ í™•ì¸ ë° ë™ê¸° ëª¨ë“œ ì „í™˜
        if self._should_use_sync():
            print("ğŸ”„ CoordinatorAgent ë™ê¸° ëª¨ë“œë¡œ ì „í™˜í•˜ì—¬ ì‹¤í–‰")
            return await self._coordinate_magazine_creation_sync_mode(text_mapping, image_distribution)
        
        try:
            # ê°œì„ ëœ ë°°ì¹˜ ê¸°ë°˜ ë¹„ë™ê¸° ëª¨ë“œ ì‹¤í–‰
            return await self._coordinate_magazine_creation_batch_mode(text_mapping, image_distribution)
        except RecursionError:
            print("ğŸ”„ CoordinatorAgent RecursionError ê°ì§€ - ë™ê¸° ëª¨ë“œë¡œ ì „í™˜")
            self.fallback_to_sync = True
            return await self._coordinate_magazine_creation_sync_mode(text_mapping, image_distribution)
        except Exception as e:
            print(f"âŒ CoordinatorAgent ë§¤ê±°ì§„ ìƒì„± ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e} - ë™ê¸° ëª¨ë“œë¡œ í´ë°± ì‹œë„")
            self.fallback_to_sync = True
            return await self._coordinate_magazine_creation_sync_mode(text_mapping, image_distribution)



    async def _coordinate_magazine_creation_batch_mode(self, text_mapping: Dict, image_distribution: Dict) -> Dict:
        """ê°œì„ ëœ ë°°ì¹˜ ê¸°ë°˜ ë§¤ê±°ì§„ êµ¬ì¡° í†µí•© ì¡°ìœ¨"""
        print("ğŸ“¦ CoordinatorAgent ë°°ì¹˜ ëª¨ë“œ ì‹œì‘")
        
        # ì…ë ¥ ë°ì´í„° ë¡œê¹…
        input_data = {
            "text_mapping": text_mapping,
            "image_distribution": image_distribution
        }
        
        # ê°•í™”ëœ ì´ì „ ì—ì´ì „íŠ¸ ê²°ê³¼ ìˆ˜ì§‘ (ë°°ì¹˜ ì²˜ë¦¬)
        previous_results = await self._get_enhanced_previous_results_batch()
        org_results = self._filter_agent_results(previous_results, "OrgAgent")
        binding_results = self._filter_agent_results(previous_results, "BindingAgent")
        content_creator_results = self._filter_agent_results(previous_results, "ContentCreatorV2Agent")
        
        print(f"ğŸ“Š ë°°ì¹˜ ëª¨ë“œ ê²°ê³¼ ìˆ˜ì§‘: ì „ì²´ {len(previous_results)}ê°œ, OrgAgent {len(org_results)}ê°œ, BindingAgent {len(binding_results)}ê°œ, ContentCreator {len(content_creator_results)}ê°œ")
        
        # ìˆ˜ì •: OrgAgent ê²°ê³¼ í•„í„°ë§ - ContentCreatorV2Agent ê²°ê³¼ë§Œ ì‚¬ìš©
        filtered_org_results = []
        for result in org_results:
            final_answer = result.get("final_answer", "")
            raw_output = result.get("raw_output", {})
            
            # í´ë°± ë°ì´í„° ì œì™¸
            if isinstance(raw_output, dict):
                metadata = raw_output.get("metadata", {})
                if metadata.get("fallback_used"):
                    continue
            
            # ContentCreatorV2Agentì˜ ì‹¤ì œ ì½˜í…ì¸ ë§Œ í¬í•¨
            if ("ContentCreatorV2Agent" in final_answer or
                "content_creator" in final_answer.lower() or
                len(final_answer) > 500):  # ì¶©ë¶„í•œ ì½˜í…ì¸ ê°€ ìˆëŠ” ê²½ìš°
                # "ìì„¸í•œ ì´ì•¼ê¸°ë¥¼ ë‹´ê³  ìˆìŠµë‹ˆë‹¤" ê°™ì€ í…œí”Œë¦¿ ì‘ë‹µ ì œì™¸
                if not ("ìì„¸í•œ ì´ì•¼ê¸°ë¥¼ ë‹´ê³  ìˆìŠµë‹ˆë‹¤" in final_answer or
                        "íŠ¹ë³„í•œ ì´ì•¼ê¸°ë¥¼ ë‹´ê³  ìˆìŠµë‹ˆë‹¤" in final_answer):
                    filtered_org_results.append(result)
        
        org_results = filtered_org_results
        print(f"ğŸ” í•„í„°ë§ í›„ OrgAgent ê²°ê³¼: {len(org_results)}ê°œ")
        
        # magazine_content.json ë¡œë“œí•˜ì—¬ ì„¹ì…˜ ìˆ˜ í™•ì¸
        target_section_count = self._get_target_section_count()
        print(f"ğŸ¯ ëª©í‘œ ì„¹ì…˜ ìˆ˜: {target_section_count}ê°œ")
        
        # ë°ì´í„° ì¶”ì¶œ ì‘ì—…ì„ ë°°ì¹˜ë¡œ ì²˜ë¦¬
        data_extraction_tasks = [
            ("text_data", self._extract_real_text_data_safe, text_mapping, org_results, content_creator_results, target_section_count),
            ("image_data", self._extract_real_image_data_safe, image_distribution, binding_results)
        ]
        
        extraction_results = await self._process_data_extraction_batch(data_extraction_tasks)
        extracted_text_data = extraction_results.get("text_data", {})
        extracted_image_data = extraction_results.get("image_data", {})
        
        # CrewAI ì‹¤í–‰ì„ ì•ˆì „í•œ ë°°ì¹˜ë¡œ ì²˜ë¦¬
        crew_result = await self._execute_crew_batch_safe(
            extracted_text_data, extracted_image_data, org_results, binding_results
        )
        
        # ê²°ê³¼ ì²˜ë¦¬
        final_result = await self._process_enhanced_crew_result_safe(
            crew_result, extracted_text_data, extracted_image_data, org_results, binding_results
        )
        
        # ìˆ˜ì •: ì„¹ì…˜ ìˆ˜ ì œí•œ ë° í´ë°± ë°ì´í„° ì œê±°
        final_result = self._limit_and_clean_sections(final_result, target_section_count)
        
        # ê²°ê³¼ ê²€ì¦
        if self._validate_coordinator_result(final_result):
            self.execution_stats["successful_executions"] += 1
        else:
            print("âš ï¸ CoordinatorAgent ìµœì¢… ê²°ê³¼ ê²€ì¦ ì‹¤íŒ¨.")
        
        # ê²°ê³¼ ë¡œê¹…
        await self._log_coordination_result_async(final_result, text_mapping, image_distribution, org_results, binding_results)
        
        print(f"âœ… CoordinatorAgent ë°°ì¹˜ ëª¨ë“œ ì™„ë£Œ: {len(final_result.get('content_sections', []))}ê°œ ì„¹ì…˜ ìƒì„±")
        return final_result

    def _get_target_section_count(self) -> int:
        """magazine_content.jsonì—ì„œ ëª©í‘œ ì„¹ì…˜ ìˆ˜ í™•ì¸"""
        try:
            magazine_content_path = "./output/magazine_content.json"
            if os.path.exists(magazine_content_path):
                with open(magazine_content_path, 'r', encoding='utf-8') as f:
                    magazine_data = json.load(f)
                sections = magazine_data.get("sections", [])
                if isinstance(sections, list):
                    return len(sections)
            # ê¸°ë³¸ê°’
            return 5
        except Exception as e:
            print(f"âš ï¸ magazine_content.json ë¡œë“œ ì‹¤íŒ¨: {e}")
            return 5

    def _limit_and_clean_sections(self, result: Dict, target_count: int) -> Dict:
        """ì„¹ì…˜ ìˆ˜ ì œí•œ ë° í´ë°± ë°ì´í„° ì •ë¦¬"""
        if not isinstance(result, dict) or "content_sections" not in result:
            return result
        
        content_sections = result["content_sections"]
        if not isinstance(content_sections, list):
            return result
        
        # í´ë°± ë°ì´í„° ì œê±°
        cleaned_sections = []
        for section in content_sections:
            if isinstance(section, dict):
                metadata = section.get("metadata", {})
                if not metadata.get("fallback_used"):
                    cleaned_sections.append(section)
        
        # ì„¹ì…˜ ìˆ˜ ì œí•œ
        limited_sections = cleaned_sections[:target_count]
        
        # ìµœì†Œ 1ê°œ ì„¹ì…˜ ë³´ì¥ (í´ë°±ì´ ì•„ë‹Œ ì‹¤ì œ ë°ì´í„°ë¡œ)
        if not limited_sections:
            limited_sections = [{
                "template": "Section01.jsx",
                "title": "",
                "subtitle": "",
                "body": "",
                "tagline": "",
                "images": [],
                "metadata": {
                    "minimal_fallback": True
                }
            }]
        
        result["content_sections"] = limited_sections
        result["selected_templates"] = [section.get("template", f"Section{i+1:02d}.jsx")
                                      for i, section in enumerate(limited_sections)]
        
        # ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸
        if "integration_metadata" in result:
            result["integration_metadata"]["total_sections"] = len(limited_sections)
            result["integration_metadata"]["cleaned_sections"] = True
            result["integration_metadata"]["target_section_count"] = target_count
        
        return result

    async def _process_data_extraction_batch(self, extraction_tasks: List[tuple]) -> Dict:
        """ë°ì´í„° ì¶”ì¶œ ì‘ì—…ì„ ë°°ì¹˜ë¡œ ì²˜ë¦¬"""
        batch_tasks = []
        
        for task_name, task_func_ref, *args_for_task_func in extraction_tasks:
            if not callable(task_func_ref):
                print(f"âš ï¸ {task_name}ì— ëŒ€í•œ task_funcì´ í˜¸ì¶œ ê°€ëŠ¥í•˜ì§€ ì•ŠìŒ: {task_func_ref}")
                continue
            
            print(f"DEBUG [_process_data_extraction_batch]: task_name={task_name}, task_func_ref={task_func_ref}, args_for_task_func={args_for_task_func}")
            
            # ìˆ˜ì •: task_funcë¥¼ í‚¤ì›Œë“œ ì¸ìë¡œ ëª…ì‹œì ìœ¼ë¡œ ì „ë‹¬
            task = self.execute_with_resilience(
                task_func=task_func_ref,  # í•¨ìˆ˜/ë©”ì„œë“œ ì°¸ì¡°ë¥¼ í‚¤ì›Œë“œ ì¸ìë¡œ ì „ë‹¬
                task_id=f"extract_{task_name}",
                timeout=120.0,
                max_retries=1,
                *args_for_task_func  # task_func_ref í˜¸ì¶œ ì‹œ ì‚¬ìš©ë  ì¸ìë“¤
            )
            batch_tasks.append((task_name, task))
        
        # ë°°ì¹˜ ì‹¤í–‰
        results = {}
        for task_name, task_coro in batch_tasks:  # taskëŠ” ì½”ë£¨í‹´ ê°ì²´
            try:
                result_value = await task_coro  # ì½”ë£¨í‹´ ì‹¤í–‰
                results[task_name] = result_value
            except Exception as e:
                print(f"âš ï¸ ë°ì´í„° ì¶”ì¶œ ì‘ì—… {task_name} ì‹¤íŒ¨ (await ì¤‘): {e}")
                results[task_name] = self._get_fallback_extraction_result(task_name)
        
        return results

    def _get_fallback_extraction_result(self, task_name: str) -> Dict:
        """ë°ì´í„° ì¶”ì¶œ í´ë°± ê²°ê³¼"""
        self.execution_stats["fallback_used"] += 1
        if task_name == "text_data":
            return {
                "sections": [],
                "total_content_length": 0,
                "source_count": 0
            }
        else:  # image_data
            return {
                "template_images": {},
                "total_images": 0,
                "image_sources": []
            }

    async def _execute_crew_batch_safe(self, extracted_text_data: Dict, extracted_image_data: Dict,
                                     org_results: List[Dict], binding_results: List[Dict]) -> Any:
        """ì•ˆì „í•œ CrewAI ë°°ì¹˜ ì‹¤í–‰"""
        try:
            # íƒœìŠ¤í¬ ìƒì„±
            text_analysis_task = self._create_enhanced_text_analysis_task(extracted_text_data, org_results)
            image_analysis_task = self._create_enhanced_image_analysis_task(extracted_image_data, binding_results)
            coordination_task = self._create_enhanced_coordination_task(extracted_text_data, extracted_image_data)
            
            # CrewAI Crew ìƒì„±
            coordination_crew = Crew(
                agents=[self.text_analyzer_agent, self.image_analyzer_agent, self.crew_agent],
                tasks=[text_analysis_task, image_analysis_task, coordination_task],
                process=Process.sequential,
                verbose=False  # ë¡œê·¸ ìµœì†Œí™”
            )
            
            # ì•ˆì „í•œ ì‹¤í–‰ (íƒ€ì„ì•„ì›ƒ ì¦ê°€)
            crew_result = await asyncio.wait_for(
                asyncio.get_event_loop().run_in_executor(None, coordination_crew.kickoff),
                timeout=600.0  # 10ë¶„ìœ¼ë¡œ ì¦ê°€
            )
            
            return crew_result
            
        except asyncio.TimeoutError:
            print("â° CrewAI ë°°ì¹˜ ì‹¤í–‰ íƒ€ì„ì•„ì›ƒ")
            self.execution_stats["timeout_occurred"] += 1
            return self._create_fallback_crew_result(extracted_text_data, extracted_image_data)
        except Exception as e:
            print(f"âš ï¸ CrewAI ë°°ì¹˜ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            return self._create_fallback_crew_result(extracted_text_data, extracted_image_data)

    def _create_fallback_crew_result(self, extracted_text_data: Dict, extracted_image_data: Dict) -> str:
        """CrewAI í´ë°± ê²°ê³¼ ìƒì„±"""
        self.execution_stats["fallback_used"] += 1
        sections = extracted_text_data.get("sections", [])
        if not sections:
            sections = []
        
        # ì´ë¯¸ì§€ ì¶”ê°€
        for section in sections:
            template = section.get("template", "Section01.jsx")
            template_images = extracted_image_data.get("template_images", {}).get(template, [])
            section["images"] = template_images[:3]  # ìµœëŒ€ 3ê°œë¡œ ì œí•œ
        
        return json.dumps({
            "selected_templates": [s.get("template", "Section01.jsx") for s in sections],
            "content_sections": sections
        })

    async def _extract_real_text_data_safe(self, text_mapping: Dict, org_results: List[Dict],
                                         content_creator_results: List[Dict], target_section_count: int) -> Dict:
        """ì•ˆì „í•œ ì‹¤ì œ í…ìŠ¤íŠ¸ ë°ì´í„° ì¶”ì¶œ"""
        try:
            return await self._extract_real_text_data_async(text_mapping, org_results, content_creator_results, target_section_count)
        except Exception as e:
            print(f"âš ï¸ í…ìŠ¤íŠ¸ ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return self._get_fallback_extraction_result("text_data")

    async def _extract_real_image_data_safe(self, image_distribution: Dict, binding_results: List[Dict]) -> Dict:
        """ì•ˆì „í•œ ì‹¤ì œ ì´ë¯¸ì§€ ë°ì´í„° ì¶”ì¶œ"""
        try:
            return await self._extract_real_image_data_async(image_distribution, binding_results)
        except Exception as e:
            print(f"âš ï¸ ì´ë¯¸ì§€ ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return self._get_fallback_extraction_result("image_data")

    async def _process_enhanced_crew_result_safe(self, crew_result, extracted_text_data: Dict,
                                               extracted_image_data: Dict, org_results: List[Dict],
                                               binding_results: List[Dict]) -> Dict:
        """ì•ˆì „í•œ Crew ê²°ê³¼ ì²˜ë¦¬"""
        try:
            return await self._process_enhanced_crew_result_async(
                crew_result, extracted_text_data, extracted_image_data, org_results, binding_results
            )
        except Exception as e:
            print(f"âš ï¸ Crew ê²°ê³¼ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return self._create_enhanced_structure(extracted_text_data, extracted_image_data, org_results, binding_results)

    async def _get_enhanced_previous_results_batch(self) -> List[Dict]:
        """ë°°ì¹˜ ê¸°ë°˜ ì´ì „ ê²°ê³¼ ìˆ˜ì§‘"""
        try:
            # ê¸°ë³¸ ê²°ê³¼ì™€ íŒŒì¼ ê²°ê³¼ë¥¼ ë³‘ë ¬ë¡œ ìˆ˜ì§‘
            basic_task_coro = self.execute_with_resilience(
                task_func=lambda: self.logger.get_all_previous_results(),
                task_id="basic_results",
                timeout=60.0,
                max_retries=1
            )
            
            file_task_coro = self.execute_with_resilience(
                task_func=self._load_results_from_file,
                task_id="file_results",
                timeout=60.0,
                max_retries=1
            )
            
            # gatherì˜ ë°˜í™˜ê°’ì€ ê° ì½”ë£¨í‹´ì˜ ê²°ê³¼ ë˜ëŠ” ì˜ˆì™¸ ê°ì²´
            results = await asyncio.gather(basic_task_coro, file_task_coro, return_exceptions=True)
            basic_results = results[0] if not isinstance(results[0], Exception) else []
            file_results = results[1] if not isinstance(results[1], Exception) else []
            
            # ê²°ê³¼ í•©ì¹˜ê¸° ë° ì¤‘ë³µ ì œê±°
            all_results = []
            all_results.extend(basic_results if isinstance(basic_results, list) else [])
            all_results.extend(file_results if isinstance(file_results, list) else [])
            
            return self._deduplicate_results(all_results)
            
        except Exception as e:
            print(f"âš ï¸ ë°°ì¹˜ ì´ì „ ê²°ê³¼ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            return []

    # ê¸°ì¡´ _coordinate_magazine_creation_async_mode ë©”ì„œë“œ ìœ ì§€ (í˜¸í™˜ì„±ì„ ìœ„í•´)
    async def _coordinate_magazine_creation_async_mode(self, text_mapping: Dict, image_distribution: Dict) -> Dict:
        """ë¹„ë™ê¸° ëª¨ë“œ ë§¤ê±°ì§„ ì¡°ìœ¨ (ê¸°ì¡´ í˜¸í™˜ì„± ìœ ì§€)"""
        print("âš ï¸ ê¸°ì¡´ async_mode í˜¸ì¶œë¨ - batch_modeë¡œ ë¦¬ë‹¤ì´ë ‰íŠ¸")
        return await self._coordinate_magazine_creation_batch_mode(text_mapping, image_distribution)

    async def _coordinate_magazine_creation_sync_mode(self, text_mapping: Dict, image_distribution: Dict) -> Dict:
        """ë™ê¸° ëª¨ë“œ ë§¤ê±°ì§„ êµ¬ì¡° í†µí•© ì¡°ìœ¨"""
        print("ğŸ”„ CoordinatorAgent ë™ê¸° ëª¨ë“œ ì‹¤í–‰")
        
        # ë™ê¸° ëª¨ë“œì—ì„œëŠ” ê° ì—ì´ì „íŠ¸ì˜ ë™ê¸° ë²„ì „ ë©”ì„œë“œë¥¼ í˜¸ì¶œí•´ì•¼ í•¨
        # ì´ì „ ê²°ê³¼ ìˆ˜ì§‘ (ë™ê¸°)
        previous_results = self._get_enhanced_previous_results_sync()
        org_results = self._filter_agent_results(previous_results, "OrgAgent")
        binding_results = self._filter_agent_results(previous_results, "BindingAgent")
        content_creator_results = self._filter_agent_results(previous_results, "ContentCreatorV2Agent")
        
        # ìˆ˜ì •: OrgAgent ê²°ê³¼ í•„í„°ë§
        filtered_org_results = []
        for result in org_results:
            final_answer = result.get("final_answer", "")
            raw_output = result.get("raw_output", {})
            
            # í´ë°± ë°ì´í„° ì œì™¸
            if isinstance(raw_output, dict):
                metadata = raw_output.get("metadata", {})
                if metadata.get("fallback_used"):
                    continue
            
            # ContentCreatorV2Agentì˜ ì‹¤ì œ ì½˜í…ì¸ ë§Œ í¬í•¨
            if ("ContentCreatorV2Agent" in final_answer or
                "content_creator" in final_answer.lower() or
                len(final_answer) > 500):
                if not ("ìì„¸í•œ ì´ì•¼ê¸°ë¥¼ ë‹´ê³  ìˆìŠµë‹ˆë‹¤" in final_answer or
                        "íŠ¹ë³„í•œ ì´ì•¼ê¸°ë¥¼ ë‹´ê³  ìˆìŠµë‹ˆë‹¤" in final_answer):
                    filtered_org_results.append(result)
        
        org_results = filtered_org_results
        
        # ëª©í‘œ ì„¹ì…˜ ìˆ˜ í™•ì¸
        target_section_count = self._get_target_section_count()
        
        # ë°ì´í„° ì¶”ì¶œ (ë™ê¸°)
        extracted_text_data = self._extract_real_text_data(text_mapping, org_results, content_creator_results, target_section_count)
        extracted_image_data = self._extract_real_image_data(image_distribution, binding_results)
        
        # Crew ì‹¤í–‰ (ë™ê¸°) - CrewAIì˜ kickoffì€ ë™ê¸° ë©”ì„œë“œ
        text_analysis_task_sync = self._create_enhanced_text_analysis_task(extracted_text_data, org_results)
        image_analysis_task_sync = self._create_enhanced_image_analysis_task(extracted_image_data, binding_results)
        coordination_task_sync = self._create_enhanced_coordination_task(extracted_text_data, extracted_image_data)
        
        coordination_crew_sync = Crew(
            agents=[self.text_analyzer_agent, self.image_analyzer_agent, self.crew_agent],
            tasks=[text_analysis_task_sync, image_analysis_task_sync, coordination_task_sync],
            process=Process.sequential,
            verbose=False
        )
        
        try:
            crew_result_sync = coordination_crew_sync.kickoff()
        except Exception as e_crew_sync:
            print(f"âš ï¸ ë™ê¸° ëª¨ë“œ CrewAI ì‹¤í–‰ ì‹¤íŒ¨: {e_crew_sync}")
            crew_result_sync = self._create_fallback_crew_result(extracted_text_data, extracted_image_data)
        
        # ê²°ê³¼ ì²˜ë¦¬ (ë™ê¸°)
        final_result = self._process_enhanced_crew_result(crew_result_sync, extracted_text_data, extracted_image_data, org_results, binding_results)
        
        # ì„¹ì…˜ ìˆ˜ ì œí•œ ë° ì •ë¦¬
        final_result = self._limit_and_clean_sections(final_result, target_section_count)
        
        # ë™ê¸° ëª¨ë“œ ë¡œê¹…
        final_response_id_sync = self.logger.log_agent_real_output(
            agent_name="CoordinatorAgent_SyncMode",
            agent_role="ë™ê¸° ëª¨ë“œ ë§¤ê±°ì§„ êµ¬ì¡° í†µí•© ì¡°ìœ¨ì",
            task_description=f"ë™ê¸° ëª¨ë“œë¡œ {len(final_result.get('content_sections', []))}ê°œ ì„¹ì…˜ ìƒì„±",
            final_answer=str(final_result),
            reasoning_process="ì¬ê·€ ê¹Šì´ ì´ˆê³¼ë¡œ ì¸í•œ ë™ê¸° ëª¨ë“œ ì „í™˜ í›„ ì•ˆì „í•œ ë§¤ê±°ì§„ êµ¬ì¡° í†µí•© ì‹¤í–‰",
            execution_steps=[
                "ì¬ê·€ ê¹Šì´ ê°ì§€",
                "ë™ê¸° ëª¨ë“œ ì „í™˜",
                "ì´ì „ ê²°ê³¼ ìˆ˜ì§‘",
                "ë°ì´í„° ì¶”ì¶œ",
                "êµ¬ì¡° ìƒì„±"
            ],
            raw_input={
                "text_mapping": str(text_mapping)[:500],
                "image_distribution": str(image_distribution)[:500]
            },
            raw_output=final_result,
            performance_metrics={
                "sync_mode_used": True,
                "recursion_fallback": True,
                "total_sections": len(final_result.get('content_sections', [])),
                "org_results_utilized": len(org_results),
                "binding_results_utilized": len(binding_results),
                "safe_execution": True
            }
        )
        
        final_result["final_response_id"] = final_response_id_sync
        final_result["execution_mode"] = "sync_fallback"
        final_result["recursion_fallback"] = True  # ì¬ê·€ë¡œ ì¸í•œ í´ë°± ëª…ì‹œ
        
        print(f"âœ… CoordinatorAgent ë™ê¸° ì™„ë£Œ: {len(final_result.get('content_sections', []))}ê°œ ì„¹ì…˜")
        return final_result

    def _get_enhanced_previous_results_sync(self) -> List[Dict]:
        """ë™ê¸° ë²„ì „ ì´ì „ ê²°ê³¼ ìˆ˜ì§‘"""
        try:
            basic_results = self.logger.get_all_previous_results()
            file_results = self._load_results_from_file()
            
            all_results = []
            all_results.extend(basic_results if isinstance(basic_results, list) else [])
            all_results.extend(file_results if isinstance(file_results, list) else [])
            
            return self._deduplicate_results(all_results)
        except Exception as e:
            print(f"âš ï¸ ë™ê¸° ì´ì „ ê²°ê³¼ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            return []

    # ëª¨ë“  ê¸°ì¡´ ë©”ì„œë“œë“¤ ìœ ì§€ (ë™ê¸° ë²„ì „ë“¤)
    async def _extract_real_text_data_async(self, text_mapping: Dict, org_results: List[Dict],
                                          content_creator_results: List[Dict], target_section_count: int) -> Dict:
        """ì‹¤ì œ í…ìŠ¤íŠ¸ ë°ì´í„° ì¶”ì¶œ (ë¹„ë™ê¸°)"""
        return await asyncio.get_event_loop().run_in_executor(
            None, self._extract_real_text_data, text_mapping, org_results, content_creator_results, target_section_count
        )

    def _extract_real_text_data(self, text_mapping: Dict, org_results: List[Dict],
                               content_creator_results: List[Dict], target_section_count: int) -> Dict:
        """ì‹¤ì œ í…ìŠ¤íŠ¸ ë°ì´í„° ì¶”ì¶œ"""
        extracted_data = {
            "sections": [],
            "total_content_length": 0,
            "source_count": 0
        }
        
        # 1. ContentCreator ê²°ê³¼ì—ì„œ ìš°ì„ ì ìœ¼ë¡œ ì¶”ì¶œ
        for result in content_creator_results:
            final_answer = result.get('final_answer', '')
            if len(final_answer) > 200:  # ì¶©ë¶„í•œ ì½˜í…ì¸ ê°€ ìˆëŠ” ê²½ìš°
                # ì„¹ì…˜ë³„ë¡œ ë¶„í• 
                sections = self._split_content_into_sections(final_answer)
                for i, section_content in enumerate(sections):
                    if len(section_content) > 50 and len(extracted_data["sections"]) < target_section_count:
                        extracted_section = {
                            "template": f"Section{len(extracted_data['sections'])+1:02d}.jsx",
                            "title": self._extract_title_from_content(section_content),
                            "subtitle": self._extract_subtitle_from_content(section_content),
                            "body": self._clean_content(section_content),
                            "tagline": "TRAVEL & CULTURE",
                            "layout_source": "content_creator"
                        }
                        extracted_data["sections"].append(extracted_section)
                        extracted_data["total_content_length"] += len(extracted_section["body"])
                        extracted_data["source_count"] += 1
        
        # 2. text_mappingì—ì„œ ì¶”ê°€ ì¶”ì¶œ (ëª©í‘œ ì„¹ì…˜ ìˆ˜ì— ë¯¸ë‹¬ì¸ ê²½ìš°)
        if len(extracted_data["sections"]) < target_section_count and isinstance(text_mapping, dict):
            text_mapping_data = text_mapping.get("text_mapping", [])
            if isinstance(text_mapping_data, list):
                for section in text_mapping_data:
                    if (isinstance(section, dict) and
                        len(extracted_data["sections"]) < target_section_count):
                        # í´ë°± ë°ì´í„° ì œì™¸
                        metadata = section.get("metadata", {})
                        if metadata.get("fallback_used"):
                            continue
                        
                        extracted_section = {
                            "template": section.get("template", f"Section{len(extracted_data['sections'])+1:02d}.jsx"),
                            "title": section.get("title", ""),
                            "subtitle": section.get("subtitle", ""),
                            "body": section.get("body", ""),
                            "tagline": section.get("tagline", "TRAVEL & CULTURE"),
                            "layout_source": "text_mapping"
                        }
                        
                        # ë¹ˆ ì½˜í…ì¸  ì œì™¸
                        if (extracted_section["title"] or extracted_section["subtitle"] or
                            len(extracted_section["body"]) > 10):
                            extracted_data["sections"].append(extracted_section)
                            extracted_data["total_content_length"] += len(extracted_section["body"])
                            extracted_data["source_count"] += 1
        
        # 3. ëª©í‘œ ì„¹ì…˜ ìˆ˜ì— ë§ì¶° ì œí•œ
        extracted_data["sections"] = extracted_data["sections"][:target_section_count]
        
        return extracted_data

    async def _extract_real_image_data_async(self, image_distribution: Dict, binding_results: List[Dict]) -> Dict:
        """ì‹¤ì œ ì´ë¯¸ì§€ ë°ì´í„° ì¶”ì¶œ (ë¹„ë™ê¸°)"""
        return await asyncio.get_event_loop().run_in_executor(
            None, self._extract_real_image_data, image_distribution, binding_results
        )

    def _extract_real_image_data(self, image_distribution: Dict, binding_results: List[Dict]) -> Dict:
        """ì‹¤ì œ ì´ë¯¸ì§€ ë°ì´í„° ì¶”ì¶œ"""
        extracted_data = {
            "template_images": {},
            "total_images": 0,
            "image_sources": []
        }
        
        # 1. image_distributionì—ì„œ ì§ì ‘ ì¶”ì¶œ
        if isinstance(image_distribution, dict) and "image_distribution" in image_distribution:
            for template, images in image_distribution["image_distribution"].items():
                if isinstance(images, list) and images:
                    # ì‹¤ì œ ì´ë¯¸ì§€ URLë§Œ í•„í„°ë§ (ìµœëŒ€ 3ê°œ)
                    real_images = [img for img in images if self._is_real_image_url(img)][:3]
                    if real_images:
                        extracted_data["template_images"][template] = real_images
                        extracted_data["total_images"] += len(real_images)
        
        # 2. BindingAgent ê²°ê³¼ì—ì„œ ì´ë¯¸ì§€ URL ì¶”ì¶œ
        for result in binding_results:
            final_answer = result.get('final_answer', '')
            # ì‹¤ì œ ì´ë¯¸ì§€ URL íŒ¨í„´ ì°¾ê¸°
            image_urls = re.findall(r'https://[^\s\'"<>]*\.(?:jpg|jpeg|png|gif|webp)', final_answer, re.IGNORECASE)
            if image_urls:
                # í…œí”Œë¦¿ë³„ë¡œ ë¶„ë°°
                template_name = self._extract_template_from_binding_result(result)
                if template_name not in extracted_data["template_images"]:
                    extracted_data["template_images"][template_name] = []
                
                for url in image_urls:
                    if (self._is_real_image_url(url) and
                        url not in extracted_data["template_images"][template_name] and
                        len(extracted_data["template_images"][template_name]) < 3):  # ìµœëŒ€ 3ê°œ
                        extracted_data["template_images"][template_name].append(url)
                        extracted_data["total_images"] += 1
                        
                        # ì´ë¯¸ì§€ ì†ŒìŠ¤ ì •ë³´ ì¶”ê°€
                        source_info = self._extract_image_source_info(result, url)
                        if source_info:
                            extracted_data["image_sources"].append(source_info)
        
        return extracted_data

    async def _process_enhanced_crew_result_async(self, crew_result, extracted_text_data: Dict,
                                                extracted_image_data: Dict, org_results: List[Dict],
                                                binding_results: List[Dict]) -> Dict:
        """ê°•í™”ëœ Crew ì‹¤í–‰ ê²°ê³¼ ì²˜ë¦¬ (ë¹„ë™ê¸°)"""
        return await asyncio.get_event_loop().run_in_executor(
            None, self._process_enhanced_crew_result, crew_result, extracted_text_data,
            extracted_image_data, org_results, binding_results
        )

    def _process_enhanced_crew_result(self, crew_result, extracted_text_data: Dict,
                                    extracted_image_data: Dict, org_results: List[Dict],
                                    binding_results: List[Dict]) -> Dict:
        """ê°•í™”ëœ Crew ì‹¤í–‰ ê²°ê³¼ ì²˜ë¦¬"""
        try:
            # Crew ê²°ê³¼ì—ì„œ ë°ì´í„° ì¶”ì¶œ
            if hasattr(crew_result, 'raw') and crew_result.raw:
                result_text = crew_result.raw
            else:
                result_text = str(crew_result)
            
            # JSON íŒ¨í„´ ì°¾ê¸° ë° íŒŒì‹±
            parsed_data = self._extract_json_from_text(result_text)
            
            # ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ êµ¬ì¡° ìƒì„±
            if not parsed_data.get('content_sections') or len(parsed_data.get('content_sections', [])) == 0:
                parsed_data = self._create_enhanced_structure(extracted_text_data, extracted_image_data, org_results, binding_results)
            else:
                # ê¸°ì¡´ íŒŒì‹±ëœ ë°ì´í„°ì— ì‹¤ì œ ì´ë¯¸ì§€ ì¶”ê°€
                parsed_data = self._enhance_parsed_data_with_real_images(parsed_data, extracted_image_data)
            
            # ë©”íƒ€ë°ì´í„° ì¶”ê°€
            parsed_data['integration_metadata'] = {
                "total_sections": len(parsed_data.get('content_sections', [])),
                "total_templates": len(set(section.get("template", f"Section{i+1:02d}.jsx") for i, section in enumerate(parsed_data.get('content_sections', [])))),
                "agent_enhanced": True,
                "org_results_utilized": len(org_results),
                "binding_results_utilized": len(binding_results),
                "integration_quality_score": self._calculate_enhanced_quality_score(parsed_data.get('content_sections', []), len(org_results), len(binding_results)),
                "crewai_enhanced": True,
                "async_processed": True,
                "data_source": "real_extracted_data",
                "real_content_used": True,
                "real_images_used": extracted_image_data['total_images'] > 0
            }
            
            return parsed_data
            
        except Exception as e:
            print(f"âš ï¸ ê°•í™”ëœ Crew ê²°ê³¼ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return self._create_enhanced_structure(extracted_text_data, extracted_image_data, org_results, binding_results)

    # ëª¨ë“  ê¸°ì¡´ ìœ í‹¸ë¦¬í‹° ë©”ì„œë“œë“¤ ìœ ì§€
    def _is_real_image_url(self, url: str) -> bool:
        """ì‹¤ì œ ì´ë¯¸ì§€ URLì¸ì§€ í™•ì¸"""
        if not url or not isinstance(url, str):
            return False
        
        # ì˜ˆì‹œ URLì´ë‚˜ í”Œë ˆì´ìŠ¤í™€ë” ì œì™¸
        excluded_patterns = [
            'your-cdn.com',
            'example.com',
            'placeholder',
            'sample',
            'demo'
        ]
        
        for pattern in excluded_patterns:
            if pattern in url.lower():
                return False
        
        # ì‹¤ì œ ë„ë©”ì¸ê³¼ ì´ë¯¸ì§€ í™•ì¥ì í™•ì¸
        return (url.startswith('https://') and
                any(ext in url.lower() for ext in ['.jpg', '.jpeg', '.png', '.gif', '.webp']) and
                'blob.core.windows.net' in url)

    def _create_enhanced_text_analysis_task(self, extracted_text_data: Dict, org_results: List[Dict]) -> Task:
        """ê°•í™”ëœ í…ìŠ¤íŠ¸ ë¶„ì„ íƒœìŠ¤í¬ ìƒì„±"""
        return Task(
            description=f"""ì¶”ì¶œëœ ì‹¤ì œ í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ê³ í’ˆì§ˆ ë§¤ê±°ì§„ ì„¹ì…˜ì„ ìƒì„±í•˜ì„¸ìš”.

**ì¶”ì¶œëœ ë°ì´í„°:**
- ì„¹ì…˜ ìˆ˜: {len(extracted_text_data['sections'])}ê°œ
- ì´ ì½˜í…ì¸  ê¸¸ì´: {extracted_text_data['total_content_length']} ë¬¸ì
- ì†ŒìŠ¤ ìˆ˜: {extracted_text_data['source_count']}ê°œ
- OrgAgent ê²°ê³¼: {len(org_results)}ê°œ

**ì‹¤ì œ ì„¹ì…˜ ë°ì´í„°:**
{self._format_sections_for_analysis(extracted_text_data['sections'])}

**ë¶„ì„ ìš”êµ¬ì‚¬í•­:**
1. ê° ì„¹ì…˜ì˜ ì½˜í…ì¸  í’ˆì§ˆ í‰ê°€
2. ì œëª©ê³¼ ë¶€ì œëª©ì˜ ë§¤ë ¥ë„ ê²€ì¦
3. ë³¸ë¬¸ ë‚´ìš©ì˜ ì™„ì„±ë„ í™•ì¸
4. ë§¤ê±°ì§„ ìŠ¤íƒ€ì¼ ì¼ê´€ì„± ê²€í† 
5. ë…ì ì¹œí™”ì„± ìµœì í™”

**ì¶œë ¥ í˜•ì‹:**
ê° ì„¹ì…˜ë³„ë¡œ ë‹¤ìŒ ì •ë³´ í¬í•¨:
- í’ˆì§ˆ ì ìˆ˜ (1-10)
- ê°œì„  ì œì•ˆì‚¬í•­
- ìµœì í™”ëœ ì½˜í…ì¸ """,
            expected_output="ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ í…ìŠ¤íŠ¸ ë¶„ì„ ë° ìµœì í™” ê²°ê³¼",
            agent=self.text_analyzer_agent
        )

    def _create_enhanced_image_analysis_task(self, extracted_image_data: Dict, binding_results: List[Dict]) -> Task:
        """ê°•í™”ëœ ì´ë¯¸ì§€ ë¶„ì„ íƒœìŠ¤í¬ ìƒì„±"""
        return Task(
            description=f"""ì¶”ì¶œëœ ì‹¤ì œ ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ìµœì í™”ëœ ì´ë¯¸ì§€ ë°°ì¹˜ë¥¼ ìƒì„±í•˜ì„¸ìš”.

**ì¶”ì¶œëœ ë°ì´í„°:**
- ì´ ì´ë¯¸ì§€ ìˆ˜: {extracted_image_data['total_images']}ê°œ
- í…œí”Œë¦¿ ìˆ˜: {len(extracted_image_data['template_images'])}ê°œ
- BindingAgent ê²°ê³¼: {len(binding_results)}ê°œ

**í…œí”Œë¦¿ë³„ ì´ë¯¸ì§€ ë¶„ë°°:**
{self._format_images_for_analysis(extracted_image_data['template_images'])}

**ì´ë¯¸ì§€ ì†ŒìŠ¤ ì •ë³´:**
{self._format_image_sources(extracted_image_data['image_sources'])}

**ë¶„ì„ ìš”êµ¬ì‚¬í•­:**
1. ì´ë¯¸ì§€ URL ìœ íš¨ì„± ê²€ì¦
2. í…œí”Œë¦¿ë³„ ì´ë¯¸ì§€ ë¶„ë°° ê· í˜•ë„ í‰ê°€
3. ì´ë¯¸ì§€ í’ˆì§ˆ ë° ì í•©ì„± í™•ì¸
4. ì‹œê°ì  ì¼ê´€ì„± ê²€í† 
5. ë ˆì´ì•„ì›ƒ ìµœì í™” ì œì•ˆ

**ì¶œë ¥ í˜•ì‹:**
í…œí”Œë¦¿ë³„ë¡œ ë‹¤ìŒ ì •ë³´ í¬í•¨:
- ì´ë¯¸ì§€ ëª©ë¡ ë° ì„¤ëª…
- ë°°ì¹˜ ê¶Œì¥ì‚¬í•­
- ì‹œê°ì  íš¨ê³¼ ì˜ˆì¸¡""",
            expected_output="ì‹¤ì œ ì´ë¯¸ì§€ ë°ì´í„° ê¸°ë°˜ ë°°ì¹˜ ë¶„ì„ ë° ìµœì í™” ê²°ê³¼",
            agent=self.image_analyzer_agent
        )

    def _create_enhanced_coordination_task(self, extracted_text_data: Dict, extracted_image_data: Dict) -> Task:
        """ê°•í™”ëœ í†µí•© ì¡°ìœ¨ íƒœìŠ¤í¬ ìƒì„±"""
        return Task(
            description=f"""ì‹¤ì œ ì¶”ì¶œëœ í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ í†µí•©í•˜ì—¬ ì™„ë²½í•œ ë§¤ê±°ì§„ êµ¬ì¡°ë¥¼ ìƒì„±í•˜ì„¸ìš”.

**í…ìŠ¤íŠ¸ ë°ì´í„° ìš”ì•½:**
- ì„¹ì…˜ ìˆ˜: {len(extracted_text_data['sections'])}ê°œ
- ì´ ê¸¸ì´: {extracted_text_data['total_content_length']} ë¬¸ì

**ì´ë¯¸ì§€ ë°ì´í„° ìš”ì•½:**
- ì´ ì´ë¯¸ì§€: {extracted_image_data['total_images']}ê°œ
- í…œí”Œë¦¿ ìˆ˜: {len(extracted_image_data['template_images'])}ê°œ

**í†µí•© ìš”êµ¬ì‚¬í•­:**
1. í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ì˜ ì™„ë²½í•œ ë§¤ì¹­
2. ê° ì„¹ì…˜ë³„ ìµœì  í…œí”Œë¦¿ ì„ íƒ
3. ì½˜í…ì¸  í’ˆì§ˆ ë³´ì¥
4. ì‹œê°ì  ì¼ê´€ì„± ìœ ì§€
5. JSX êµ¬í˜„ì„ ìœ„í•œ ì™„ì „í•œ ìŠ¤í™ ìƒì„±
6. ê° ì„¹ì…˜ë‹¹ ìµœëŒ€ 3ê°œì˜ ì´ë¯¸ì§€ë¡œ ì œí•œ
7. í´ë°± ë°ì´í„° ì ˆëŒ€ í¬í•¨ ê¸ˆì§€

**ìµœì¢… ì¶œë ¥ êµ¬ì¡°:**
{{
  "selected_templates": ["í…œí”Œë¦¿ ëª©ë¡"],
  "content_sections": [
    {{
      "template": "í…œí”Œë¦¿ëª…",
      "title": "ì‹¤ì œ ì œëª©",
      "subtitle": "ì‹¤ì œ ë¶€ì œëª©",
      "body": "ì‹¤ì œ ë³¸ë¬¸ ë‚´ìš©",
      "tagline": "íƒœê·¸ë¼ì¸",
      "images": ["ì‹¤ì œ ì´ë¯¸ì§€ URLë“¤ (ìµœëŒ€ 3ê°œ)"],
      "metadata": {{
        "content_quality": "í’ˆì§ˆ ì ìˆ˜",
        "image_count": "ì´ë¯¸ì§€ ìˆ˜",
        "source": "ë°ì´í„° ì†ŒìŠ¤"
      }}
    }}
  ],
  "integration_metadata": {{
    "total_sections": "ì„¹ì…˜ ìˆ˜",
    "integration_quality_score": "í’ˆì§ˆ ì ìˆ˜"
  }}
}}

ì´ì „ íƒœìŠ¤í¬ë“¤ì˜ ë¶„ì„ ê²°ê³¼ë¥¼ í™œìš©í•˜ì—¬ ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ì˜ ê³ í’ˆì§ˆ ë§¤ê±°ì§„ êµ¬ì¡°ë¥¼ ì™„ì„±í•˜ì„¸ìš”.""",
            expected_output="ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ ì™„ì„±ëœ ë§¤ê±°ì§„ êµ¬ì¡° JSON",
            agent=self.crew_agent,
            context=[self._create_enhanced_text_analysis_task(extracted_text_data, []),
                    self._create_enhanced_image_analysis_task(extracted_image_data, [])]
        )

    def _create_enhanced_structure(self, extracted_text_data: Dict, extracted_image_data: Dict,
                                 org_results: List[Dict], binding_results: List[Dict]) -> Dict:
        """ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ ê°•í™”ëœ êµ¬ì¡° ìƒì„±"""
        content_sections = []
        selected_templates = []
        
        # ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ì„¹ì…˜ì„ ê¸°ë°˜ìœ¼ë¡œ êµ¬ì¡° ìƒì„±
        for i, section in enumerate(extracted_text_data.get('sections', [])):
            template = section.get('template', f"Section{i+1:02d}.jsx")
            
            # í•´ë‹¹ í…œí”Œë¦¿ì˜ ì´ë¯¸ì§€ ê°€ì ¸ì˜¤ê¸°
            template_images = extracted_image_data.get('template_images', {}).get(template, [])
            
            # ì„¹ì…˜ êµ¬ì¡° ìƒì„±
            section_data = {
                "template": template,
                "title": section.get('title', ''),
                "subtitle": section.get('subtitle', ''),
                "body": section.get('body', ''),
                "tagline": section.get('tagline', 'TRAVEL & CULTURE'),
                "images": template_images[:3],  # ìµœëŒ€ 3ê°œë¡œ ì œí•œ
                "metadata": {
                    "content_quality": self._calculate_content_quality(section),
                    "image_count": len(template_images[:3]),
                    "source": section.get('layout_source', 'extracted'),
                    "real_content": True,
                    "fallback_used": False
                }
            }
            
            content_sections.append(section_data)
            selected_templates.append(template)
        
        # ìµœì†Œ 1ê°œ ì„¹ì…˜ ë³´ì¥
        if not content_sections:
            content_sections = [{
                "template": "Section01.jsx",
                "title": "ì—¬í–‰ ë§¤ê±°ì§„",
                "subtitle": "íŠ¹ë³„í•œ ì´ì•¼ê¸°",
                "body": "ë§¤ê±°ì§„ ì½˜í…ì¸ ë¥¼ ì¤€ë¹„ ì¤‘ì…ë‹ˆë‹¤.",
                "tagline": "TRAVEL & CULTURE",
                "images": [],
                "metadata": {
                    "content_quality": 0.5,
                    "image_count": 0,
                    "source": "minimal_fallback",
                    "real_content": False,
                    "fallback_used": True
                }
            }]
            selected_templates = ["Section01.jsx"]
        
        return {
            "selected_templates": selected_templates,
            "content_sections": content_sections,
            "integration_metadata": {
                "total_sections": len(content_sections),
                "total_templates": len(set(selected_templates)),
                "integration_quality_score": self._calculate_enhanced_quality_score(
                    content_sections, len(org_results), len(binding_results)
                ),
                "org_results_utilized": len(org_results),
                "binding_results_utilized": len(binding_results),
                "enhanced_structure": True,
                "real_data_based": True
            }
        }

    def _enhance_parsed_data_with_real_images(self, parsed_data: Dict, extracted_image_data: Dict) -> Dict:
        """íŒŒì‹±ëœ ë°ì´í„°ì— ì‹¤ì œ ì´ë¯¸ì§€ ì¶”ê°€"""
        if not isinstance(parsed_data, dict) or 'content_sections' not in parsed_data:
            return parsed_data
        
        content_sections = parsed_data['content_sections']
        if not isinstance(content_sections, list):
            return parsed_data
        
        # ê° ì„¹ì…˜ì— ì‹¤ì œ ì´ë¯¸ì§€ ì¶”ê°€
        for section in content_sections:
            if isinstance(section, dict):
                template = section.get('template', 'Section01.jsx')
                real_images = extracted_image_data.get('template_images', {}).get(template, [])
                
                # ê¸°ì¡´ ì´ë¯¸ì§€ë¥¼ ì‹¤ì œ ì´ë¯¸ì§€ë¡œ êµì²´ (ìµœëŒ€ 3ê°œ)
                section['images'] = real_images[:3]
                
                # ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸
                if 'metadata' not in section:
                    section['metadata'] = {}
                section['metadata']['real_images_used'] = len(real_images[:3]) > 0
                section['metadata']['image_count'] = len(real_images[:3])
        
        return parsed_data

    def _calculate_content_quality(self, section: Dict) -> float:
        """ì½˜í…ì¸  í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°"""
        score = 0.0
        
        # ì œëª© í’ˆì§ˆ (0.3)
        title = section.get('title', '')
        if title and len(title) > 5:
            score += 0.3
        elif title:
            score += 0.15
        
        # ë¶€ì œëª© í’ˆì§ˆ (0.2)
        subtitle = section.get('subtitle', '')
        if subtitle and len(subtitle) > 5:
            score += 0.2
        elif subtitle:
            score += 0.1
        
        # ë³¸ë¬¸ í’ˆì§ˆ (0.4)
        body = section.get('body', '')
        if len(body) > 200:
            score += 0.4
        elif len(body) > 100:
            score += 0.3
        elif len(body) > 50:
            score += 0.2
        elif body:
            score += 0.1
        
        # íƒœê·¸ë¼ì¸ í’ˆì§ˆ (0.1)
        tagline = section.get('tagline', '')
        if tagline and tagline != 'TRAVEL & CULTURE':
            score += 0.1
        elif tagline:
            score += 0.05
        
        return min(score, 1.0)

    def _calculate_enhanced_quality_score(self, content_sections: List[Dict], 
                                        org_results_count: int, binding_results_count: int) -> float:
        """ê°•í™”ëœ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°"""
        if not content_sections:
            return 0.0
        
        # ê¸°ë³¸ ì½˜í…ì¸  í’ˆì§ˆ ì ìˆ˜
        content_scores = [self._calculate_content_quality(section) for section in content_sections]
        avg_content_score = sum(content_scores) / len(content_scores)
        
        # ë°ì´í„° í™œìš©ë„ ì ìˆ˜
        data_utilization_score = min((org_results_count + binding_results_count) / 10.0, 1.0)
        
        # ì´ë¯¸ì§€ í™œìš©ë„ ì ìˆ˜
        total_images = sum(len(section.get('images', [])) for section in content_sections)
        image_score = min(total_images / (len(content_sections) * 2), 1.0)  # ì„¹ì…˜ë‹¹ í‰ê·  2ê°œ ì´ë¯¸ì§€ ê¸°ì¤€
        
        # ê°€ì¤‘ í‰ê·  ê³„ì‚°
        final_score = (avg_content_score * 0.5 + data_utilization_score * 0.3 + image_score * 0.2)
        
        return round(final_score, 2)

    def _format_sections_for_analysis(self, sections: List[Dict]) -> str:
        """ë¶„ì„ìš© ì„¹ì…˜ í¬ë§·íŒ…"""
        if not sections:
            return "ì„¹ì…˜ ë°ì´í„° ì—†ìŒ"
        
        formatted = []
        for i, section in enumerate(sections[:3]):  # ì²˜ìŒ 3ê°œë§Œ í‘œì‹œ
            formatted.append(f"""
ì„¹ì…˜ {i+1}:
- í…œí”Œë¦¿: {section.get('template', 'N/A')}
- ì œëª©: {section.get('title', 'N/A')[:50]}...
- ë¶€ì œëª©: {section.get('subtitle', 'N/A')[:50]}...
- ë³¸ë¬¸ ê¸¸ì´: {len(section.get('body', ''))} ë¬¸ì
- ì†ŒìŠ¤: {section.get('layout_source', 'N/A')}""")
        
        if len(sections) > 3:
            formatted.append(f"... ë° {len(sections) - 3}ê°œ ì¶”ê°€ ì„¹ì…˜")
        
        return "\n".join(formatted)

    def _format_images_for_analysis(self, template_images: Dict) -> str:
        """ë¶„ì„ìš© ì´ë¯¸ì§€ í¬ë§·íŒ…"""
        if not template_images:
            return "ì´ë¯¸ì§€ ë°ì´í„° ì—†ìŒ"
        
        formatted = []
        for template, images in template_images.items():
            formatted.append(f"- {template}: {len(images)}ê°œ ì´ë¯¸ì§€")
            for img in images[:2]:  # ì²˜ìŒ 2ê°œë§Œ í‘œì‹œ
                formatted.append(f"  * {img[:60]}...")
        
        return "\n".join(formatted)

    def _format_image_sources(self, image_sources: List[Dict]) -> str:
        """ì´ë¯¸ì§€ ì†ŒìŠ¤ ì •ë³´ í¬ë§·íŒ…"""
        if not image_sources:
            return "ì´ë¯¸ì§€ ì†ŒìŠ¤ ì •ë³´ ì—†ìŒ"
        
        formatted = []
        for source in image_sources[:5]:  # ì²˜ìŒ 5ê°œë§Œ í‘œì‹œ
            formatted.append(f"- {source.get('url', 'N/A')[:50]}... (ì†ŒìŠ¤: {source.get('source', 'N/A')})")
        
        if len(image_sources) > 5:
            formatted.append(f"... ë° {len(image_sources) - 5}ê°œ ì¶”ê°€ ì†ŒìŠ¤")
        
        return "\n".join(formatted)

    def _split_content_into_sections(self, content: str) -> List[str]:
        """ì½˜í…ì¸ ë¥¼ ì„¹ì…˜ë³„ë¡œ ë¶„í• """
        # ë‹¨ë½ ê¸°ì¤€ìœ¼ë¡œ ë¶„í• 
        paragraphs = [p.strip() for p in content.split('\n\n') if p.strip()]
        
        # ìµœì†Œ ê¸¸ì´ ì´ìƒì˜ ë‹¨ë½ë“¤ì„ ì„¹ì…˜ìœ¼ë¡œ êµ¬ì„±
        sections = []
        current_section = ""
        
        for paragraph in paragraphs:
            if len(current_section + paragraph) < 300:  # ì„¹ì…˜ë‹¹ ìµœì†Œ 300ì
                current_section += paragraph + "\n\n"
            else:
                if current_section:
                    sections.append(current_section.strip())
                current_section = paragraph + "\n\n"
        
        # ë§ˆì§€ë§‰ ì„¹ì…˜ ì¶”ê°€
        if current_section:
            sections.append(current_section.strip())
        
        return sections

    def _extract_title_from_content(self, content: str) -> str:
        """ì½˜í…ì¸ ì—ì„œ ì œëª© ì¶”ì¶œ"""
        lines = content.split('\n')
        for line in lines:
            line = line.strip()
            if line and len(line) < 100:  # ì œëª©ì€ ë³´í†µ 100ì ì´í•˜
                # íŠ¹ìˆ˜ ë¬¸ìë‚˜ ë²ˆí˜¸ ì œê±°
                cleaned = re.sub(r'^[\d\.\-\*\#\s]+', '', line)
                if len(cleaned) > 5:
                    return cleaned[:80]  # ìµœëŒ€ 80ì
        
        # ì²« ë²ˆì§¸ ë¬¸ì¥ì„ ì œëª©ìœ¼ë¡œ ì‚¬ìš©
        first_sentence = content.split('.')[0].strip()
        return first_sentence[:80] if first_sentence else "ì—¬í–‰ ì´ì•¼ê¸°"

    def _extract_subtitle_from_content(self, content: str) -> str:
        """ì½˜í…ì¸ ì—ì„œ ë¶€ì œëª© ì¶”ì¶œ"""
        lines = content.split('\n')
        
        # ë‘ ë²ˆì§¸ ì¤„ì´ë‚˜ ì²« ë²ˆì§¸ ë¬¸ì¥ ë‹¤ìŒì„ ë¶€ì œëª©ìœ¼ë¡œ ì‚¬ìš©
        if len(lines) > 1:
            subtitle = lines[1].strip()
            if subtitle and len(subtitle) < 150:
                return subtitle[:100]
        
        # ë‘ ë²ˆì§¸ ë¬¸ì¥ì„ ë¶€ì œëª©ìœ¼ë¡œ ì‚¬ìš©
        sentences = content.split('.')
        if len(sentences) > 1:
            subtitle = sentences[1].strip()
            return subtitle[:100] if subtitle else "íŠ¹ë³„í•œ ê²½í—˜"
        
        return "íŠ¹ë³„í•œ ê²½í—˜"

    def _clean_content(self, content: str) -> str:
        """ì½˜í…ì¸  ì •ë¦¬"""
        # ë¶ˆí•„ìš”í•œ ê³µë°± ì œê±°
        cleaned = re.sub(r'\n\s*\n', '\n\n', content)
        cleaned = re.sub(r'[ \t]+', ' ', cleaned)
        
        # íŠ¹ìˆ˜ ë¬¸ì ì •ë¦¬
        cleaned = re.sub(r'^[\d\.\-\*\#\s]+', '', cleaned, flags=re.MULTILINE)
        
        return cleaned.strip()

    def _extract_template_from_binding_result(self, result: Dict) -> str:
        """BindingAgent ê²°ê³¼ì—ì„œ í…œí”Œë¦¿ëª… ì¶”ì¶œ"""
        final_answer = result.get('final_answer', '')
        
        # í…œí”Œë¦¿ íŒ¨í„´ ì°¾ê¸°
        template_match = re.search(r'Section\d{2}\.jsx', final_answer)
        if template_match:
            return template_match.group()
        
        # ê¸°ë³¸ í…œí”Œë¦¿ ë°˜í™˜
        return "Section01.jsx"

    def _extract_image_source_info(self, result: Dict, url: str) -> Dict:
        """ì´ë¯¸ì§€ ì†ŒìŠ¤ ì •ë³´ ì¶”ì¶œ"""
        return {
            "url": url,
            "source": "BindingAgent",
            "agent_id": result.get('agent_id', 'unknown'),
            "timestamp": result.get('timestamp', 'unknown')
        }

    def _filter_agent_results(self, results: List[Dict], agent_name: str) -> List[Dict]:
        """íŠ¹ì • ì—ì´ì „íŠ¸ ê²°ê³¼ í•„í„°ë§"""
        filtered = []
        for result in results:
            if isinstance(result, dict):
                agent_info = result.get('agent_name', '')
                if agent_name.lower() in agent_info.lower():
                    filtered.append(result)
        return filtered

    def _deduplicate_results(self, results: List[Dict]) -> List[Dict]:
        """ê²°ê³¼ ì¤‘ë³µ ì œê±°"""
        seen_ids = set()
        deduplicated = []
        
        for result in results:
            if isinstance(result, dict):
                result_id = result.get('id', str(hash(str(result))))
                if result_id not in seen_ids:
                    seen_ids.add(result_id)
                    deduplicated.append(result)
        
        return deduplicated

    def _load_results_from_file(self) -> List[Dict]:
        """íŒŒì¼ì—ì„œ ê²°ê³¼ ë¡œë“œ"""
        try:
            results_file = "./output/agent_results.json"
            if os.path.exists(results_file):
                with open(results_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    return data if isinstance(data, list) else []
            return []
        except Exception as e:
            print(f"âš ï¸ ê²°ê³¼ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return []

    def _extract_json_from_text(self, text: str) -> Dict:
        """í…ìŠ¤íŠ¸ì—ì„œ JSON ì¶”ì¶œ ë° íŒŒì‹±"""
        try:
            # JSON ë¸”ë¡ ì°¾ê¸°
            json_match = re.search(r'\{.*\}', text, re.DOTALL)
            if json_match:
                json_str = json_match.group()
                return json.loads(json_str)
            
            # ê¸°ë³¸ êµ¬ì¡° ë°˜í™˜
            return {
                "selected_templates": [],
                "content_sections": []
            }
        except Exception as e:
            print(f"âš ï¸ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
            return {
                "selected_templates": [],
                "content_sections": []
            }

    def _validate_coordinator_result(self, result: Dict) -> bool:
        """CoordinatorAgent ê²°ê³¼ ê²€ì¦"""
        if not isinstance(result, dict):
            return False
        
        # í•„ìˆ˜ í‚¤ í™•ì¸
        required_keys = ['selected_templates', 'content_sections']
        for key in required_keys:
            if key not in result:
                return False
        
        # ì½˜í…ì¸  ì„¹ì…˜ ê²€ì¦
        content_sections = result.get('content_sections', [])
        if not isinstance(content_sections, list) or len(content_sections) == 0:
            return False
        
        # ê° ì„¹ì…˜ ê²€ì¦
        for section in content_sections:
            if not isinstance(section, dict):
                return False
            
            required_section_keys = ['template', 'title', 'body']
            for key in required_section_keys:
                if key not in section:
                    return False
        
        return True

    async def _log_coordination_result_async(self, result: Dict, text_mapping: Dict, 
                                           image_distribution: Dict, org_results: List[Dict], 
                                           binding_results: List[Dict]):
        """ë¹„ë™ê¸° ì¡°ìœ¨ ê²°ê³¼ ë¡œê¹…"""
        try:
            response_id = self.logger.log_agent_real_output(
                agent_name="CoordinatorAgent",
                agent_role="ë§¤ê±°ì§„ êµ¬ì¡° í†µí•© ì¡°ìœ¨ì",
                task_description=f"ë°°ì¹˜ ëª¨ë“œë¡œ {len(result.get('content_sections', []))}ê°œ ì„¹ì…˜ ìƒì„±",
                final_answer=str(result),
                reasoning_process="ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ ë°°ì¹˜ ì²˜ë¦¬ë¥¼ í†µí•œ ì•ˆì „í•œ ë§¤ê±°ì§„ êµ¬ì¡° í†µí•©",
                execution_steps=[
                    "ì´ì „ ê²°ê³¼ ë°°ì¹˜ ìˆ˜ì§‘",
                    "ì‹¤ì œ ë°ì´í„° ì¶”ì¶œ",
                    "CrewAI ë°°ì¹˜ ì‹¤í–‰",
                    "ê²°ê³¼ í†µí•© ë° ê²€ì¦",
                    "í’ˆì§ˆ ë³´ì¦"
                ],
                raw_input={
                    "text_mapping": str(text_mapping)[:500],
                    "image_distribution": str(image_distribution)[:500]
                },
                raw_output=result,
                performance_metrics={
                    "batch_mode_used": True,
                    "total_sections": len(result.get('content_sections', [])),
                    "org_results_utilized": len(org_results),
                    "binding_results_utilized": len(binding_results),
                    "execution_stats": self.execution_stats,
                    "quality_score": result.get('integration_metadata', {}).get('integration_quality_score', 0),
                    "real_data_used": True
                }
            )
            
            result["final_response_id"] = response_id
            result["execution_mode"] = "batch_async"
            
        except Exception as e:
            print(f"âš ï¸ ë¹„ë™ê¸° ë¡œê¹… ì‹¤íŒ¨: {e}")

    def get_execution_stats(self) -> Dict:
        """ì‹¤í–‰ í†µê³„ ë°˜í™˜"""
        return {
            **self.execution_stats,
            "success_rate": (self.execution_stats["successful_executions"] / 
                           max(self.execution_stats["total_attempts"], 1)) * 100,
            "fallback_rate": (self.execution_stats["fallback_used"] / 
                            max(self.execution_stats["total_attempts"], 1)) * 100,
            "circuit_breaker_state": self.circuit_breaker.state,
            "current_mode": "sync" if self.fallback_to_sync else "async"
        }

    def reset_execution_state(self):
        """ì‹¤í–‰ ìƒíƒœ ì´ˆê¸°í™”"""
        self.fallback_to_sync = False
        self.circuit_breaker = CircuitBreaker()
        self.execution_stats = {
            "total_attempts": 0,
            "successful_executions": 0,
            "fallback_used": 0,
            "circuit_breaker_triggered": 0,
            "timeout_occurred": 0
        }
        print("âœ… CoordinatorAgent ì‹¤í–‰ ìƒíƒœ ì´ˆê¸°í™” ì™„ë£Œ")
    async def __aenter__(self):
        """ë¹„ë™ê¸° ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì € ì§„ì…"""
        return self

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """ë¹„ë™ê¸° ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì € ì¢…ë£Œ"""
        if self.work_queue.executor:
            self.work_queue.executor.shutdown(wait=True)
        
        # ì˜ˆì™¸ ì²˜ë¦¬
        if exc_type:
            print(f"âš ï¸ CoordinatorAgent ì»¨í…ìŠ¤íŠ¸ì—ì„œ ì˜ˆì™¸ ë°œìƒ: {exc_type.__name__}: {exc_val}")
            return False  # ì˜ˆì™¸ë¥¼ ì¬ë°œìƒì‹œí‚´
        
        return True

    def __enter__(self):
        """ë™ê¸° ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì € ì§„ì…"""
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        """ë™ê¸° ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì € ì¢…ë£Œ"""
        if self.work_queue.executor:
            self.work_queue.executor.shutdown(wait=True)
        
        if exc_type:
            print(f"âš ï¸ CoordinatorAgent ë™ê¸° ì»¨í…ìŠ¤íŠ¸ì—ì„œ ì˜ˆì™¸ ë°œìƒ: {exc_type.__name__}: {exc_val}")
        
        return False

    def cleanup_resources(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        try:
            if hasattr(self.work_queue, 'executor') and self.work_queue.executor:
                self.work_queue.executor.shutdown(wait=True)
                print("âœ… ThreadPoolExecutor ì •ë¦¬ ì™„ë£Œ")
            
            # í ì •ë¦¬
            self.work_queue.work_queue.clear()
            self.work_queue.active_tasks.clear()
            self.work_queue.results.clear()
            
            print("âœ… CoordinatorAgent ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ")
            
        except Exception as e:
            print(f"âš ï¸ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")

    async def health_check(self) -> Dict[str, Any]:
        """CoordinatorAgent ìƒíƒœ í™•ì¸"""
        try:
            # ê¸°ë³¸ ìƒíƒœ ì •ë³´
            health_status = {
                "status": "healthy",
                "timestamp": time.time(),
                "execution_mode": "sync" if self.fallback_to_sync else "async",
                "circuit_breaker_state": self.circuit_breaker.state,
                "queue_size": len(self.work_queue.work_queue),
                "active_tasks": len(self.work_queue.active_tasks),
                "execution_stats": self.execution_stats
            }
            
            # LLM ì—°ê²° í™•ì¸
            try:
                if self.llm:
                    health_status["llm_status"] = "connected"
                else:
                    health_status["llm_status"] = "disconnected"
                    health_status["status"] = "degraded"
            except Exception as e:
                health_status["llm_status"] = f"error: {str(e)}"
                health_status["status"] = "degraded"
            
            # ë¡œê±° ìƒíƒœ í™•ì¸
            try:
                if self.logger:
                    health_status["logger_status"] = "connected"
                else:
                    health_status["logger_status"] = "disconnected"
                    health_status["status"] = "degraded"
            except Exception as e:
                health_status["logger_status"] = f"error: {str(e)}"
                health_status["status"] = "degraded"
            
            # ì—ì´ì „íŠ¸ ìƒíƒœ í™•ì¸
            agents_status = {}
            for agent_name, agent in [
                ("crew_agent", self.crew_agent),
                ("text_analyzer_agent", self.text_analyzer_agent),
                ("image_analyzer_agent", self.image_analyzer_agent)
            ]:
                try:
                    if agent and hasattr(agent, 'role'):
                        agents_status[agent_name] = "initialized"
                    else:
                        agents_status[agent_name] = "not_initialized"
                        health_status["status"] = "degraded"
                except Exception as e:
                    agents_status[agent_name] = f"error: {str(e)}"
                    health_status["status"] = "degraded"
            
            health_status["agents_status"] = agents_status
            
            # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸ (ì„ íƒì )
            try:
                import psutil
                process = psutil.Process()
                memory_info = process.memory_info()
                health_status["memory_usage"] = {
                    "rss": memory_info.rss,
                    "vms": memory_info.vms,
                    "percent": process.memory_percent()
                }
            except ImportError:
                health_status["memory_usage"] = "psutil not available"
            except Exception as e:
                health_status["memory_usage"] = f"error: {str(e)}"
            
            return health_status
            
        except Exception as e:
            return {
                "status": "error",
                "timestamp": time.time(),
                "error": str(e),
                "execution_stats": self.execution_stats
            }

    async def force_reset(self):
        """ê°•ì œ ì¬ì„¤ì •"""
        print("ğŸ”„ CoordinatorAgent ê°•ì œ ì¬ì„¤ì • ì‹œì‘")
        
        try:
            # 1. ì‹¤í–‰ ì¤‘ì¸ ì‘ì—… ì¤‘ë‹¨
            for task_id, task in self.work_queue.active_tasks.items():
                if not task.done():
                    task.cancel()
                    print(f"â¹ï¸ ì‘ì—… {task_id} ì·¨ì†Œ")
            
            # 2. í ë° ê²°ê³¼ ì •ë¦¬
            self.work_queue.work_queue.clear()
            self.work_queue.active_tasks.clear()
            self.work_queue.results.clear()
            
            # 3. ì‹¤í–‰ ìƒíƒœ ì´ˆê¸°í™”
            self.reset_execution_state()
            
            # 4. ì—ì´ì „íŠ¸ ì¬ìƒì„±
            self.crew_agent = self._create_crew_agent()
            self.text_analyzer_agent = self._create_text_analyzer_agent()
            self.image_analyzer_agent = self._create_image_analyzer_agent()
            
            print("âœ… CoordinatorAgent ê°•ì œ ì¬ì„¤ì • ì™„ë£Œ")
            
        except Exception as e:
            print(f"âŒ ê°•ì œ ì¬ì„¤ì • ì¤‘ ì˜¤ë¥˜: {e}")
            raise

    def get_performance_metrics(self) -> Dict[str, Any]:
        """ì„±ëŠ¥ ë©”íŠ¸ë¦­ ë°˜í™˜"""
        total_attempts = self.execution_stats["total_attempts"]
        
        if total_attempts == 0:
            return {
                "success_rate": 0.0,
                "failure_rate": 0.0,
                "fallback_rate": 0.0,
                "timeout_rate": 0.0,
                "circuit_breaker_rate": 0.0,
                "total_attempts": 0,
                "current_mode": "sync" if self.fallback_to_sync else "async",
                "circuit_breaker_state": self.circuit_breaker.state
            }
        
        return {
            "success_rate": (self.execution_stats["successful_executions"] / total_attempts) * 100,
            "failure_rate": ((total_attempts - self.execution_stats["successful_executions"]) / total_attempts) * 100,
            "fallback_rate": (self.execution_stats["fallback_used"] / total_attempts) * 100,
            "timeout_rate": (self.execution_stats["timeout_occurred"] / total_attempts) * 100,
            "circuit_breaker_rate": (self.execution_stats["circuit_breaker_triggered"] / total_attempts) * 100,
            "total_attempts": total_attempts,
            "successful_executions": self.execution_stats["successful_executions"],
            "current_mode": "sync" if self.fallback_to_sync else "async",
            "circuit_breaker_state": self.circuit_breaker.state,
            "queue_utilization": len(self.work_queue.work_queue) / self.work_queue.max_queue_size * 100,
            "active_tasks_count": len(self.work_queue.active_tasks)
        }

    async def test_coordination_pipeline(self) -> Dict[str, Any]:
        """ì¡°ìœ¨ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸"""
        print("ğŸ§ª CoordinatorAgent íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ ì‹œì‘")
        
        test_results = {
            "test_timestamp": time.time(),
            "tests_passed": 0,
            "tests_failed": 0,
            "test_details": []
        }
        
        # í…ŒìŠ¤íŠ¸ 1: ê¸°ë³¸ ì´ˆê¸°í™” í™•ì¸
        try:
            assert self.llm is not None, "LLMì´ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ"
            assert self.logger is not None, "Loggerê°€ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ"
            assert self.crew_agent is not None, "Crew Agentê°€ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ"
            
            test_results["tests_passed"] += 1
            test_results["test_details"].append({
                "test_name": "initialization_test",
                "status": "passed",
                "message": "ëª¨ë“  êµ¬ì„± ìš”ì†Œê°€ ì •ìƒì ìœ¼ë¡œ ì´ˆê¸°í™”ë¨"
            })
        except Exception as e:
            test_results["tests_failed"] += 1
            test_results["test_details"].append({
                "test_name": "initialization_test",
                "status": "failed",
                "error": str(e)
            })
        
        # í…ŒìŠ¤íŠ¸ 2: ê°„ë‹¨í•œ ì‘ì—… ì‹¤í–‰ í…ŒìŠ¤íŠ¸
        try:
            test_task_result = await self.execute_with_resilience(
                task_func=lambda: {"test": "success"},
                task_id="pipeline_test",
                timeout=30.0,
                max_retries=1
            )
            
            assert test_task_result is not None, "í…ŒìŠ¤íŠ¸ ì‘ì—… ê²°ê³¼ê°€ None"
            
            test_results["tests_passed"] += 1
            test_results["test_details"].append({
                "test_name": "task_execution_test",
                "status": "passed",
                "message": "ì‘ì—… ì‹¤í–‰ì´ ì •ìƒì ìœ¼ë¡œ ì™„ë£Œë¨",
                "result": test_task_result
            })
        except Exception as e:
            test_results["tests_failed"] += 1
            test_results["test_details"].append({
                "test_name": "task_execution_test",
                "status": "failed",
                "error": str(e)
            })
        
        # í…ŒìŠ¤íŠ¸ 3: ë°ì´í„° ì¶”ì¶œ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸
        try:
            test_text_data = {
                "sections": [{
                    "template": "Section01.jsx",
                    "title": "í…ŒìŠ¤íŠ¸ ì œëª©",
                    "body": "í…ŒìŠ¤íŠ¸ ë³¸ë¬¸ ë‚´ìš©"
                }]
            }
            
            test_image_data = {
                "template_images": {
                    "Section01.jsx": ["https://example.com/test.jpg"]
                }
            }
            
            enhanced_structure = self._create_enhanced_structure(
                test_text_data, test_image_data, [], []
            )
            
            assert isinstance(enhanced_structure, dict), "êµ¬ì¡° ìƒì„± ê²°ê³¼ê°€ ë”•ì…”ë„ˆë¦¬ê°€ ì•„ë‹˜"
            assert "content_sections" in enhanced_structure, "content_sections í‚¤ê°€ ì—†ìŒ"
            
            test_results["tests_passed"] += 1
            test_results["test_details"].append({
                "test_name": "data_extraction_test",
                "status": "passed",
                "message": "ë°ì´í„° ì¶”ì¶œ ë° êµ¬ì¡° ìƒì„±ì´ ì •ìƒì ìœ¼ë¡œ ì™„ë£Œë¨"
            })
        except Exception as e:
            test_results["tests_failed"] += 1
            test_results["test_details"].append({
                "test_name": "data_extraction_test",
                "status": "failed",
                "error": str(e)
            })
        
        # í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½
        total_tests = test_results["tests_passed"] + test_results["tests_failed"]
        test_results["success_rate"] = (test_results["tests_passed"] / total_tests * 100) if total_tests > 0 else 0
        test_results["overall_status"] = "passed" if test_results["tests_failed"] == 0 else "failed"
        
        print(f"ğŸ§ª íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ ì™„ë£Œ: {test_results['tests_passed']}/{total_tests} í†µê³¼")
        
        return test_results

# ì‚¬ìš© ì˜ˆì‹œ ë° ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
def create_coordinator_agent() -> CoordinatorAgent:
    """CoordinatorAgent ì¸ìŠ¤í„´ìŠ¤ ìƒì„±"""
    try:
        coordinator = CoordinatorAgent()
        print("âœ… CoordinatorAgent ìƒì„± ì™„ë£Œ")
        return coordinator
    except Exception as e:
        print(f"âŒ CoordinatorAgent ìƒì„± ì‹¤íŒ¨: {e}")
        raise

async def run_coordination_with_monitoring(coordinator: CoordinatorAgent, 
                                         text_mapping: Dict, 
                                         image_distribution: Dict) -> Dict:
    """ëª¨ë‹ˆí„°ë§ê³¼ í•¨ê»˜ ì¡°ìœ¨ ì‹¤í–‰"""
    start_time = time.time()
    
    try:
        # ìƒíƒœ í™•ì¸
        health_status = await coordinator.health_check()
        if health_status["status"] == "error":
            print(f"âš ï¸ CoordinatorAgent ìƒíƒœ ë¶ˆëŸ‰: {health_status}")
        
        # ì¡°ìœ¨ ì‹¤í–‰
        result = await coordinator.coordinate_magazine_creation(text_mapping, image_distribution)
        
        # ì‹¤í–‰ ì‹œê°„ ì¸¡ì •
        execution_time = time.time() - start_time
        
        # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì¶”ê°€
        result["execution_metadata"] = {
            "execution_time": execution_time,
            "performance_metrics": coordinator.get_performance_metrics(),
            "health_status": health_status
        }
        
        print(f"âœ… ì¡°ìœ¨ ì™„ë£Œ (ì‹¤í–‰ ì‹œê°„: {execution_time:.2f}ì´ˆ)")
        return result
        
    except Exception as e:
        execution_time = time.time() - start_time
        print(f"âŒ ì¡°ìœ¨ ì‹¤í–‰ ì‹¤íŒ¨ (ì‹¤í–‰ ì‹œê°„: {execution_time:.2f}ì´ˆ): {e}")
        
        # ì˜¤ë¥˜ ì •ë³´ì™€ í•¨ê»˜ í´ë°± ê²°ê³¼ ë°˜í™˜
        return {
            "selected_templates": ["Section01.jsx"],
            "content_sections": [{
                "template": "Section01.jsx",
                "title": "ë§¤ê±°ì§„ ìƒì„± ì˜¤ë¥˜",
                "subtitle": "ì‹œìŠ¤í…œ ì˜¤ë¥˜ë¡œ ì¸í•œ í´ë°±",
                "body": f"ì¡°ìœ¨ ê³¼ì •ì—ì„œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
                "tagline": "SYSTEM ERROR",
                "images": [],
                "metadata": {
                    "error_fallback": True,
                    "error_message": str(e),
                    "execution_time": execution_time
                }
            }],
            "integration_metadata": {
                "total_sections": 1,
                "error_occurred": True,
                "execution_time": execution_time,
                "performance_metrics": coordinator.get_performance_metrics()
            }
        }

# ëª¨ë“ˆ ìˆ˜ì¤€ ìœ í‹¸ë¦¬í‹°
def validate_coordination_inputs(text_mapping: Dict, image_distribution: Dict) -> bool:
    """ì¡°ìœ¨ ì…ë ¥ ë°ì´í„° ê²€ì¦"""
    try:
        # text_mapping ê²€ì¦
        if not isinstance(text_mapping, dict):
            print("âš ï¸ text_mappingì´ ë”•ì…”ë„ˆë¦¬ê°€ ì•„ë‹˜")
            return False
        
        # image_distribution ê²€ì¦
        if not isinstance(image_distribution, dict):
            print("âš ï¸ image_distributionì´ ë”•ì…”ë„ˆë¦¬ê°€ ì•„ë‹˜")
            return False
        
        print("âœ… ì¡°ìœ¨ ì…ë ¥ ë°ì´í„° ê²€ì¦ í†µê³¼")
        return True
        
    except Exception as e:
        print(f"âŒ ì…ë ¥ ë°ì´í„° ê²€ì¦ ì‹¤íŒ¨: {e}")
        return False

# ì „ì—­ ì„¤ì •
COORDINATOR_CONFIG = {
    "max_workers": 1,
    "max_queue_size": 20,
    "default_timeout": 300.0,
    "max_retries": 2,
    "circuit_breaker_threshold": 5,
    "circuit_breaker_timeout": 60.0,
    "batch_size": 2,
    "recursion_threshold": 800
}

def update_coordinator_config(**kwargs):
    """CoordinatorAgent ì„¤ì • ì—…ë°ì´íŠ¸"""
    global COORDINATOR_CONFIG
    COORDINATOR_CONFIG.update(kwargs)
    print(f"âœ… CoordinatorAgent ì„¤ì • ì—…ë°ì´íŠ¸: {kwargs}")

# ëª¨ë“ˆ ì´ˆê¸°í™” ì‹œ ì‹¤í–‰ë˜ëŠ” ì½”ë“œ
if __name__ == "__main__":
    print("ğŸš€ CoordinatorAgent ëª¨ë“ˆ ë¡œë“œ ì™„ë£Œ")
    print(f"ğŸ“‹ í˜„ì¬ ì„¤ì •: {COORDINATOR_CONFIG}")
