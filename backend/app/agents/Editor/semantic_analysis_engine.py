import asyncio
import json
import numpy as np
import open_clip
import time
from typing import Dict, List
from sklearn.metrics.pairwise import cosine_similarity
from custom_llm import get_azure_llm
from utils.hybridlogging import get_hybrid_logger
from utils.ai_search_isolation import AISearchIsolationManager
from utils.pdf_vector_manager import PDFVectorManager
from utils.session_isolation import SessionAwareMixin
from utils.agent_communication_isolation import InterAgentCommunicationMixin
from agents.Editor.image_diversity_manager import ImageDiversityManager
from utils.logging_manager import LoggingManager

class SemanticAnalysisEngine(SessionAwareMixin, InterAgentCommunicationMixin):
    """ì˜ë¯¸ì  ë¶„ì„ ì—”ì§„ - í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ì˜ ì˜ë¯¸ì  ì—°ê´€ì„± ë¶„ì„ (AI Search í†µí•©)"""
    
    def __init__(self):
        self.llm = get_azure_llm()
        self.logger = get_hybrid_logger(self.__class__.__name__)
        # AI Search ê²©ë¦¬ ì‹œìŠ¤í…œ ì¶”ê°€
        self.isolation_manager = AISearchIsolationManager()
        # PDF ë²¡í„° ë§¤ë‹ˆì € ì¶”ê°€ (ê²©ë¦¬ í™œì„±í™”)
        self.vector_manager = PDFVectorManager(isolation_enabled=True)
        self.logging_manager = LoggingManager()
        self.__init_session_awareness__()
        self.__init_inter_agent_communication__()
        self.image_diversity_manager = ImageDiversityManager()

        self._setup_logging_system()

    def _setup_logging_system(self):
        """ë¡œê·¸ ì €ì¥ ì‹œìŠ¤í…œ ì„¤ì •"""
        self.log_enabled = True
        self.response_counter = 0



    async def process_data(self, input_data):
        # ì—ì´ì „íŠ¸ ì‘ì—… ìˆ˜í–‰
        result = await self._do_work(input_data)
        
        # âœ… ì‘ë‹µ ë¡œê·¸ ì €ì¥
        await self.logging_manager.log_agent_response(
            agent_name=self.__class__.__name__,
            agent_role="ì—ì´ì „íŠ¸ ì—­í•  ì„¤ëª…",
            task_description="ìˆ˜í–‰í•œ ì‘ì—… ì„¤ëª…",
            response_data=result,  # ì‹¤ì œ ì‘ë‹µ ë°ì´í„°ë§Œ
            metadata={"additional": "info"}
        )

    async def _log_semantic_analysis_response(self, analysis_result: Dict) -> str:
        """ì˜ë¯¸ì  ë¶„ì„ ê²°ê³¼ ë¡œê·¸ ì €ì¥ (BindingAgent ë°©ì‹ ì ìš©)"""
        if not self.log_enabled:
            return "logging_disabled"
        
        try:
            response_data = {
                "agent_name": "SemanticAnalysisEngine",
                "analysis_type": "text_image_semantics",
                "text_sections": len(analysis_result.get("text_semantics", [])),
                "image_sections": len(analysis_result.get("image_semantics", [])),
                "mapping_confidence": analysis_result.get("analysis_metadata", {}).get("mapping_confidence", 0.0),
                "ai_search_enhanced": analysis_result.get("analysis_metadata", {}).get("ai_search_enhanced", False),
                "timestamp": time.time(),
                "session_id": self.current_session_id
            }
            
            response_id = f"SemanticAnalysis_{int(time.time() * 1000000)}"
            
            self.store_result(response_data)
            
            self.logger.info(f"ğŸ“¦ SemanticAnalysisEngine ì‘ë‹µ ì €ì¥: {response_id}")
            return response_id
            
        except Exception as e:
            self.logger.error(f"ë¡œê·¸ ì €ì¥ ì‹¤íŒ¨: {e}")
            return "log_save_failed"
        


        
    async def analyze_text_image_semantics(self, magazine_content: Dict, image_analysis: List[Dict]) -> Dict:
        """
        ì˜ë¯¸ì  í…ìŠ¤íŠ¸-ì´ë¯¸ì§€ ë§¤ì¹­ (ì¤‘ë³µ ì—†ì´, ì˜ë¯¸ì  êµ°ì§‘ ê¸°ë°˜)
        """
        sections = magazine_content.get("sections", [])
        if not sections or not image_analysis:
            return {"semantic_mappings": []}

        # CLIP ì„ë² ë”© ìƒì„±
        if hasattr(self, 'clip_available') and self.clip_available:
            section_texts = [sec.get("title", "") + " " + sec.get("content", "")[:200] for sec in sections]
            section_embeddings = await self._generate_clip_text_embeddings(section_texts)
            image_embeddings = await self._generate_clip_image_embeddings_from_data(image_analysis)
            similarity_matrix = cosine_similarity(section_embeddings, image_embeddings)
        else:
            similarity_matrix = None

        semantic_mappings = []
        assigned_image_indices = set()

        for i, section in enumerate(sections):
            mapping = {
                "text_section_index": i,
                "text_title": section.get("title", f"ì„¹ì…˜ {i+1}"),
                "image_matches": []
            }
            # ì˜ë¯¸ì  ìœ ì‚¬ë„ ê¸°ë°˜ ì´ë¯¸ì§€ ì„ íƒ
            if similarity_matrix is not None:
                sim_scores = list(enumerate(similarity_matrix[i]))
                sim_scores = [s for s in sim_scores if s[0] not in assigned_image_indices]
                sim_scores.sort(key=lambda x: x[1], reverse=True)
                selected_indices = [idx for idx, _ in sim_scores[:3]]
            else:
                quality_scores = [(idx, img.get("overall_quality", 0.5)) for idx, img in enumerate(image_analysis) if idx not in assigned_image_indices]
                quality_scores.sort(key=lambda x: x[1], reverse=True)
                selected_indices = [idx for idx, _ in quality_scores[:3]]

            for idx in selected_indices:
                assigned_image_indices.add(idx)
                match = image_analysis[idx].copy()
                match["image_index"] = idx
                match["similarity_score"] = similarity_matrix[i][idx] if similarity_matrix is not None else match.get("overall_quality", 0.5)
                mapping["image_matches"].append(match)

            semantic_mappings.append(mapping)

        return {"semantic_mappings": semantic_mappings}

    async def _generate_clip_text_embeddings(self, texts: List[str]) -> np.ndarray:
        import torch
        with torch.no_grad():
            text_tokens = open_clip.tokenize(texts).to(self.device)
            text_features = self.clip_model.encode_text(text_tokens)
            text_features = text_features / text_features.norm(dim=-1, keepdim=True)
            return text_features.cpu().numpy()

    async def _generate_clip_image_embeddings_from_data(self, images: List[Dict]) -> np.ndarray:
        import torch
        embeddings = []
        for img in images:
            url = img.get("image_url")
            if url and hasattr(self, "image_diversity_manager") and url in self.image_diversity_manager.image_embeddings_cache:
                embeddings.append(self.image_diversity_manager.image_embeddings_cache[url])
            else:
                # fallback: zeros
                embeddings.append(np.zeros(512))
        return np.array(embeddings)

    # _generate_optimal_combinations_with_ai_searchëŠ” ê¸°ì¡´ ë¡œì§ì—ì„œ ì¤‘ë³µ ë°©ì§€ì™€ ì˜ë¯¸ì  ë§¤ì¹­ë§Œ ìœ ì§€
    async def _generate_optimal_combinations_with_ai_search(self, semantic_mappings: List[Dict]) -> List[Dict]:
        """
        ì˜ë¯¸ì  ë¶„ì„ ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì„¹ì…˜ë³„ ìµœì  ì´ë¯¸ì§€ ì¡°í•© ìƒì„± (ì¤‘ë³µ ì—†ì´)
        """
        optimal_combinations = []
        used_images = set()
        for mapping in semantic_mappings:
            section_index = mapping["text_section_index"]
            section_title = mapping["text_title"]
            best_images = []
            for image_match in mapping["image_matches"]:
                if image_match["image_index"] not in used_images:
                    best_images.append(image_match)
                    used_images.add(image_match["image_index"])
            optimal_combinations.append({
                "section_index": section_index,
                "section_title": section_title,
                "assigned_images": best_images,
                "total_similarity_score": sum(img["similarity_score"] for img in best_images),
                "ai_search_enhanced": True,
                "optimization_notes": f"{len(best_images)}ê°œ ì´ë¯¸ì§€ í• ë‹¹ë¨ (ì¤‘ë³µ ì—†ì´ ì˜ë¯¸ì  ë§¤ì¹­)"
            })
        return optimal_combinations
    
    async def _extract_text_semantics_with_vector_search(self, content: Dict) -> List[Dict]:
        """AI Search ë²¡í„° ê²€ìƒ‰ì„ í™œìš©í•œ í…ìŠ¤íŠ¸ ì˜ë¯¸ ì¶”ì¶œ"""
        
        text_sections = []
        
        if isinstance(content, dict) and "sections" in content:
            for i, section in enumerate(content["sections"]):
                # ì„¹ì…˜ë³„ ì˜¤ì—¼ ê²€ì‚¬
                if self.isolation_manager.is_contaminated(section, f"text_section_{i}"):
                    self.logger.warning(f"í…ìŠ¤íŠ¸ ì„¹ì…˜ {i}ì—ì„œ ì˜¤ì—¼ ê°ì§€, ì›ë³¸ ë°ì´í„° ì‚¬ìš©")
                    section = self.isolation_manager.restore_original_content(section)
                
                # AI Search ë²¡í„° ê²€ìƒ‰ìœ¼ë¡œ ìœ ì‚¬í•œ ë§¤ê±°ì§„ íŒ¨í„´ ì°¾ê¸°
                section_content = section.get("content", "")
                similar_patterns = await self._search_similar_text_patterns(section_content)
                
                semantic_info = await self._analyze_text_section_with_patterns(section, i, similar_patterns)
                text_sections.append(semantic_info)
        
        return text_sections
    
    async def _search_similar_text_patterns(self, section_content: str) -> List[Dict]:
        """AI Searchì—ì„œ ìœ ì‚¬í•œ í…ìŠ¤íŠ¸ íŒ¨í„´ ê²€ìƒ‰"""
        
        try:
            # AI Search í‚¤ì›Œë“œ í•„í„°ë§
            clean_query = self.isolation_manager.clean_query_from_azure_keywords(section_content[:300])
            
            # ë²¡í„° ê²€ìƒ‰ ì‹¤í–‰ (í…ìŠ¤íŠ¸ íŒ¨í„´ ì¤‘ì‹¬)
            similar_patterns = await asyncio.get_event_loop().run_in_executor(
                None,
                lambda: self.vector_manager.search_similar_layouts(
                    clean_query, "text-semantic-patterns-index", top_k=8
                )
            )
            
            # ê²©ë¦¬ëœ íŒ¨í„´ë§Œ ë°˜í™˜
            isolated_patterns = self.isolation_manager.filter_contaminated_data(
                similar_patterns, "text_patterns"
            )
            
            self.logger.debug(f"í…ìŠ¤íŠ¸ íŒ¨í„´ ê²€ìƒ‰: {len(similar_patterns)} â†’ {len(isolated_patterns)}ê°œ")
            return isolated_patterns
            
        except Exception as e:
            self.logger.error(f"í…ìŠ¤íŠ¸ íŒ¨í„´ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []
    
    async def _analyze_text_section_with_patterns(self, section: Dict, index: int, patterns: List[Dict]) -> Dict:
        """AI Search íŒ¨í„´ì„ ì°¸ì¡°í•œ í…ìŠ¤íŠ¸ ì„¹ì…˜ ë¶„ì„"""
        
        section_content = section.get("content", "")
        title = section.get("title", "")
        
        # AI Search í‚¤ì›Œë“œ í•„í„°ë§
        filtered_content = self.isolation_manager.clean_query_from_azure_keywords(section_content)
        filtered_title = self.isolation_manager.clean_query_from_azure_keywords(title)
        
        # íŒ¨í„´ ê¸°ë°˜ ë¶„ì„ í”„ë¡¬í”„íŠ¸ ìƒì„±
        pattern_context = ""
        if patterns:
            pattern_info = []
            for pattern in patterns[:3]:  # ìƒìœ„ 3ê°œ íŒ¨í„´ë§Œ ì‚¬ìš©
                pattern_info.append({
                    "ê¸€_í˜•íƒœ": pattern.get("text_structure", "ì¼ë°˜í˜•"),
                    "ë¬¸ì¥_ê¸¸ì´": pattern.get("sentence_length", "ì¤‘ê°„"),
                    "ê¸€_ë§ºìŒ": pattern.get("conclusion_style", "ìì—°ìŠ¤ëŸ¬ìš´"),
                    "ì„¹ì…˜_êµ¬ì¡°": pattern.get("section_format", "ì œëª©-ë³¸ë¬¸")
                })
            pattern_context = f"ì°¸ì¡° íŒ¨í„´: {json.dumps(pattern_info, ensure_ascii=False)}"
        
        analysis_prompt = f"""
ë‹¤ìŒ í…ìŠ¤íŠ¸ ì„¹ì…˜ì˜ ì˜ë¯¸ì  ìš”ì†Œë¥¼ ë¶„ì„í•˜ì„¸ìš”:

ì œëª©: {filtered_title}
ë‚´ìš©: {filtered_content}

{pattern_context}

ë¶„ì„ í•­ëª©:
1. ì£¼ìš” ì£¼ì œ (êµ¬ì²´ì  í‚¤ì›Œë“œ ì¶”ì¶œ)
2. ê°ì •ì  í†¤ (ê¸ì •ì , ì¤‘ì„±ì , ì„±ì°°ì  ë“±)
3. ì‹œê°ì  ì—°ê´€ í‚¤ì›Œë“œ (ìƒ‰ìƒ, í’ê²½, ê±´ë¬¼, ì‚¬ëŒ ë“±)
4. ê³„ì ˆ/ì‹œê°„ëŒ€ ì •ë³´
5. ë¬¸í™”ì  ìš”ì†Œ
6. ê¸€ì˜ í˜•íƒœ (ì„œìˆ í˜•, ëŒ€í™”í˜•, ì„¤ëª…í˜• ë“±)
7. ë¬¸ì¥ ê¸¸ì´ íŠ¹ì„± (ì§§ì€/ì¤‘ê°„/ê¸´ ë¬¸ì¥ ë¹„ìœ¨)

ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•˜ì„¸ìš”.
"""
        
        try:
            response = await self.llm.ainvoke(analysis_prompt)
            
            #  ê°•í™”ëœ ì‘ë‹µ ì²˜ë¦¬
            if not response or not response.strip():
                self.logger.warning(f"í…ìŠ¤íŠ¸ ì„¹ì…˜ {index} ë¶„ì„ì—ì„œ ë¹ˆ ì‘ë‹µ ìˆ˜ì‹ ")
                return self._get_clean_section_fallback(index, title, section_content)
            
            #  ì‘ë‹µ ê¸¸ì´ ì²´í¬
            if len(response.strip()) < 5:
                self.logger.warning(f"í…ìŠ¤íŠ¸ ì„¹ì…˜ {index} ì‘ë‹µì´ ë„ˆë¬´ ì§§ìŒ: {response}")
                return self._get_clean_section_fallback(index, title, section_content)
            
            #  ê°•í™”ëœ JSON ì¶”ì¶œ
            cleaned_response = self._extract_json_from_response(response.strip())
            
            #  JSON ê²€ì¦ ë° ìˆ˜ì •
            validated_json = self._validate_and_fix_json(cleaned_response)
            
            # JSON íŒŒì‹± ì‹œë„
            try:
                analysis_result = json.loads(validated_json)
            except json.JSONDecodeError as json_error:
                self.logger.error(f"í…ìŠ¤íŠ¸ ì„¹ì…˜ {index} JSON íŒŒì‹± ìµœì¢… ì‹¤íŒ¨: {json_error}")
                self.logger.debug(f"ì›ë³¸ ì‘ë‹µ: {response[:200]}...")
                self.logger.debug(f"ì •ì œëœ ì‘ë‹µ: {cleaned_response[:200]}...")
                self.logger.debug(f"ê²€ì¦ëœ JSON: {validated_json[:200]}...")
                
                #  ìµœí›„ì˜ ìˆ˜ë‹¨: ì •ê·œì‹ìœ¼ë¡œ í‚¤ì›Œë“œ ì¶”ì¶œ
                fallback_result = self._extract_keywords_with_regex(response)
                if fallback_result:
                    analysis_result = fallback_result
                else:
                    return self._get_clean_section_fallback(index, title, section_content)
            
            # ë¶„ì„ ê²°ê³¼ ì˜¤ì—¼ ê²€ì‚¬
            if self.isolation_manager.is_contaminated(analysis_result, f"analysis_result_{index}"):
                self.logger.warning(f"ë¶„ì„ ê²°ê³¼ {index}ì—ì„œ ì˜¤ì—¼ ê°ì§€, ê¸°ë³¸ê°’ ì‚¬ìš©")
                analysis_result = self._get_clean_analysis_fallback()
            
            return {
                "section_index": index,
                "title": title,
                "content_preview": section_content[:200],
                "semantic_analysis": analysis_result,
                "confidence_score": 0.8,
                "ai_search_patterns": len(patterns),
                "isolation_metadata": {
                    "patterns_referenced": len(patterns),
                    "contamination_detected": False,
                    "original_preserved": True
                }
            }
            
        except Exception as e:
            self.logger.error(f"í…ìŠ¤íŠ¸ ì„¹ì…˜ {index} ë¶„ì„ ì‹¤íŒ¨: {e}")
            return self._get_clean_section_fallback(index, title, section_content)
    
    def _extract_keywords_with_regex(self, response: str) -> Dict:
        """ì •ê·œì‹ì„ ì‚¬ìš©í•œ í‚¤ì›Œë“œ ì¶”ì¶œ (ìµœí›„ì˜ ìˆ˜ë‹¨)"""
        
        import re
        
        result = {
            "ì£¼ìš”_ì£¼ì œ": [],
            "ê°ì •ì _í†¤": "ì¤‘ì„±ì ",
            "ì‹œê°ì _í‚¤ì›Œë“œ": [],
            "ê³„ì ˆ_ì‹œê°„": "ì•Œ ìˆ˜ ì—†ìŒ",
            "ë¬¸í™”ì _ìš”ì†Œ": [],
            "ê¸€ì˜_í˜•íƒœ": "ì„œìˆ í˜•",
            "ë¬¸ì¥_ê¸¸ì´_íŠ¹ì„±": "ì¤‘ê°„"
        }
        
        try:
            # ì£¼ìš” ì£¼ì œ ì¶”ì¶œ
            topic_patterns = [
                r'ì£¼ìš”[_\s]*ì£¼ì œ[:\s]*([^\n\r,]+)',
                r'í‚¤ì›Œë“œ[:\s]*([^\n\r,]+)',
                r'ì—¬í–‰|ë² ë„¤ì¹˜ì•„|ì´íƒˆë¦¬ì•„|ë¬¸í™”|ì˜ˆìˆ '
            ]
            
            for pattern in topic_patterns:
                matches = re.findall(pattern, response, re.IGNORECASE)
                if matches:
                    result["ì£¼ìš”_ì£¼ì œ"].extend([m.strip() for m in matches if m.strip()])
            
            # ê°ì •ì  í†¤ ì¶”ì¶œ
            tone_patterns = r'(ê¸ì •ì |ë¶€ì •ì |ì¤‘ì„±ì |ì„±ì°°ì |ê°ì„±ì |ë‚­ë§Œì )'
            tone_match = re.search(tone_patterns, response, re.IGNORECASE)
            if tone_match:
                result["ê°ì •ì _í†¤"] = tone_match.group(1)
            
            # ì‹œê°ì  í‚¤ì›Œë“œ ì¶”ì¶œ
            visual_patterns = r'(ìƒ‰ìƒ|í’ê²½|ê±´ë¬¼|ë°”ë‹¤|í•˜ëŠ˜|ê±°ë¦¬|ê´‘ì¥|ë‹¤ë¦¬)'
            visual_matches = re.findall(visual_patterns, response, re.IGNORECASE)
            if visual_matches:
                result["ì‹œê°ì _í‚¤ì›Œë“œ"] = visual_matches
            
            self.logger.info(f"ì •ê·œì‹ìœ¼ë¡œ í‚¤ì›Œë“œ ì¶”ì¶œ ì„±ê³µ: {len(result['ì£¼ìš”_ì£¼ì œ'])}ê°œ ì£¼ì œ")
            return result
            
        except Exception as e:
            self.logger.error(f"ì •ê·œì‹ í‚¤ì›Œë“œ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return None



    async def _extract_image_semantics_with_layout_patterns_batch(self, images: List[Dict]) -> List[Dict]:
        """AI Search ë ˆì´ì•„ì›ƒ íŒ¨í„´ì„ ì°¸ì¡°í•œ ì´ë¯¸ì§€ ì˜ë¯¸ ì¶”ì¶œ (ë°°ì¹˜ ì²˜ë¦¬)"""
        
        # ì„¸ë§ˆí¬ì–´ë¡œ ë™ì‹œ ì²˜ë¦¬ ì œí•œ
        semaphore = asyncio.Semaphore(5)  # ìµœëŒ€ 5ê°œ ë™ì‹œ ì²˜ë¦¬
        
        async def process_single_image(i: int, image: Dict) -> Dict:
            async with semaphore:
                try:
                    layout_patterns = await self._search_image_layout_patterns(image)
                    return await self._analyze_image_with_layout_patterns(image, i, layout_patterns)
                except Exception as e:
                    self.logger.error(f"ì´ë¯¸ì§€ {i} ë°°ì¹˜ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                    return self._get_clean_image_fallback(i, image.get("image_name", f"image_{i}"),
                                                       image.get("location", ""), image.get("image_url", ""))
        
        # ë³‘ë ¬ ì²˜ë¦¬
        tasks = [process_single_image(i, image) for i, image in enumerate(images)]
        image_semantics = await asyncio.gather(*tasks, return_exceptions=True)
        
        # ì˜ˆì™¸ ì²˜ë¦¬ëœ ê²°ê³¼ í•„í„°ë§
        valid_results = []
        for i, result in enumerate(image_semantics):
            if isinstance(result, Exception):
                self.logger.error(f"ì´ë¯¸ì§€ {i} ì²˜ë¦¬ ì˜ˆì™¸: {result}")
                valid_results.append(self._get_clean_image_fallback(i, f"image_{i}", "", ""))
            else:
                valid_results.append(result)
        
        return valid_results
    
    async def _extract_image_semantics_with_layout_patterns(self, images: List[Dict]) -> List[Dict]:
        """AI Search ë ˆì´ì•„ì›ƒ íŒ¨í„´ì„ ì°¸ì¡°í•œ ì´ë¯¸ì§€ ì˜ë¯¸ ì¶”ì¶œ"""
        
        image_semantics = []
        
        for i, image in enumerate(images):
            # ì´ë¯¸ì§€ë³„ ë ˆì´ì•„ì›ƒ íŒ¨í„´ ê²€ìƒ‰
            layout_patterns = await self._search_image_layout_patterns(image)
            
            semantic_info = await self._analyze_image_with_layout_patterns(image, i, layout_patterns)
            image_semantics.append(semantic_info)
        
        return image_semantics
    
    async def _search_image_layout_patterns(self, image: Dict) -> List[Dict]:
        """ì´ë¯¸ì§€ ë°°ì¹˜ë¥¼ ìœ„í•œ AI Search ë ˆì´ì•„ì›ƒ íŒ¨í„´ ê²€ìƒ‰"""
        
        try:
            image_location = image.get("location", "")
            image_name = image.get("image_name", "")
            
            # ì´ë¯¸ì§€ íŠ¹ì„± ê¸°ë°˜ ì¿¼ë¦¬ ìƒì„±
            search_query = f"ì´ë¯¸ì§€ ë°°ì¹˜ ë ˆì´ì•„ì›ƒ {image_location} {image_name}"
            clean_query = self.isolation_manager.clean_query_from_azure_keywords(search_query)
            
            # ë ˆì´ì•„ì›ƒ íŒ¨í„´ ê²€ìƒ‰
            layout_patterns = await asyncio.get_event_loop().run_in_executor(
                None,
                lambda: self.vector_manager.search_similar_layouts(
                    clean_query, "magazine-vector-index", top_k=5
                )
            )
            
            # ê²©ë¦¬ëœ íŒ¨í„´ë§Œ ë°˜í™˜
            isolated_patterns = self.isolation_manager.filter_contaminated_data(
                layout_patterns, "image_layout_patterns"
            )
            
            return isolated_patterns
            
        except Exception as e:
            self.logger.error(f"ì´ë¯¸ì§€ ë ˆì´ì•„ì›ƒ íŒ¨í„´ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []
    
    async def _analyze_image_with_layout_patterns(self, image: Dict, index: int, patterns: List[Dict]) -> Dict:
        """ë ˆì´ì•„ì›ƒ íŒ¨í„´ì„ ì°¸ì¡°í•œ ì´ë¯¸ì§€ ë¶„ì„"""
        
        image_name = image.get("image_name", f"image_{index}")
        location = image.get("location", "")
        image_url = image.get("image_url", "")
        
        # íŒ¨í„´ ê¸°ë°˜ ë ˆì´ì•„ì›ƒ ì •ë³´ ìƒì„±
        layout_context = ""
        if patterns:
            layout_info = []
            for pattern in patterns[:3]:
                layout_info.append({
                    "ì´ë¯¸ì§€_í¬ê¸°": pattern.get("image_size", "ì¤‘ê°„"),
                    "ë°°ì¹˜_ìœ„ì¹˜": pattern.get("placement", "ìƒë‹¨"),
                    "í…ìŠ¤íŠ¸_ê°„ê²©": pattern.get("text_spacing", "ì ë‹¹í•¨"),
                    "ì´ë¯¸ì§€_ê°œìˆ˜": pattern.get("image_count", 1)
                })
            layout_context = f"ë ˆì´ì•„ì›ƒ ì°¸ì¡°: {json.dumps(layout_info, ensure_ascii=False)}"
        
        analysis_prompt = f"""
ë‹¤ìŒ ì´ë¯¸ì§€ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì˜ë¯¸ì  ìš”ì†Œë¥¼ ë¶„ì„í•˜ì„¸ìš”:

ì´ë¯¸ì§€ëª…: {image_name}
ìœ„ì¹˜ ì •ë³´: {location}

{layout_context}

ë¶„ì„ í•­ëª©:
1. ì§€ë¦¬ì  íŠ¹ì„± (ë„ì‹œ, ìì—°, ê±´ë¬¼ ë“±)
2. ì‹œê°ì  íŠ¹ì§• (ìƒ‰ìƒ, êµ¬ë„, ë¶„ìœ„ê¸° ë“±)
3. ë¬¸í™”ì  ë§¥ë½
4. ê°ì •ì  ì„íŒ©íŠ¸
5. ì‹œê°„ëŒ€/ê³„ì ˆ ì¶”ì •
6. ì í•©í•œ ì´ë¯¸ì§€ í¬ê¸° (ì‘ì€/ì¤‘ê°„/í°)
7. ê¶Œì¥ ë°°ì¹˜ ìœ„ì¹˜ (ìƒë‹¨/ì¤‘ê°„/í•˜ë‹¨)
8. í…ìŠ¤íŠ¸ì™€ì˜ ì ì • ê°„ê²©

ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•˜ì„¸ìš”.
"""
        
        try:
            response = await self.llm.ainvoke(analysis_prompt)
            
            # âœ… ë™ì¼í•œ ê°•í™”ëœ JSON ì²˜ë¦¬ ë¡œì§ ì ìš©
            if not response or not response.strip():
                self.logger.warning(f"ì´ë¯¸ì§€ {index} ë¶„ì„ì—ì„œ ë¹ˆ ì‘ë‹µ ìˆ˜ì‹ ")
                return self._get_clean_image_fallback(index, image_name, location, image_url)
            
            cleaned_response = self._extract_json_from_response(response.strip())
            validated_json = self._validate_and_fix_json(cleaned_response)
            
            try:
                analysis_result = json.loads(validated_json)
            except json.JSONDecodeError as json_error:
                self.logger.error(f"ì´ë¯¸ì§€ {index} JSON íŒŒì‹± ìµœì¢… ì‹¤íŒ¨: {json_error}")
                # ì´ë¯¸ì§€ìš© ì •ê·œì‹ í‚¤ì›Œë“œ ì¶”ì¶œë„ êµ¬í˜„ ê°€ëŠ¥
                return self._get_clean_image_fallback(index, image_name, location, image_url)
            
            return {
                "image_index": index,
                "image_name": image_name,
                "location": location,
                "image_url": image_url,
                "semantic_analysis": analysis_result,
                "confidence_score": 0.8,
                "layout_patterns": len(patterns),
                "isolation_metadata": {
                    "patterns_referenced": len(patterns),
                    "contamination_detected": False
                }
            }
            
        except Exception as e:
            self.logger.error(f"ì´ë¯¸ì§€ {index} ë¶„ì„ ì‹¤íŒ¨: {e}")
            return self._get_clean_image_fallback(index, image_name, location, image_url)
    
    async def _perform_semantic_matching_with_vectors(self, text_semantics: List[Dict],
                                                    image_semantics: List[Dict]) -> List[Dict]:
        """ë²¡í„° ë°ì´í„° ê¸°ë°˜ ì˜ë¯¸ì  ë§¤ì¹­"""
        
        mappings = []
        
        for text_section in text_semantics:
            section_mappings = []
            
            for image in image_semantics:
                # AI Search íŒ¨í„´ì„ ê³ ë ¤í•œ ìœ ì‚¬ë„ ê³„ì‚°
                similarity_score = await self._calculate_semantic_similarity_with_patterns(
                    text_section, image
                )
                
                section_mappings.append({
                    "image_index": image["image_index"],
                    "image_name": image["image_name"],
                    "similarity_score": similarity_score,
                    "matching_factors": self._identify_matching_factors_with_patterns(text_section, image),
                    "layout_recommendation": self._get_layout_recommendation(text_section, image)
                })
            
            # ìœ ì‚¬ë„ ìˆœìœ¼ë¡œ ì •ë ¬
            section_mappings.sort(key=lambda x: x["similarity_score"], reverse=True)
            
            mappings.append({
                "text_section_index": text_section["section_index"],
                "text_title": text_section["title"],
                "image_matches": section_mappings[:5]
            })
        
        return mappings
    
    def _extract_json_from_response(self, response: str) -> str:
        """LLM ì‘ë‹µì—ì„œ JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ (ê°•í™”ëœ ë²„ì „)"""
        
        if not response or not response.strip():
            return "{}"  # ë¹ˆ ì‘ë‹µ ì‹œ ê¸°ë³¸ JSON ë°˜í™˜
        
        response = response.strip()
        
        # 1. ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì œê±° (ë‹¤ì–‘í•œ íŒ¨í„´ ì§€ì›)
        patterns = [
            r'``````',  # ``````
            r'``````',      # ``````
            r'`(.*?)`',                # `...`
        ]
        
        for pattern in patterns:
            import re
            match = re.search(pattern, response, re.DOTALL | re.IGNORECASE)
            if match:
                extracted = match.group(1).strip()
                if extracted and (extracted.startswith('{') or extracted.startswith('[')):
                    return extracted
        
        # 2. HTML/XML íƒœê·¸ ì œê±°
        if response.startswith('<'):
            # HTML/XML ì‘ë‹µì¸ ê²½ìš° JSON ë¶€ë¶„ ì°¾ê¸°
            import re
            json_match = re.search(r'\{.*\}', response, re.DOTALL)
            if json_match:
                return json_match.group(0)
            else:
                return "{}"  # JSONì„ ì°¾ì„ ìˆ˜ ì—†ìœ¼ë©´ ë¹ˆ ê°ì²´
        
        # 3. ì²« ë²ˆì§¸ì™€ ë§ˆì§€ë§‰ ì¤‘ê´„í˜¸ ì‚¬ì´ì˜ ë‚´ìš© ì¶”ì¶œ
        first_brace = response.find('{')
        last_brace = response.rfind('}')
        
        if first_brace != -1 and last_brace != -1 and first_brace < last_brace:
            potential_json = response[first_brace:last_brace + 1]
            return potential_json
        
        # 4. ë°°ì—´ í˜•íƒœ JSON ì²˜ë¦¬
        first_bracket = response.find('[')
        last_bracket = response.rfind(']')
        
        if first_bracket != -1 and last_bracket != -1 and first_bracket < last_bracket:
            potential_json = response[first_bracket:last_bracket + 1]
            return potential_json
        
        # 5. ëª¨ë“  ë°©ë²•ì´ ì‹¤íŒ¨í•˜ë©´ ì›ë³¸ ë°˜í™˜
        return response.strip()

    def _validate_and_fix_json(self, json_str: str) -> str:
        """JSON ë¬¸ìì—´ ê²€ì¦ ë° ìˆ˜ì •"""
        
        try:
            # 1. ê¸°ë³¸ JSON íŒŒì‹± ì‹œë„
            json.loads(json_str)
            return json_str
        except json.JSONDecodeError:
            pass
        
        # 2. ì¼ë°˜ì ì¸ JSON ì˜¤ë¥˜ ìˆ˜ì • ì‹œë„
        fixed_json = json_str
        
        # ë”°ì˜´í‘œ ë¬¸ì œ ìˆ˜ì •
        fixed_json = fixed_json.replace("'", '"')  # ë‹¨ì¼ ë”°ì˜´í‘œë¥¼ ì´ì¤‘ ë”°ì˜´í‘œë¡œ
        fixed_json = fixed_json.replace('True', 'true')  # Python boolì„ JSON boolë¡œ
        fixed_json = fixed_json.replace('False', 'false')
        fixed_json = fixed_json.replace('None', 'null')
        
        # ë§ˆì§€ë§‰ ì‰¼í‘œ ì œê±°
        import re
        fixed_json = re.sub(r',\s*}', '}', fixed_json)
        fixed_json = re.sub(r',\s*]', ']', fixed_json)
        
        try:
            json.loads(fixed_json)
            return fixed_json
        except json.JSONDecodeError:
            pass
        
        # 3. ë” ê³µê²©ì ì¸ ìˆ˜ì • ì‹œë„
        try:
            # í‚¤ì— ë”°ì˜´í‘œ ì¶”ê°€
            fixed_json = re.sub(r'(\w+):', r'"\1":', fixed_json)
            json.loads(fixed_json)
            return fixed_json
        except:
            pass
        
        # 4. ëª¨ë“  ìˆ˜ì • ì‹œë„ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ JSON ë°˜í™˜
        return '{"error": "JSON íŒŒì‹± ì‹¤íŒ¨", "original": "' + json_str.replace('"', '\\"')[:100] + '"}'




    async def _calculate_semantic_similarity_with_patterns(self, text_section: Dict, image: Dict) -> float:
        """AI Search íŒ¨í„´ì„ ê³ ë ¤í•œ ì˜ë¯¸ì  ìœ ì‚¬ë„ ê³„ì‚°"""
        
        text_analysis = text_section.get("semantic_analysis", {})
        image_analysis = image.get("semantic_analysis", {})
        
        similarity_factors = []
        
        # ê¸°ë³¸ ì˜ë¯¸ì  ë§¤ì¹­
        text_keywords = text_analysis.get("ì‹œê°ì _í‚¤ì›Œë“œ", [])
        image_features = image_analysis.get("ì§€ë¦¬ì _íŠ¹ì„±", [])
        keyword_match = len(set(text_keywords) & set(image_features)) / max(len(text_keywords), 1)
        similarity_factors.append(keyword_match * 0.3)
        
        # ê°ì •ì  í†¤ ë§¤ì¹­
        text_tone = text_analysis.get("ê°ì •ì _í†¤", "")
        image_impact = image_analysis.get("ê°ì •ì _ì„íŒ©íŠ¸", "")
        tone_match = 1.0 if text_tone == image_impact else 0.5
        similarity_factors.append(tone_match * 0.2)
        
        # AI Search íŒ¨í„´ ê¸°ë°˜ ë ˆì´ì•„ì›ƒ ì í•©ì„±
        layout_compatibility = self._calculate_layout_compatibility(text_section, image)
        similarity_factors.append(layout_compatibility * 0.3)
        
        # ë¬¸í™”ì /ì§€ë¦¬ì  ì—°ê´€ì„±
        cultural_match = self._calculate_cultural_relevance(text_analysis, image_analysis)
        similarity_factors.append(cultural_match * 0.2)
        
        # ì „ì²´ ìœ ì‚¬ë„ ê³„ì‚°
        total_similarity = sum(similarity_factors)
        
        # ì‹ ë¢°ë„ ê°€ì¤‘ì¹˜ ì ìš©
        confidence_weight = (text_section.get("confidence_score", 0.5) + 
                           image.get("confidence_score", 0.5)) / 2
        
        return min(total_similarity * confidence_weight, 1.0)
    
    def _calculate_layout_compatibility(self, text_section: Dict, image: Dict) -> float:
        """ë ˆì´ì•„ì›ƒ í˜¸í™˜ì„± ê³„ì‚°"""
        
        text_patterns = text_section.get("ai_search_patterns", 0)
        image_patterns = image.get("layout_patterns", 0)
        
        # íŒ¨í„´ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ë†’ì€ ì ìˆ˜
        if text_patterns > 0 and image_patterns > 0:
            return 0.9
        elif text_patterns > 0 or image_patterns > 0:
            return 0.7
        else:
            return 0.5
    
    def _calculate_cultural_relevance(self, text_analysis: Dict, image_analysis: Dict) -> float:
        """ë¬¸í™”ì  ì—°ê´€ì„± ê³„ì‚°"""
        
        text_cultural = text_analysis.get("ë¬¸í™”ì _ìš”ì†Œ", [])
        image_cultural = image_analysis.get("ë¬¸í™”ì _ë§¥ë½", [])
        
        if not text_cultural and not image_cultural:
            return 0.5
        
        common_cultural = set(text_cultural) & set(image_cultural)
        total_cultural = set(text_cultural) | set(image_cultural)
        
        if not total_cultural:
            return 0.5
        
        return len(common_cultural) / len(total_cultural)
    
    def _identify_matching_factors_with_patterns(self, text_section: Dict, image: Dict) -> List[str]:
        """AI Search íŒ¨í„´ì„ ê³ ë ¤í•œ ë§¤ì¹­ ìš”ì¸ ì‹ë³„"""
        
        factors = []
        
        text_analysis = text_section.get("semantic_analysis", {})
        image_analysis = image.get("semantic_analysis", {})
        
        # ê¸°ë³¸ ë§¤ì¹­ ìš”ì¸
        text_keywords = set(text_analysis.get("ì‹œê°ì _í‚¤ì›Œë“œ", []))
        image_features = set(image_analysis.get("ì§€ë¦¬ì _íŠ¹ì„±", []))
        
        common_elements = text_keywords & image_features
        if common_elements:
            factors.append(f"ê³µí†µ_ìš”ì†Œ: {', '.join(common_elements)}")
        
        # AI Search íŒ¨í„´ ê¸°ë°˜ ìš”ì¸
        if text_section.get("ai_search_patterns", 0) > 0:
            factors.append("í…ìŠ¤íŠ¸_íŒ¨í„´_ì°¸ì¡°")
        
        if image.get("layout_patterns", 0) > 0:
            factors.append("ë ˆì´ì•„ì›ƒ_íŒ¨í„´_ì°¸ì¡°")
        
        # ë ˆì´ì•„ì›ƒ í˜¸í™˜ì„±
        layout_score = self._calculate_layout_compatibility(text_section, image)
        if layout_score > 0.8:
            factors.append("ë ˆì´ì•„ì›ƒ_ê³ ë„_í˜¸í™˜")
        elif layout_score > 0.6:
            factors.append("ë ˆì´ì•„ì›ƒ_ì ë‹¹_í˜¸í™˜")
        
        return factors
    
    def _get_layout_recommendation(self, text_section: Dict, image: Dict) -> Dict:
        """ë ˆì´ì•„ì›ƒ ì¶”ì²œ ìƒì„±"""
        
        image_analysis = image.get("semantic_analysis", {})
        
        return {
            "ê¶Œì¥_ì´ë¯¸ì§€_í¬ê¸°": image_analysis.get("ì í•©í•œ_ì´ë¯¸ì§€_í¬ê¸°", "ì¤‘ê°„"),
            "ê¶Œì¥_ë°°ì¹˜_ìœ„ì¹˜": image_analysis.get("ê¶Œì¥_ë°°ì¹˜_ìœ„ì¹˜", "ìƒë‹¨"),
            "í…ìŠ¤íŠ¸_ê°„ê²©": image_analysis.get("í…ìŠ¤íŠ¸ì™€ì˜_ì ì •_ê°„ê²©", "ì ë‹¹í•¨"),
            "íŒ¨í„´_ê¸°ë°˜": text_section.get("ai_search_patterns", 0) > 0 and image.get("layout_patterns", 0) > 0
        }
    
    async def _generate_optimal_combinations_with_ai_search(self, semantic_mappings: List[Dict]) -> List[Dict]:
        """AI Search ë°ì´í„°ë¥¼ í™œìš©í•œ ìµœì  ì¡°í•© ìƒì„± (ë‹¤ì–‘ì„± ìµœì í™” ì¸ì‹)"""
        
        optimal_combinations = []
        used_images = set()
        
        for mapping in semantic_mappings:
            section_index = mapping["text_section_index"]
            section_title = mapping["text_title"]
            
            # âœ… ê¸°ì¡´ AI Search íŒ¨í„´ ê¸°ë°˜ ì´ë¯¸ì§€ ì„ íƒ ë¡œì§ ìœ ì§€
            best_images = []
            semantic_matches = []  # âœ… ì˜ë¯¸ì  ë§¤ì¹­ ì •ë³´ë„ ë³„ë„ ë³´ê´€
            
            for image_match in mapping["image_matches"]:
                image_index = image_match["image_index"]
                
                # âœ… ì¤‘ë³µ ë°©ì§€ (ImageDiversityManagerì™€ í˜‘ë ¥)
                if image_index not in used_images:
                    semantic_matches.append(image_match)  # ì˜ë¯¸ì  ë§¤ì¹­ ì •ë³´ ë³´ê´€
                    
                    # âœ… ê¸°ì¡´ AI Search íŒ¨í„´ ìš°ì„ ìˆœìœ„ ë¡œì§ ìœ ì§€
                    layout_rec = image_match.get("layout_recommendation", {})
                    if layout_rec.get("íŒ¨í„´_ê¸°ë°˜", False):
                        best_images.insert(0, image_match)  # ì•ì— ì¶”ê°€
                    else:
                        best_images.append(image_match)
                    
                    used_images.add(image_index)
                    
                    # âœ… ê¸°ì¡´ ì œí•œ ë¡œì§ ìœ ì§€
                    if len(best_images) >= 3:
                        break
            
            # âœ… ê¸°ì¡´ êµ¬ì¡° ìœ ì§€ + ë‹¤ì–‘ì„± ì •ë³´ ì¶”ê°€
            optimal_combinations.append({
                "section_index": section_index,
                "section_title": section_title,
                "assigned_images": best_images,  # âœ… ê¸°ì¡´ í‚¤ ìœ ì§€ (í˜¸í™˜ì„±)
                "semantic_matches": semantic_matches,  # âœ… ì¶”ê°€ ì •ë³´
                "total_similarity_score": sum(img["similarity_score"] for img in best_images),
                "semantic_score": sum(match.get("similarity_score", 0) for match in semantic_matches),
                "ai_search_enhanced": any(img.get("layout_recommendation", {}).get("íŒ¨í„´_ê¸°ë°˜", False) for img in best_images),
                "diversity_aware": True,  # âœ… ë‹¤ì–‘ì„± ì¸ì‹ í‘œì‹œ
                "optimization_notes": f"{len(best_images)}ê°œ ì´ë¯¸ì§€ í• ë‹¹ë¨ (AI Search íŒ¨í„´ + ë‹¤ì–‘ì„± ì¸ì‹)"
            })
        
        self.logger.info(f"ì˜ë¯¸ì  ë¶„ì„ ì™„ë£Œ: {len(optimal_combinations)}ê°œ ì¡°í•©, "
                        f"{len(used_images)}ê°œ ê³ ìœ  ì´ë¯¸ì§€ (AI Search íŒ¨í„´ + ë‹¤ì–‘ì„± ìµœì í™”)")
        
        return optimal_combinations
    
    # ê¸°ì¡´ í—¬í¼ ë©”ì„œë“œë“¤ ìœ ì§€
    def _get_clean_analysis_fallback(self) -> Dict:
        """ì˜¤ì—¼ë˜ì§€ ì•Šì€ ê¸°ë³¸ ë¶„ì„ ê²°ê³¼"""
        return {
            "ì£¼ìš”_ì£¼ì œ": ["ì—¬í–‰"],
            "ê°ì •ì _í†¤": "ì¤‘ì„±ì ",
            "ì‹œê°ì _í‚¤ì›Œë“œ": ["í’ê²½"],
            "ê³„ì ˆ_ì‹œê°„": "ì•Œ ìˆ˜ ì—†ìŒ",
            "ë¬¸í™”ì _ìš”ì†Œ": [],
            "ê¸€ì˜_í˜•íƒœ": "ì„œìˆ í˜•",
            "ë¬¸ì¥_ê¸¸ì´_íŠ¹ì„±": "ì¤‘ê°„"
        }
    
    def _get_clean_section_fallback(self, index: int, title: str, content: str) -> Dict:
        """ì˜¤ì—¼ë˜ì§€ ì•Šì€ ê¸°ë³¸ ì„¹ì…˜ ê²°ê³¼"""
        return {
            "section_index": index,
            "title": title,
            "content_preview": content[:200],
            "semantic_analysis": self._get_clean_analysis_fallback(),
            "confidence_score": 0.3,
            "ai_search_patterns": 0,
            "isolation_metadata": {
                "patterns_referenced": 0,
                "contamination_detected": True,
                "fallback_used": True
            }
        }
    
    def _get_clean_image_fallback(self, index: int, image_name: str, location: str, image_url: str) -> Dict:
        """ì˜¤ì—¼ë˜ì§€ ì•Šì€ ê¸°ë³¸ ì´ë¯¸ì§€ ê²°ê³¼"""
        return {
            "image_index": index,
            "image_name": image_name,
            "location": location,
            "image_url": image_url,
            "semantic_analysis": {
                "ì§€ë¦¬ì _íŠ¹ì„±": ["ë„ì‹œ"],
                "ì‹œê°ì _íŠ¹ì§•": ["ì¼ë°˜ì "],
                "ë¬¸í™”ì _ë§¥ë½": [],
                "ê°ì •ì _ì„íŒ©íŠ¸": "ì¤‘ì„±ì ",
                "ì‹œê°„ëŒ€_ê³„ì ˆ": "ì•Œ ìˆ˜ ì—†ìŒ",
                "ì í•©í•œ_ì´ë¯¸ì§€_í¬ê¸°": "ì¤‘ê°„",
                "ê¶Œì¥_ë°°ì¹˜_ìœ„ì¹˜": "ìƒë‹¨",
                "í…ìŠ¤íŠ¸ì™€ì˜_ì ì •_ê°„ê²©": "ì ë‹¹í•¨"
            },
            "confidence_score": 0.3,
            "layout_patterns": 0,
            "isolation_metadata": {
                "patterns_referenced": 0,
                "contamination_detected": True
            }
        }
    
    def _generate_clean_fallback_result(self, content: Dict, images: List[Dict]) -> Dict:
        """ì™„ì „íˆ ì •í™”ëœ í´ë°± ê²°ê³¼"""
        return {
            "text_semantics": [],
            "image_semantics": [],
            "semantic_mappings": [],
            "optimal_combinations": [],
            "analysis_metadata": {
                "total_text_sections": 0,
                "total_images": 0,
                "mapping_confidence": 0.0,
                "ai_search_enhanced": False,
                "isolation_applied": True,
                "contamination_detected": True,
                "fallback_used": True
            }
        }
    
    def _calculate_overall_confidence(self, semantic_mappings: List[Dict]) -> float:
        """ì „ì²´ ë§¤í•‘ ì‹ ë¢°ë„ ê³„ì‚°"""
        
        if not semantic_mappings:
            return 0.0
        
        total_confidence = 0.0
        total_matches = 0
        
        for mapping in semantic_mappings:
            for image_match in mapping["image_matches"]:
                total_confidence += image_match["similarity_score"]
                total_matches += 1
        
        return total_confidence / max(total_matches, 1)
