import asyncio
import os
import json
import traceback
from typing import Dict, List, Any, Optional
from utils.log.hybridlogging import get_hybrid_logger
from service.file_manager import FileManager
from utils.data.blob_storage import BlobStorageManager
from utils.log.logging_manager import LoggingManager

from agents.image_analyzer import ImageAnalyzerAgent
from agents.contents.content_creator import ContentCreatorV2Crew

from agents.Editor.unified_multimodal_agent import UnifiedMultimodalAgent
from agents.Editor.semantic_analysis_engine import SemanticAnalysisEngine
from agents.Editor.realtime_layout_generator import RealtimeLayoutGenerator
from agents.jsx.unified_jsx_generator import UnifiedJSXGenerator
from agents.jsx.template_selector import SectionStyleAnalyzer
from db.cosmos_connection import logging_container, template_container, jsx_container
from db.db_utils import save_to_cosmos, save_jsx_components
from crewai import Crew
from uuid import uuid4
from db.magazine_db_utils import MagazineDBUtils
from datetime import datetime

# Helper function to sanitize coroutine objects from data structures
def sanitize_coroutines(data: Any) -> Any:
    if isinstance(data, dict):
        return {k: sanitize_coroutines(v) for k, v in data.items()}
    elif isinstance(data, list):
        return [sanitize_coroutines(item) for item in data]
    elif asyncio.iscoroutine(data):
        # Log or identify that a coroutine was found and stringified
        # This helps in debugging which part of the async chain was not awaited
        return f"COROUTINE_OBJECT_REMOVED: {str(data)}"
    return data

class SystemCoordinator:
    """í†µí•© ì‹œìŠ¤í…œ ì¡°ìœ¨ì - ê¸°ì¡´ ì‹œìŠ¤í…œê³¼ ìƒˆë¡œìš´ ì‹œìŠ¤í…œ ì™„ì „ í†µí•©"""

    def __init__(self):
        self.logger = get_hybrid_logger(self.__class__.__name__)
        self.file_manager = FileManager(
            output_folder=os.getenv("OUTPUT_FOLDER", "./output"))
        self.blob_manager = BlobStorageManager()
        self.logging_manager = LoggingManager(self.logger)

        # ê¸°ì¡´ ì—ì´ì „íŠ¸ë“¤ (1-2ë‹¨ê³„ìš©)
        self.image_analyzer = ImageAnalyzerAgent()
        self.content_creator = ContentCreatorV2Crew()

        # ìƒˆë¡œìš´ í†µí•© ì—ì´ì „íŠ¸ë“¤ (3-4ë‹¨ê³„ìš©)
        self.layout_generator = RealtimeLayoutGenerator() # ë ˆì´ì•„ì›ƒ ì „ëµ ìƒì„±ê¸°
        self.multimodal_agent = UnifiedMultimodalAgent()
        self.semantic_engine = SemanticAnalysisEngine()
        self.template_selector = SectionStyleAnalyzer()
        self.jsx_generator = UnifiedJSXGenerator()

    async def coordinate_complete_magazine_generation(self, user_input: str = None,
                                                      image_folder: str = None,
                                                      user_id: str = "unknown_user") -> Dict:
        """ì™„ì „ í†µí•© ë§¤ê±°ì§„ ìƒì„± í”„ë¡œì„¸ìŠ¤ (ìƒˆë¡œìš´ ì•„í‚¤í…ì²˜)"""

        self.logger.info("=== ğŸ“ ì‹ ê·œ ì•„í‚¤í…ì²˜ ê¸°ë°˜ ë§¤ê±°ì§„ ìƒì„± ì‹œì‘ ===")
        magazine_id = str(uuid4())
        
        try:
            # === 1ë‹¨ê³„: ì½˜í…ì¸  ì´ˆì•ˆ ìƒì„± ===
            self.logger.info("--- ğŸš€ Phase 1: ì½˜í…ì¸  ì´ˆì•ˆ ìƒì„± ---")
            # ì´ë¯¸ì§€ ë¶„ì„ì€ ì½˜í…ì¸  ìƒì„±ê³¼ ë³‘ë ¬ ë˜ëŠ” ì§ì „ì— ìˆ˜í–‰ë  ìˆ˜ ìˆìŒ
            image_analysis_results = await self._execute_image_analysis_stage()
            
            # ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼ë¥¼ í•˜ë‚˜ì˜ ë¬¸ì„œë¡œ images ì»¨í…Œì´ë„ˆì— ì €ì¥
            if image_analysis_results:
                combined_analysis = {
                    "id": str(uuid4()),
                    "magazine_id": magazine_id,
                    "created_at": str(datetime.now()),
                    "analysis_count": len(image_analysis_results),
                    "image_analyses": image_analysis_results
                }
                await MagazineDBUtils.save_combined_image_analysis(combined_analysis)
            
            raw_content_json = await self._execute_content_generation_stage(user_input, image_analysis_results)
            raw_content = json.loads(raw_content_json)
            
            # ì´ˆê¸° ìƒíƒœ ì €ì¥ - ë§¤ê±°ì§„ ì½˜í…ì¸ ë§Œ magazine_containerì— ì €ì¥
            await MagazineDBUtils.save_magazine_content({
                "id": magazine_id,
                "user_id": user_id,
                "status": "phase1_completed",
                "raw_content": raw_content
            })
            
            self.logger.info(f"âœ… Phase 1 ì™„ë£Œ. Magazine ID: {magazine_id}")

            # === 2ë‹¨ê³„: í¸ì§‘ ë° ì˜ë¯¸/ìŠ¤íƒ€ì¼ í™•ì • ===
            self.logger.info("--- ğŸ¨ Phase 2: í¸ì§‘ ë° ì˜ë¯¸/ìŠ¤íƒ€ì¼ í™•ì • ---")
            
            # ë§¤ê±°ì§„ ì½˜í…ì¸ ë¥¼ ì„¹ì…˜ìœ¼ë¡œ íŒŒì‹±
            parsed_content = self._parse_magazine_content_to_sections(raw_content_json)
            self.logger.info(f"íŒŒì‹±ëœ ì„¹ì…˜ ìˆ˜: {len(parsed_content.get('sections', []))}")
            
            # ì˜ë¯¸ì  ë¶„ì„ ìˆ˜í–‰
            semantic_analysis = await self.semantic_engine.analyze_text_image_semantics(
                parsed_content,
                image_analysis_results
            )
            
            if not semantic_analysis:
                self.logger.warning("ì˜ë¯¸ì  ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                semantic_analysis = {
                    "text_semantics": [],
                    "semantic_mappings": [],
                    "analysis_metadata": {
                        "sections_processed": 0,
                        "images_processed": 0,
                        "success": False
                    }
                }
                
            self.logger.info(f"ì˜ë¯¸ ë¶„ì„ëœ í…ìŠ¤íŠ¸ ì„¹ì…˜: {len(semantic_analysis.get('text_semantics', []))}")
            
            # ë©€í‹°ëª¨ë‹¬ ì—ì´ì „íŠ¸ë¡œ í†µí•© ì²˜ë¦¬ (í¸ì§‘ ë‹¨ê³„)
            unified_results = await self.multimodal_agent.process_magazine_unified(
                parsed_content,
                image_analysis_results,
                [],  # í…œí”Œë¦¿ì€ ë” ì´ìƒ ì—¬ê¸°ì„œ ì „ë‹¬í•˜ì§€ ì•ŠìŒ
                user_id=user_id
            )
            
            if not unified_results:
                self.logger.warning("ë©€í‹°ëª¨ë‹¬ í†µí•© ì²˜ë¦¬ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                unified_results = {
                    "status": "error",
                    "message": "ë©€í‹°ëª¨ë‹¬ í†µí•© ì²˜ë¦¬ ì‹¤íŒ¨",
                    "user_id": user_id
                }
                
            # Phase 2 ê²°ê³¼ ì €ì¥
            final_sections = []
            for section_idx, section in enumerate(parsed_content.get('sections', [])):
                # í•´ë‹¹ ì„¹ì…˜ì— ëŒ€í•œ ì˜ë¯¸ ë¶„ì„ ë°ì´í„° ì°¾ê¸°
                section_semantics = None
                for sem in semantic_analysis.get('text_semantics', []):
                    if sem.get('section_index') == section_idx:
                        section_semantics = sem
                        break
                
                # ìµœì¢… í¸ì§‘ëœ ì½˜í…ì¸ ì™€ ë©”íƒ€ë°ì´í„°
                final_section_data = {
                    "title": section.get('title'),
                    "subtitle": section.get('subtitle', ''),
                    "final_content": section.get('content'),  # ì‹¤ì œë¡œëŠ” Editor ì—ì´ì „íŠ¸ë“¤ì´ ìˆ˜ì •í•œ ìµœì¢…ë³¸
                    "metadata": {
                        "style": section_semantics.get('style', '') if section_semantics else '',
                        "emotion": section_semantics.get('emotional_tone', '') if section_semantics else '',
                        "keywords": section_semantics.get('keywords', []) if section_semantics else [],
                        "image_count": len(section_semantics.get('related_images', [])) if section_semantics else 0
                    }
                }
                final_sections.append(final_section_data)
                
            await MagazineDBUtils.update_magazine_content(magazine_id, {
                "status": "phase2_completed",
                "final_content": final_sections,
                "semantic_analysis": semantic_analysis,
                "unified_results": unified_results
            })
            self.logger.info("âœ… Phase 2 ì™„ë£Œ.")

            # === 2.5ë‹¨ê³„: ì„¹ì…˜ë³„ ë ˆì´ì•„ì›ƒ ì „ëµ ìƒì„± ===
            self.logger.info("--- ğŸ§  Phase 2.5: ì„¹ì…˜ë³„ ë ˆì´ì•„ì›ƒ ì „ëµ ìƒì„± ---")
            layout_strategies = []
            for section_data in final_sections:
                # RealtimeLayoutGeneratorë¥¼ ì‚¬ìš©í•´ ê° ì„¹ì…˜ì˜ ì´ìƒì ì¸ ë ˆì´ì•„ì›ƒ ì „ëµì„ ìƒì„±
                strategy = await self.layout_generator.generate_layout_strategy_for_section(
                    section_data  # ì „ì²´ ì„¹ì…˜ ë°ì´í„° ì „ë‹¬
                )
                layout_strategies.append(strategy)
            
            await MagazineDBUtils.update_magazine_content(magazine_id, {
                "status": "phase2.5_completed",
                "layout_strategies": layout_strategies
            })
            self.logger.info("âœ… Phase 2.5 ì™„ë£Œ.")


            # === 3ë‹¨ê³„: ì§€ëŠ¥í˜• í…œí”Œë¦¿ ë§¤ì¹­ ===
            self.logger.info("--- ğŸ§© Phase 3: ì§€ëŠ¥í˜• í…œí”Œë¦¿ ë§¤ì¹­ ---")
            content_template_pairs = []
            
            for i, section_data in enumerate(final_sections):
                # ìƒì„±ëœ ë ˆì´ì•„ì›ƒ ì „ëµì„ template_selectorì— ì „ë‹¬í•˜ì—¬ ìµœì ì˜ í…œí”Œë¦¿ ê²€ìƒ‰
                template_code = await self.template_selector.analyze_and_select_template(
                    section_data, 
                    layout_strategies[i]
                )
                content_template_pairs.append({
                    "content": section_data,
                    "template_code": template_code,
                    "layout_strategy": layout_strategies[i]
                })
            
            await MagazineDBUtils.update_magazine_content(magazine_id, {
                "status": "phase3_completed",
                "content_template_pairs": content_template_pairs
            })
            self.logger.info("âœ… Phase 3 ì™„ë£Œ.")
            
            # === 4ë‹¨ê³„: ìµœì¢… JSX ì–´ì…ˆë¸”ë¦¬ ===
            self.logger.info("--- ğŸ› ï¸ Phase 4: ìµœì¢… JSX ì–´ì…ˆë¸”ë¦¬ ---")
            final_jsx_components = []
            
            for pair in content_template_pairs:
                # UnifiedJSXGeneratorëŠ” ì½˜í…ì¸ ì™€ í…œí”Œë¦¿ ì½”ë“œë¥¼ ë°›ì•„ ê²°í•©
                jsx_component = await self.jsx_generator.generate_jsx_from_template(
                    pair['content'], 
                    pair['template_code']
                )
                final_jsx_components.append(jsx_component)
                
            final_result = {
                "magazine_id": magazine_id,
                "magazine_title": parsed_content.get("magazine_title", "ì œëª© ì—†ìŒ"),
                "magazine_subtitle": parsed_content.get("magazine_subtitle", ""),
                "components": final_jsx_components,
                "user_id": user_id,
                "processing_summary": {
                    "total_sections": len(parsed_content.get("sections", [])),
                    "semantic_confidence": semantic_analysis.get("analysis_metadata", {}).get("success", False),
                    "multimodal_optimization": True,
                    "responsive_design": True
                }
            }
            
            await MagazineDBUtils.update_magazine_content(magazine_id, {
                "status": "completed",
                "final_result": final_result
            })
            
            # âœ… NEW: JSX ì»´í¬ë„ŒíŠ¸ ë³„ë„ ì €ì¥ (íŒŒì¼ ì‹œìŠ¤í…œ ëŒ€ì‹  Cosmos DB JSX ì»¨í…Œì´ë„ˆì— ì €ì¥)
            await self._save_results_with_file_manager({
                "magazine_id": magazine_id,
                "jsx_components": final_jsx_components,
                "template_data": {
                    "user_id": user_id,
                    "content_sections": final_sections,
                    "selected_templates": [pair.get("template_code", "") for pair in content_template_pairs]
                }
            })
            
            self.logger.info("ğŸ‰âœ… Phase 4 ì™„ë£Œ. ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì„±ê³µ!")
            
            return {"magazine_id": magazine_id, "result": final_result}
            
        except Exception as e:
            self.logger.error(f"ë§¤ê±°ì§„ ìƒì„± ì‹¤íŒ¨: {e}\n{traceback.format_exc()}")
            await MagazineDBUtils.update_magazine_content(magazine_id, {
                "status": "failed",
                "error": str(e)
            })
            return {"error": str(e), "magazine_id": magazine_id}

    async def _execute_image_analysis_stage(self) -> List[Dict]:
        """1ë‹¨ê³„: ì´ë¯¸ì§€ ë¶„ì„ ì‹¤í–‰"""
        self.logger.info("1ë‹¨ê³„: ì´ë¯¸ì§€ ë¶„ì„ ì‹œì‘")

        try:
            images = self.blob_manager.get_images()
            self.logger.info(f"ì´ë¯¸ì§€ {len(images)}ê°œ ë°œê²¬")

            if not images:
                self.logger.warning("ë¶„ì„í•  ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return []

            crew = Crew(agents=[self.image_analyzer.create_agent()], verbose=False)
            
            # ì´ë¯¸ì§€ ë¶„ì„ ì‹¤í–‰
            if hasattr(self.image_analyzer, 'analyze_images_batch_async'):
                results = await self.image_analyzer.analyze_images_batch_async(images, max_concurrent=5)
            else:
                loop = asyncio.get_event_loop()
                results = await loop.run_in_executor(None, self.image_analyzer.analyze_images_batch, images)

            return results

        except Exception as e:
            self.logger.error(f"ì´ë¯¸ì§€ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return []

    async def _execute_content_generation_stage(self, user_input: str, image_analysis_results: List[Dict]) -> str:
        """2ë‹¨ê³„: ì½˜í…ì¸  ìƒì„± ì‹¤í–‰"""
        self.logger.info("2ë‹¨ê³„: ì½˜í…ì¸  ìƒì„± ì‹œì‘")

        try:
            text_blobs = self.blob_manager.get_texts()
            texts = [self.blob_manager.read_text_file(text_blob) for text_blob in text_blobs]

            if not texts:
                self.logger.warning("ì²˜ë¦¬í•  í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return self._create_default_content()

            # ì½˜í…ì¸  ìƒì„± ì‹¤í–‰
            if hasattr(self.content_creator, 'execute_content_creation') and asyncio.iscoroutinefunction(self.content_creator.execute_content_creation):
                magazine_content = await self.content_creator.execute_content_creation(texts, image_analysis_results)
            else:
                magazine_content = await asyncio.get_event_loop().run_in_executor(
                    None, self.content_creator.execute_content_creation_sync, texts, image_analysis_results
                )

            if not magazine_content:
                self.logger.warning("ì½˜í…ì¸  ìƒì„± ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return self._create_default_content()

            # ê²°ê³¼ ì •ê·œí™”: DB ì €ì¥ ë¡œì§ì„ ì œê±°í•˜ê³ , ë°˜í™˜ê°’ì„ JSON ë¬¸ìì—´ë¡œ ì¼ê´€ì„± ìˆê²Œ ë§Œë“­ë‹ˆë‹¤.
            if isinstance(magazine_content, dict):
                try:
                    magazine_content = json.dumps(magazine_content, ensure_ascii=False)
                except (TypeError, ValueError) as e:
                    self.logger.error(f"ì½˜í…ì¸  ì§ë ¬í™” ì‹¤íŒ¨: {e}")
                    return self._create_default_content()
            
            # ìƒì„±ëœ ì½˜í…ì¸ ê°€ ë¬¸ìì—´ì´ ì•„ë‹Œ ê²½ìš° ë¬¸ìì—´ë¡œ ë³€í™˜
            if not isinstance(magazine_content, str):
                magazine_content = str(magazine_content)

            # ìµœì¢… ë°˜í™˜ ì „ì— ìœ íš¨í•œ JSONì¸ì§€ í™•ì¸
            try:
                # ì—¬ê¸°ì„œëŠ” ë¡œë“œë§Œ í•´ë³´ê³ , ì‹¤ì œ ê°ì²´ëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
                # ìƒìœ„ ë©”ì†Œë“œì—ì„œ ë‹¤ì‹œ íŒŒì‹±í•´ì„œ ì‚¬ìš©í•©ë‹ˆë‹¤.
                json.loads(magazine_content)
            except json.JSONDecodeError:
                self.logger.warning(f"ìƒì„±ëœ ì½˜í…ì¸ ê°€ ìœ íš¨í•œ JSONì´ ì•„ë‹™ë‹ˆë‹¤. ê¸°ë³¸ ì½˜í…ì¸ ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. Content: {magazine_content[:200]}...")
                return self._create_default_content()


            self.logger.info(f"2ë‹¨ê³„: ì½˜í…ì¸  ìƒì„± ì™„ë£Œ - {len(magazine_content)}ì")
            return magazine_content

        except Exception as e:
            self.logger.error(f"ì½˜í…ì¸  ìƒì„± ì‹¤íŒ¨: {e}\\n{traceback.format_exc()}")
            return self._create_default_content()

    def _create_default_content(self) -> str:
        """ê¸°ë³¸ ë§¤ê±°ì§„ ì½˜í…ì¸  ìƒì„±"""
        default_content = {
            "mag_id": "default_magazine",
            "magazine_title": "ë² ë‹ˆìŠ¤ ì—¬í–‰ ì´ì•¼ê¸°",
            "magazine_subtitle": "ì•„ë¦„ë‹¤ìš´ ìˆ˜ìƒ ë„ì‹œì—ì„œì˜ íŠ¹ë³„í•œ ìˆœê°„ë“¤",
            "sections": [
                {
                    "title": "ë² ë‹ˆìŠ¤ì˜ ê²¨ìš¸",
                    "subtitle": "ì•ˆê°œ ì† ì‹ ë¹„ë¡œìš´ ë„ì‹œ",
                    "content": "ê²¨ìš¸ì˜ ë² ë‹ˆìŠ¤ëŠ” ë˜ ë‹¤ë¥¸ ë§¤ë ¥ì„ ì„ ì‚¬í•©ë‹ˆë‹¤. ì•ˆê°œì— ìŒ“ì¸ ìš´í•˜ì™€ ê³ ë”• ê±´ì¶•ë¬¼ë“¤ì€ ë§ˆì¹˜ ë™í™” ì† í•œ ì¥ë©´ ê°™ìŠµë‹ˆë‹¤."
                },
                {
                    "title": "ì¹´ë‹ˆë°œì˜ ì—´ê¸°",
                    "subtitle": "í™”ë ¤í•œ ê°€ë©´ê³¼ ì¶•ì œ",
                    "content": "ì„¸ê³„ì ìœ¼ë¡œ ìœ ëª…í•œ ë² ë‹ˆìŠ¤ ì¹´ë‹ˆë°œì€ ë„ì‹œ ì „ì²´ë¥¼ ì¶•ì œì˜ ì¥ìœ¼ë¡œ ë§Œë“­ë‹ˆë‹¤. ì „í†µ ì˜ìƒê³¼ ì•„ë¦„ë‹¤ìš´ ê°€ë©´ì€ ì‹œê°„ ì—¬í–‰ì„ í•˜ëŠ” ë“¯í•œ ëŠë‚Œì„ ì¤ë‹ˆë‹¤."
                }
            ]
        }
        return json.dumps(default_content, ensure_ascii=False)

    def _parse_magazine_content_to_sections(self, magazine_content: str) -> Dict:
        """ë§¤ê±°ì§„ ì½˜í…ì¸ ë¥¼ ì„¹ì…˜ìœ¼ë¡œ íŒŒì‹±"""
        self.logger.info("ë§¤ê±°ì§„ ì½˜í…ì¸  ì„¹ì…˜ íŒŒì‹± ì‹œì‘")

        try:
            # JSON ë¬¸ìì—´ì¸ ê²½ìš°
            content_dict = json.loads(magazine_content)
            
            # ì´ë¯¸ ì„¹ì…˜ êµ¬ì¡°ê°€ ìˆëŠ”ì§€ í™•ì¸
            if "sections" in content_dict:
                self.logger.info(f"ê¸°ì¡´ ì„¹ì…˜ êµ¬ì¡° ë°œê²¬: {len(content_dict['sections'])}ê°œ ì„¹ì…˜")
                
                # í•˜ìœ„ ì„¹ì…˜ì´ ìˆëŠ” ê²½ìš° ì²˜ë¦¬
                has_sub_sections = False
                section_count = len(content_dict['sections'])
                total_section_count = section_count
                
                for section in content_dict['sections']:
                    if 'sub_sections' in section:
                        has_sub_sections = True
                        total_section_count += len(section['sub_sections'])
                
                if has_sub_sections:
                    self.logger.info(f"í•˜ìœ„ ì„¹ì…˜ í¬í•¨ ì´ {total_section_count}ê°œ ì„¹ì…˜ ë°œê²¬")
                    
                    # í•˜ìœ„ ì„¹ì…˜ì„ ë³„ë„ì˜ ì„¹ì…˜ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì¶”ê°€ (ë©€í‹°ëª¨ë‹¬ ì—ì´ì „íŠ¸ í˜¸í™˜ì„±)
                    flattened_sections = []
                    
                    for section in content_dict['sections']:
                        if 'sub_sections' in section:
                            # ë¶€ëª¨ ì„¹ì…˜ ì •ë³´ ì¶”ê°€ (ë³¸ë¬¸ ì—†ì´ ì œëª©ë§Œ)
                            parent_section = {
                                "title": section.get('title', ''),
                                "subtitle": section.get('subtitle', ''),
                                "content": f"ì´ ì„¹ì…˜ì€ {len(section['sub_sections'])}ê°œì˜ í•˜ìœ„ ì„¹ì…˜ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤.",
                                "is_parent": True,
                                "parent_id": section.get('section_id', '')
                            }
                            flattened_sections.append(parent_section)
                            
                            # í•˜ìœ„ ì„¹ì…˜ ì¶”ê°€
                            for sub_section in section['sub_sections']:
                                flattened_sections.append({
                                    "title": sub_section.get('title', ''),
                                    "subtitle": sub_section.get('subtitle', ''),
                                    "content": sub_section.get('body', ''),
                                    "is_sub_section": True,
                                    "parent_id": section.get('section_id', ''),
                                    "sub_section_id": sub_section.get('sub_section_id', '')
                                })
                        else:
                            # ì¼ë°˜ ì„¹ì…˜ ì¶”ê°€
                            flattened_sections.append({
                                "title": section.get('title', ''),
                                "subtitle": section.get('subtitle', ''),
                                "content": section.get('body', '')
                            })
                    
                    return {
                        "magazine_title": content_dict.get("magazine_title", "ì—¬í–‰ ë§¤ê±°ì§„"),
                        "magazine_subtitle": content_dict.get("magazine_subtitle", "íŠ¹ë³„í•œ ìˆœê°„ë“¤"),
                        "sections": flattened_sections,
                        "has_dynamic_sections": True,
                        "original_section_count": section_count,
                        "total_section_count": total_section_count
                    }
                
                # ê¸°ì¡´ ì„¹ì…˜ êµ¬ì¡° ë³€í™˜
                sections = []
                for section in content_dict['sections']:
                    sections.append({
                        "title": section.get('title', ''),
                        "subtitle": section.get('subtitle', ''),
                        "content": section.get('body', '')
                    })
                
                return {
                    "magazine_title": content_dict.get("magazine_title", "ì—¬í–‰ ë§¤ê±°ì§„"),
                    "magazine_subtitle": content_dict.get("magazine_subtitle", "íŠ¹ë³„í•œ ìˆœê°„ë“¤"),
                    "sections": sections
                }
            
            # ì„¹ì…˜ êµ¬ì¡°ê°€ ì—†ëŠ” ê²½ìš°
            self.logger.info("ì„¹ì…˜ êµ¬ì¡° ì—†ìŒ, ì½˜í…ì¸  ë¶„ì„ ì‹œì‘")
            
            # ì½˜í…ì¸  í˜•ì‹ì— ë”°ë¼ ë¶„í•  ë°©ì‹ ê²°ì •
            if isinstance(content_dict, dict) and "content" in content_dict:
                content = content_dict["content"]
                if isinstance(content, str):
                    # í—¤ë”ë¡œ ë¶„í•  ì‹œë„
                    sections = self._split_by_headers(content)
                    if len(sections["sections"]) > 1:
                        return sections
                    
                    # í—¤ë”ê°€ ì—†ìœ¼ë©´ ê¸¸ì´ë¡œ ë¶„í• 
                    return self._split_by_length(content)
                else:
                    self.logger.warning("ì½˜í…ì¸ ê°€ ë¬¸ìì—´ì´ ì•„ë‹˜")
                    return {"sections": [{"title": "ì—¬í–‰ ì´ì•¼ê¸°", "content": str(content)}]}
            else:
                # ì§ì ‘ ì½˜í…ì¸ ë¡œ ì‚¬ìš©
                return {"sections": [{"title": "ì—¬í–‰ ì´ì•¼ê¸°", "content": json.dumps(content_dict, ensure_ascii=False)}]}
                
        except json.JSONDecodeError:
            # ì¼ë°˜ í…ìŠ¤íŠ¸ì¸ ê²½ìš°
            self.logger.info("JSONì´ ì•„ë‹Œ ì¼ë°˜ í…ìŠ¤íŠ¸ë¡œ ì²˜ë¦¬")
            
            # í—¤ë”ë¡œ ë¶„í•  ì‹œë„
            sections = self._split_by_headers(magazine_content)
            if len(sections["sections"]) > 1:
                return sections
            
            # í—¤ë”ê°€ ì—†ìœ¼ë©´ ê¸¸ì´ë¡œ ë¶„í• 
            return self._split_by_length(magazine_content)
        except Exception as e:
            self.logger.error(f"ë§¤ê±°ì§„ ì½˜í…ì¸  íŒŒì‹± ì‹¤íŒ¨: {e}")
            return {"sections": [{"title": "ì—¬í–‰ ì´ì•¼ê¸°", "content": str(magazine_content)[:1000]}]}

    def _split_by_headers(self, content: str) -> Dict:
        """í—¤ë” ê¸°ë°˜ ì„¹ì…˜ ë¶„í•  (ê°œì„ ëœ ë²„ì „)"""
        sections = []
        lines = content.split('\n')
        current_section = {"title": "", "content": ""}

        for line in lines:
            line = line.strip()

            # êµ¬ì¡°ì  ë§ˆì»¤ ì œê±°
            if "magazine layout design structure" in line.lower():
                continue

            if line.startswith("===") and line.endswith("==="):
                # ì´ì „ ì„¹ì…˜ ì €ì¥
                if current_section["content"]:
                    # ë‚´ìš© ê¸¸ì´ ì œí•œ
                    if len(current_section["content"]) > 500:
                        current_section["content"] = current_section["content"][:497] + "..."
                    sections.append(current_section)

                # ìƒˆ ì„¹ì…˜ ì‹œì‘
                title = line.replace("===", "").strip()
                current_section = {"title": title, "content": ""}
            else:
                if line:
                    current_section["content"] += line + " "

        # ë§ˆì§€ë§‰ ì„¹ì…˜ ì €ì¥
        if current_section["content"]:
            if len(current_section["content"]) > 500:
                current_section["content"] = current_section["content"][:497] + "..."
            sections.append(current_section)

        self.logger.info(f"í—¤ë” ê¸°ë°˜ íŒŒì‹±: {len(sections)}ê°œ ì„¹ì…˜")
        return {
            "title": "ì—¬í–‰ ë§¤ê±°ì§„",
            "subtitle": "",
            "sections": sections
        }

    def _split_by_length(self, content: str, max_length: int = 1000) -> List[Dict]:
        """ê¸¸ì´ ê¸°ë°˜ ì„¹ì…˜ ë¶„í• """

        sections = []
        paragraphs = [p.strip() for p in content.split('\n\n') if p.strip()]

        current_section = ""
        section_count = 1

        for paragraph in paragraphs:
            if len(current_section + paragraph) > max_length and current_section:
                # í˜„ì¬ ì„¹ì…˜ ì €ì¥
                sections.append({
                    "title": f"ì—¬í–‰ ì´ì•¼ê¸° {section_count}",
                    "content": current_section.strip()
                })
                current_section = paragraph
                section_count += 1
            else:
                current_section += "\n\n" + paragraph if current_section else paragraph

        # ë§ˆì§€ë§‰ ì„¹ì…˜ ì €ì¥
        if current_section:
            sections.append({
                "title": f"ì—¬í–‰ ì´ì•¼ê¸° {section_count}",
                "content": current_section.strip()
            })

        return sections

    async def _integrate_processing_results(self, semantic_analysis: Dict,
                                            layout_results: Dict,
                                            unified_results: Dict) -> Dict:
        """ì²˜ë¦¬ ê²°ê³¼ë“¤ í†µí•©"""

        integrated_data = {
            "selected_templates": unified_results.get("selected_templates", []),
            "content_sections": unified_results.get("content_sections", []),
            "semantic_analysis": semantic_analysis,
            "optimized_layouts": layout_results.get("optimized_layouts", []),
            "user_id": unified_results.get("user_id", "unknown_user"),
            "integration_metadata": {
                "multimodal_processing": True,
                "semantic_optimization": True,
                "layout_optimization": True,
                "processing_timestamp": asyncio.get_event_loop().time(),
                "total_sections": len(unified_results.get("content_sections", [])),
                "semantic_confidence": semantic_analysis.get("analysis_metadata", {}).get("mapping_confidence", 0.0),
                "ai_search_enhanced": semantic_analysis.get("analysis_metadata", {}).get("ai_search_enhanced", False)
            }
        }

        return integrated_data

    async def _package_final_results(self, integrated_data: Dict,
                                     jsx_results: Dict,
                                     input_data: Dict) -> Dict:
        """ìµœì¢… ê²°ê³¼ íŒ¨í‚¤ì§•"""

        final_result = {
            "template_data": integrated_data,
            "jsx_components": jsx_results.get("jsx_components", []),
            "processing_summary": {
                "total_sections": len(integrated_data.get("content_sections", [])),
                "total_jsx_components": len(jsx_results.get("jsx_components", []) if isinstance(jsx_results, dict) else 0),
                "semantic_confidence": integrated_data.get("integration_metadata", {}).get("semantic_confidence", 0.0),
                "multimodal_optimization": True,
                "responsive_design": True,
                "style_optimization": True
            },
            "execution_logs": {
                "image_analysis_completed": True,
                "content_creation_completed": True,
                "semantic_analysis_completed": True,
                "layout_generation_completed": True,
                "multimodal_processing_completed": True,
                "jsx_generation_completed": True,
                "integration_completed": True
            },
            "source_data": {
                "magazine_content_sections": len(input_data.get("magazine_content", {}).get("sections", [])),
                "image_analysis_count": len(input_data.get("image_analysis", [])),
                "templates_used": len(integrated_data.get("selected_templates", []))
            }
        }

        return final_result

    async def _save_results_with_file_manager(self, final_result: Dict) -> None:
        """ê²°ê³¼ ì €ì¥ (ì™„ì „íˆ ê°œì„ ëœ File Manager í™œìš©)"""

        try:
            # 1. ê¸°ë³¸ JSON ì €ì¥ (SystemCoordinator ì—­í• )
            outputs_data = {
                "processing_summary": final_result.get("processing_summary", {}),
                "execution_logs": final_result.get("execution_logs", {}),
                "timestamp": asyncio.get_event_loop().time()
            }

            if "source_data" in final_result:
                outputs_data["source_data"] = final_result["source_data"]
            else:
                outputs_data["source_data"] = {
                    "magazine_content_sections": 0,
                    "image_analysis_count": 0,
                    "templates_used": 0
                }

            # session_id íŒŒí‹°ì…˜ í‚¤
            if 'session_id' not in outputs_data:
                outputs_data['session_id'] = final_result.get(
                    'session_id', 'unknown_session')

            # Cosmos DBì— ì €ì¥ (íŒŒí‹°ì…˜ í‚¤: session_id)
            save_to_cosmos(logging_container, outputs_data,
                           partition_key_field='session_id')
            self.logger.info("âœ… outputs ë°ì´í„° Cosmos DB ì €ì¥ ì™„ë£Œ")

            # âœ… 2. template_data Cosmos DB ì €ì¥
            template_data = final_result.get("template_data", {})
            if template_data and template_data.get("content_sections"):
                # Cosmos DBì— ì €ì¥ (íŒŒí‹°ì…˜ í‚¤: user_id)
                save_to_cosmos(template_container, template_data,
                             partition_key_field='user_id')
                self.logger.info(
                    f"âœ… template_data Cosmos DB ì €ì¥ ì™„ë£Œ: {len(template_data.get('content_sections', []))}ê°œ ì„¹ì…˜")

            # 3. JSX ì»´í¬ë„ŒíŠ¸ Cosmos DB ì €ì¥ 
            jsx_components = final_result.get("jsx_components", [])
            if jsx_components:
                # JSX ì»´í¬ë„ŒíŠ¸ ë°ì´í„° êµ¬ì¡°í™”
                jsx_data = {
                    "id": str(uuid4()),
                    "user_id": template_data.get("user_id", "unknown_user"),
                    "total_components": len(jsx_components),
                    "components": jsx_components,
                    "creation_timestamp": asyncio.get_event_loop().time()
                }
                
                # Template ì»¨í…Œì´ë„ˆì— ë©”íƒ€ë°ì´í„° ì €ì¥
                save_to_cosmos(template_container, jsx_data, partition_key_field='user_id')
                self.logger.info(f"âœ… JSX ì»´í¬ë„ŒíŠ¸ ë©”íƒ€ë°ì´í„°ë¥¼ Template ì»¨í…Œì´ë„ˆì— ì €ì¥ ì™„ë£Œ")
                
                # âœ… NEW: JSX ì»´í¬ë„ŒíŠ¸ë¥¼ ì „ìš© ì»¨í…Œì´ë„ˆì— ê°œë³„ì ìœ¼ë¡œ ì €ì¥
                magazine_id = final_result.get("magazine_id", str(uuid4()))
                saved_ids = save_jsx_components(
                    jsx_container, 
                    magazine_id, 
                    jsx_components, 
                    order_matters=True
                )
                self.logger.info(f"âœ… JSX ì»´í¬ë„ŒíŠ¸ {len(saved_ids)}ê°œë¥¼ JSX ì „ìš© ì»¨í…Œì´ë„ˆì— ì €ì¥ ì™„ë£Œ")

        except Exception as e:
            self.logger.error(f"ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}")
            raise
