import asyncio
import os
import json
from typing import Dict, List
from utils.hybridlogging import get_hybrid_logger
from utils.file_manager import FileManager
from utils.blob_storage import BlobStorageManager
from utils.logging_manager import LoggingManager

# ê¸°ì¡´ ì—ì´ì „íŠ¸ë“¤ (í˜¸í™˜ì„± ìœ ì§€)
from agents.image_analyzer import ImageAnalyzerAgent
from agents.contents.content_creator import ContentCreatorV2Crew

# ìƒˆë¡œìš´ í†µí•© ì—ì´ì „íŠ¸ë“¤
from agents.Editor.unified_multimodal_agent import UnifiedMultimodalAgent
from agents.Editor.semantic_analysis_engine import SemanticAnalysisEngine
from agents.Editor.realtime_layout_generator import RealtimeLayoutGenerator
from agents.jsx.unified_jsx_generator import UnifiedJSXGenerator
from utils.template_scanner import TemplateScanner

from crewai import Crew

class SystemCoordinator:
    """í†µí•© ì‹œìŠ¤í…œ ì¡°ìœ¨ì - ê¸°ì¡´ ì‹œìŠ¤í…œê³¼ ìƒˆë¡œìš´ ì‹œìŠ¤í…œ ì™„ì „ í†µí•©"""
    
    def __init__(self):
        self.logger = get_hybrid_logger(self.__class__.__name__)
        self.file_manager = FileManager(output_folder=os.getenv("OUTPUT_FOLDER", "./output"))
        self.blob_manager = BlobStorageManager()
        self.logging_manager = LoggingManager()
        
        # ê¸°ì¡´ ì—ì´ì „íŠ¸ë“¤ (1-2ë‹¨ê³„ìš©)
        self.image_analyzer = ImageAnalyzerAgent()
        self.content_creator = ContentCreatorV2Crew()
        
        # ìƒˆë¡œìš´ í†µí•© ì—ì´ì „íŠ¸ë“¤ (3ë‹¨ê³„ìš©)
        self.multimodal_agent = UnifiedMultimodalAgent()
        self.semantic_engine = SemanticAnalysisEngine()
        self.layout_generator = RealtimeLayoutGenerator()
        self.jsx_generator = UnifiedJSXGenerator()
        self.template_scanner = TemplateScanner()

    async def coordinate_complete_magazine_generation(self, user_input: str = None, 
                                                    image_folder: str = None, 
                                                    available_templates: List[str] = None) -> Dict:
        """ì™„ì „ í†µí•© ë§¤ê±°ì§„ ìƒì„± í”„ë¡œì„¸ìŠ¤"""
        
        self.logger.info("=== ì™„ì „ í†µí•© ë§¤ê±°ì§„ ìƒì„± í”„ë¡œì„¸ìŠ¤ ì‹œì‘ ===")
        
        try:
            # í…œí”Œë¦¿ì´ ì œê³µë˜ì§€ ì•Šì€ ê²½ìš° ë™ì  ìŠ¤ìº”
            if not available_templates:
                self.logger.info("í…œí”Œë¦¿ ëª©ë¡ì´ ì œê³µë˜ì§€ ì•ŠìŒ. ë™ì  ìŠ¤ìº” ì‹¤í–‰")
                available_templates = await self.template_scanner.scan_jsx_templates()
            
            # í…œí”Œë¦¿ ë©”íƒ€ë°ì´í„° ë¡œê¹…
            template_metadata = await self.template_scanner.get_template_metadata()
            self.logger.info(f"í…œí”Œë¦¿ ë©”íƒ€ë°ì´í„°: {template_metadata}")
            
            # âœ… ì‹¤ì œ ì²˜ë¦¬ ë‹¨ê³„ë“¤ ì‹¤í–‰
            # 1ë‹¨ê³„: ì´ë¯¸ì§€ ë¶„ì„
            image_results = await self._execute_image_analysis_stage()
            
            # 2ë‹¨ê³„: ì½˜í…ì¸  ìƒì„±
            magazine_content = await self._execute_content_creation_stage(image_results)
            
            # 3ë‹¨ê³„: ë©€í‹°ëª¨ë‹¬ ì²˜ë¦¬
            final_result = await self._execute_multimodal_processing_stage(
                magazine_content, image_results, available_templates
            )
            
            self.logger.info("=== ì™„ì „ í†µí•© ë§¤ê±°ì§„ ìƒì„± í”„ë¡œì„¸ìŠ¤ ì™„ë£Œ ===")
            return final_result
            
        except Exception as e:
            self.logger.error(f"ì™„ì „ í†µí•© ë§¤ê±°ì§„ ìƒì„± ì‹¤íŒ¨: {e}")


    async def _execute_image_analysis_stage(self) -> List[Dict]:
        """1ë‹¨ê³„: ì´ë¯¸ì§€ ë¶„ì„ ì‹¤í–‰ (ê¸°ì¡´ ì‹œìŠ¤í…œ í™œìš©)"""
        self.logger.info("1ë‹¨ê³„: ì´ë¯¸ì§€ ë¶„ì„ ì‹œì‘")
        
        images = self.blob_manager.get_images()
        self.logger.info(f"ì´ë¯¸ì§€ {len(images)}ê°œ ë°œê²¬")
        
        crew = Crew(agents=[self.image_analyzer.create_agent()], verbose=False)
        try:
            if hasattr(self.image_analyzer, 'analyze_images_batch_async'):
                results = await self.image_analyzer.analyze_images_batch_async(images, max_concurrent=5)
            else:
                loop = asyncio.get_event_loop()
                results = await loop.run_in_executor(None, self.image_analyzer.analyze_images, images, crew)
            
            # âœ… ê²°ê³¼ ì €ì¥ (ê¸°ì¡´ file_manager í™œìš©)
            analysis_path = os.path.join(self.file_manager.output_folder, "image_analysis_results.json")
            self.file_manager.save_json(results, analysis_path)
            
            # âœ… ìƒˆë¡œìš´ ë¡œê¹… ë°©ì‹ ì ìš©
            await self.logging_manager.log_image_analysis_completion(len(images), len(results))
            
            self.logger.info(f"1ë‹¨ê³„: ì´ë¯¸ì§€ ë¶„ì„ ì™„ë£Œ - {len(results)}ê°œ ê²°ê³¼")
            return results
            
        except Exception as e:
            self.logger.error(f"ì´ë¯¸ì§€ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return []

    async def _execute_content_creation_stage(self, image_results: List[Dict]) -> str:
        """2ë‹¨ê³„: ì½˜í…ì¸  ìƒì„± ì‹¤í–‰ (ê¸°ì¡´ ì‹œìŠ¤í…œ í™œìš©)"""
        self.logger.info("2ë‹¨ê³„: ì½˜í…ì¸  ìƒì„± ì‹œì‘")
        
        text_blobs = self.blob_manager.get_texts()
        texts = [self.blob_manager.read_text_file(text_blob) for text_blob in text_blobs]
        
        try:
            if hasattr(self.content_creator, 'execute_content_creation') and asyncio.iscoroutinefunction(self.content_creator.execute_content_creation):
                magazine_content = await self.content_creator.execute_content_creation(texts, image_results)
            else:
                magazine_content = await asyncio.get_event_loop().run_in_executor(
                    None, self.content_creator.execute_content_creation_sync, texts, image_results
                )
            
            # âœ… ê²°ê³¼ ì €ì¥ (ê¸°ì¡´ file_manager í™œìš©)
            content_path = os.path.join(self.file_manager.output_folder, "magazine_content.json")
            self.file_manager.save_magazine_content_json(magazine_content, content_path)
            
            # âœ… ìƒˆë¡œìš´ ë¡œê¹… ë°©ì‹ ì ìš©
            await self.logging_manager.log_content_creation_completion(len(texts), len(image_results), len(magazine_content))
            
            self.logger.info(f"2ë‹¨ê³„: ì½˜í…ì¸  ìƒì„± ì™„ë£Œ - {len(magazine_content)}ì")
            return magazine_content
            
        except Exception as e:
            self.logger.error(f"ì½˜í…ì¸  ìƒì„± ì‹¤íŒ¨: {e}")
            return "ê¸°ë³¸ ì—¬í–‰ ë§¤ê±°ì§„ ì½˜í…ì¸ "

    async def _execute_multimodal_processing_stage(self, magazine_content: str,
                                                image_results: List[Dict],
                                                available_templates: List[str]) -> Dict:
        """3ë‹¨ê³„: í†µí•© ë©€í‹°ëª¨ë‹¬ ì²˜ë¦¬ ì‹¤í–‰ (ì´ë¯¸ì§€ ë‹¤ì–‘ì„± ìµœì í™” í¬í•¨)"""
        self.logger.info("3ë‹¨ê³„: í†µí•© ë©€í‹°ëª¨ë‹¬ ì²˜ë¦¬ ì‹œì‘")
        
        try:
            parsed_content = self._parse_magazine_content_to_sections(magazine_content)
            self.logger.info(f"íŒŒì‹±ëœ ì„¹ì…˜ ìˆ˜: {len(parsed_content.get('sections', []))}")
            
            input_data = {
                "magazine_content": parsed_content,
                "image_analysis": image_results
            }
            
            # âœ… ì´ë¯¸ì§€ ë‹¤ì–‘ì„± ìµœì í™” ë¡œê¹…
            self.logger.info(f"ì´ë¯¸ì§€ ë‹¤ì–‘ì„± ìµœì í™” ëŒ€ìƒ: {len(image_results)}ê°œ ì´ë¯¸ì§€")
            
            # ì˜ë¯¸ì  ë¶„ì„ ìˆ˜í–‰
            semantic_analysis = await self.semantic_engine.analyze_text_image_semantics(
                input_data["magazine_content"],
                input_data["image_analysis"]
            )
            
            # âœ… ì˜ë¯¸ì  ë¶„ì„ ë¡œê¹…
            await self.logging_manager.log_semantic_analysis_completion(semantic_analysis)
            
            self.logger.info(f"ì˜ë¯¸ ë¶„ì„ëœ í…ìŠ¤íŠ¸ ì„¹ì…˜: {len(semantic_analysis.get('text_semantics', []))}")
            
            # ì‹¤ì‹œê°„ ë ˆì´ì•„ì›ƒ ìƒì„±
            layout_results = await self.layout_generator.generate_optimized_layouts(
                semantic_analysis,
                available_templates
            )
            
            # âœ… ë ˆì´ì•„ì›ƒ ìƒì„± ë¡œê¹…
            await self.logging_manager.log_layout_generation_completion(layout_results)
            
            # âœ… ë©€í‹°ëª¨ë‹¬ ì—ì´ì „íŠ¸ë¡œ í†µí•© ì²˜ë¦¬ (ì´ë¯¸ì§€ ë‹¤ì–‘ì„± ìµœì í™” í¬í•¨)
            unified_results = await self.multimodal_agent.process_magazine_unified(
                input_data["magazine_content"],
                input_data["image_analysis"],
                available_templates
            )
            
            # âœ… ë©€í‹°ëª¨ë‹¬ ì²˜ë¦¬ ë¡œê¹…
            await self.logging_manager.log_multimodal_processing_completion(unified_results)
            
            # âœ… ë‹¤ì–‘ì„± ìµœì í™” ê²°ê³¼ ë¡œê¹…
            if unified_results.get("diversity_optimization_applied"):
                optimization_stats = unified_results.get("optimization_stats", {})
                total_used = unified_results.get("total_images_used", 0)
                utilization_rate = total_used / len(image_results) if image_results else 0
                
                await self.logging_manager.log_diversity_optimization_completion({
                    "utilization_rate": utilization_rate,
                    "total_images_processed": len(image_results),
                    "total_images_used": total_used,
                    "optimization_stats": optimization_stats
                })
                
                self.logger.info(f"âœ… ì´ë¯¸ì§€ ë‹¤ì–‘ì„± ìµœì í™” ì ìš© - í™œìš©ë¥ : {utilization_rate:.2%}, "
                            f"CLIP ì‚¬ìš©: {optimization_stats.get('clip_available', False)}")
            
            # ê²°ê³¼ í†µí•©
            integrated_data = await self._integrate_processing_results(
                semantic_analysis, layout_results, unified_results
            )
            
            self.logger.info(f"í†µí•©ëœ ì½˜í…ì¸  ì„¹ì…˜: {len(integrated_data.get('content_sections', []))}")
            
            # JSX ì»´í¬ë„ŒíŠ¸ ìƒì„±
            jsx_results = await self.jsx_generator.generate_jsx_with_multimodal_context(
                integrated_data
            )
            
            # âœ… JSX ìƒì„± ë¡œê¹…
            await self.logging_manager.log_jsx_generation_completion(
                len(jsx_results.get('jsx_components', [])), jsx_results
            )
            
            self.logger.info(f"ìƒì„±ëœ JSX ì»´í¬ë„ŒíŠ¸: {len(jsx_results.get('jsx_components', []))}")
            
            # ìµœì¢… ê²°ê³¼ íŒ¨í‚¤ì§•
            final_result = await self._package_final_results(
                integrated_data, jsx_results, input_data
            )
            
            # âœ… ë‹¤ì–‘ì„± ìµœì í™” ë©”íƒ€ë°ì´í„° ì¶”ê°€
            final_result["diversity_optimization"] = {
                "applied": unified_results.get("diversity_optimization_applied", False),
                "total_images_processed": len(image_results),
                "total_images_used": unified_results.get("total_images_used", 0),
                "optimization_stats": unified_results.get("optimization_stats", {})
            }
            
            # ê²°ê³¼ ì €ì¥
            await self._save_results_with_file_manager(final_result)
            
            self.logger.info("3ë‹¨ê³„: í†µí•© ë©€í‹°ëª¨ë‹¬ ì²˜ë¦¬ ì™„ë£Œ (ì´ë¯¸ì§€ ë‹¤ì–‘ì„± ìµœì í™” í¬í•¨)")
            return final_result
            
        except Exception as e:
            self.logger.error(f"ë©€í‹°ëª¨ë‹¬ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")


    def _parse_magazine_content_to_sections(self, magazine_content: str) -> Dict:
        """magazine_contentë¥¼ ì—¬ëŸ¬ ì„¹ì…˜ìœ¼ë¡œ íŒŒì‹±"""
        
        try:
            # 1. JSON í˜•íƒœì¸ì§€ í™•ì¸
            if isinstance(magazine_content, str):
                try:
                    parsed_json = json.loads(magazine_content)
                    if isinstance(parsed_json, dict) and "sections" in parsed_json:
                        # ì´ë¯¸ ì„¹ì…˜ êµ¬ì¡°ê°€ ìˆëŠ” ê²½ìš°
                        self.logger.info(f"ê¸°ì¡´ ì„¹ì…˜ êµ¬ì¡° ë°œê²¬: {len(parsed_json['sections'])}ê°œ")
                        return parsed_json
                except json.JSONDecodeError:
                    pass
            
            # 2. ë¬¸ìì—´ì¸ ê²½ìš° ì„¹ì…˜ìœ¼ë¡œ ë¶„í• 
            sections = self._split_content_into_sections(magazine_content)
            
            return {
                "magazine_title": "AI ìƒì„± ì—¬í–‰ ë§¤ê±°ì§„",
                "content_type": "multimodal_magazine",
                "sections": sections
            }
            
        except Exception as e:
            self.logger.error(f"magazine_content íŒŒì‹± ì‹¤íŒ¨: {e}")
            # í´ë°±: ë‹¨ì¼ ì„¹ì…˜ìœ¼ë¡œ ì²˜ë¦¬
            return {
                "magazine_title": "AI ìƒì„± ì—¬í–‰ ë§¤ê±°ì§„", 
                "content_type": "single_section",
                "sections": [{"title": "ì—¬í–‰ ì´ì•¼ê¸°", "content": str(magazine_content)}]
            }

    def _split_content_into_sections(self, content: str) -> List[Dict]:
        """í…ìŠ¤íŠ¸ ì½˜í…ì¸ ë¥¼ ì—¬ëŸ¬ ì„¹ì…˜ìœ¼ë¡œ ë¶„í• """
        
        sections = []
        
        # 1. í—¤ë” ê¸°ë°˜ ë¶„í•  (## ë˜ëŠ” ###)
        import re
        header_pattern = r'^(#{1,3})\s+(.+?)$'
        
        lines = content.split('\n')
        current_section = {"title": "", "content": ""}
        current_content = []
        
        for line in lines:
            header_match = re.match(header_pattern, line.strip())
            if header_match:
                # ì´ì „ ì„¹ì…˜ ì €ì¥
                if current_section["title"] or current_content:
                    current_section["content"] = '\n'.join(current_content).strip()
                    if current_section["content"]:
                        sections.append(current_section.copy())
                
                # ìƒˆ ì„¹ì…˜ ì‹œì‘
                header_text = header_match.group(2).strip()
                current_section = {"title": header_text, "content": ""}
                current_content = []
            else:
                if line.strip():
                    current_content.append(line)
        
        # ë§ˆì§€ë§‰ ì„¹ì…˜ ì €ì¥
        if current_section["title"] or current_content:
            current_section["content"] = '\n'.join(current_content).strip()
            if current_section["content"]:
                sections.append(current_section)
        
        # 2. í—¤ë”ê°€ ì—†ëŠ” ê²½ìš° ê¸¸ì´ ê¸°ë°˜ ë¶„í• 
        if not sections:
            sections = self._split_by_length(content)
        
        # 3. ìµœì†Œ ì„¹ì…˜ ë³´ì¥
        if not sections:
            sections = [{"title": "ì—¬í–‰ ì´ì•¼ê¸°", "content": content}]
        
        self.logger.info(f"ì½˜í…ì¸ ë¥¼ {len(sections)}ê°œ ì„¹ì…˜ìœ¼ë¡œ ë¶„í• ")
        return sections

    def _split_by_length(self, content: str, max_length: int = 800) -> List[Dict]:
        """ê¸¸ì´ ê¸°ë°˜ ì„¹ì…˜ ë¶„í• """
        
        sections = []
        paragraphs = [p.strip() for p in content.split('\n\n') if p.strip()]
        
        current_section = ""
        section_count = 1
        
        for paragraph in paragraphs:
            if len(current_section + paragraph) > max_length and current_section:
                # í˜„ì¬ ì„¹ì…˜ ì €ì¥
                sections.append({
                    "title": f"ì—¬í–‰ ì´ì•¼ê¸° {section_count}",
                    "content": current_section.strip()
                })
                current_section = paragraph
                section_count += 1
            else:
                current_section += "\n\n" + paragraph if current_section else paragraph
        
        # ë§ˆì§€ë§‰ ì„¹ì…˜ ì €ì¥
        if current_section:
            sections.append({
                "title": f"ì—¬í–‰ ì´ì•¼ê¸° {section_count}",
                "content": current_section.strip()
            })
        
        return sections

    async def _integrate_processing_results(self, semantic_analysis: Dict,
                                          layout_results: Dict,
                                          unified_results: Dict) -> Dict:
        """ì²˜ë¦¬ ê²°ê³¼ë“¤ í†µí•©"""
        
        integrated_data = {
            "selected_templates": unified_results.get("selected_templates", []),
            "content_sections": unified_results.get("content_sections", []),
            "semantic_analysis": semantic_analysis,
            "optimized_layouts": layout_results.get("optimized_layouts", []),
            "integration_metadata": {
                "multimodal_processing": True,
                "semantic_optimization": True,
                "layout_optimization": True,
                "processing_timestamp": asyncio.get_event_loop().time(),
                "total_sections": len(unified_results.get("content_sections", [])),
                "semantic_confidence": semantic_analysis.get("analysis_metadata", {}).get("mapping_confidence", 0.0),
                "ai_search_enhanced": semantic_analysis.get("analysis_metadata", {}).get("ai_search_enhanced", False)
            }
        }
        
        return integrated_data

    async def _package_final_results(self, integrated_data: Dict,
                                   jsx_results: Dict,
                                   input_data: Dict) -> Dict:
        """ìµœì¢… ê²°ê³¼ íŒ¨í‚¤ì§•"""
        
        final_result = {
            "template_data": integrated_data,
            "jsx_components": jsx_results.get("jsx_components", []),
            "processing_summary": {
                "total_sections": len(integrated_data.get("content_sections", [])),
                "total_jsx_components": len(jsx_results.get("jsx_components", [])),
                "semantic_confidence": integrated_data.get("integration_metadata", {}).get("semantic_confidence", 0.0),
                "multimodal_optimization": True,
                "responsive_design": True,
                "style_optimization": True
            },
            "execution_logs": {
                "image_analysis_completed": True,
                "content_creation_completed": True,
                "semantic_analysis_completed": True,
                "layout_generation_completed": True,
                "multimodal_processing_completed": True,
                "jsx_generation_completed": True,
                "integration_completed": True
            },
            "source_data": {
                "magazine_content_sections": len(input_data.get("magazine_content", {}).get("sections", [])),
                "image_analysis_count": len(input_data.get("image_analysis", [])),
                "available_templates": integrated_data.get("selected_templates", [])
            }
        }
        
        return final_result

    async def _save_results_with_file_manager(self, final_result: Dict) -> None:
        """ê²°ê³¼ ì €ì¥ (ì™„ì „íˆ ê°œì„ ëœ File Manager í™œìš©)"""
        
        try:
            # 1. ê¸°ë³¸ JSON ì €ì¥ (SystemCoordinator ì—­í• )
            outputs_data = {
                "processing_summary": final_result.get("processing_summary", {}),
                "execution_logs": final_result.get("execution_logs", {}),
                "timestamp": asyncio.get_event_loop().time()
            }
            
            if "source_data" in final_result:
                outputs_data["source_data"] = final_result["source_data"]
            else:
                outputs_data["source_data"] = {
                    "magazine_content_sections": 0,
                    "image_analysis_count": 0,
                    "available_templates": []
                }
            
            outputs_path = os.path.join(self.file_manager.output_folder, "latest_outputs.json")
            self.file_manager.save_json(outputs_data, outputs_path)
            
            # âœ… 2. template_data.json ì €ì¥ (File Managerì— ìœ„ì„)
            template_data = final_result.get("template_data", {})
            if template_data and template_data.get("content_sections"):
                template_path = os.path.join(self.file_manager.output_folder, "template_data.json")
                await self.file_manager.save_template_data_async(template_data, template_path)
                self.logger.info(f"âœ… template_data.json ì €ì¥: {len(template_data.get('content_sections', []))}ê°œ ì„¹ì…˜")
            


            #  3. React ì•± ìƒì„± ìš”ì²­
            jsx_components = final_result.get("jsx_components", [])
            if template_data.get("content_sections") and jsx_components:
                project_name = f"magazine_app_{int(asyncio.get_event_loop().time())}"
                project_folder = self.file_manager.create_project_folder(project_name)
                
                # JSX ì €ì¥ì€ ì—¬ê¸°ì„œë§Œ í•œ ë²ˆë§Œ ìˆ˜í–‰
                self.file_manager.create_magazine_react_app(
                    project_folder=project_folder,
                    saved_components=jsx_components,
                    template_data=template_data
                )
                
                self.logger.info(f"âœ… React ì•± ìƒì„± ì™„ë£Œ: {project_folder}")
                self.logger.info(f"ğŸ“± ì‹¤í–‰ ë°©ë²•: cd {project_folder} && npm install && npm run dev")
            
        except Exception as e:
            self.logger.error(f"ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}")
            raise


