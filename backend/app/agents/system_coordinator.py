import asyncio
import os
import json
from typing import Dict, List

from crewai import Crew
from utils.hybridlogging import get_hybrid_logger
from utils.file_manager import FileManager
from utils.blob_storage import BlobStorageManager
from utils.logging_manager import LoggingManager

from agents.image_analyzer import ImageAnalyzerAgent
from agents.contents.content_creator import ContentCreatorV2Crew

from agents.Editor.unified_multimodal_agent import UnifiedMultimodalAgent
from agents.Editor.semantic_analysis_engine import SemanticAnalysisEngine
from agents.Editor.realtime_layout_generator import RealtimeLayoutGenerator
from agents.jsx.unified_jsx_generator import UnifiedJSXGenerator
from utils.template_scanner import TemplateScanner

# Cosmos DB ê´€ë ¨ import
from db.cosmos_connection import image_container, magazine_container, logging_container, temmplate_container
from db.db_utils import save_to_cosmos


class SystemCoordinator:
    """í†µí•© ì‹œìŠ¤í…œ ì¡°ìœ¨ì - ê¸°ì¡´ ì‹œìŠ¤í…œê³¼ ìƒˆë¡œìš´ ì‹œìŠ¤í…œ ì™„ì „ í†µí•©"""

    def __init__(self):
        self.logger = get_hybrid_logger(self.__class__.__name__)
        self.file_manager = FileManager(
            output_folder=os.getenv("OUTPUT_FOLDER", "./output"))
        self.blob_manager = BlobStorageManager()
        self.logging_manager = LoggingManager()

        # ê¸°ì¡´ ì—ì´ì „íŠ¸ë“¤ (1-2ë‹¨ê³„ìš©)
        self.image_analyzer = ImageAnalyzerAgent()
        self.content_creator = ContentCreatorV2Crew()

        # ìƒˆë¡œìš´ í†µí•© ì—ì´ì „íŠ¸ë“¤ (3ë‹¨ê³„ìš©)
        self.multimodal_agent = UnifiedMultimodalAgent()
        self.semantic_engine = SemanticAnalysisEngine()
        self.layout_generator = RealtimeLayoutGenerator()
        self.jsx_generator = UnifiedJSXGenerator()
        self.template_scanner = TemplateScanner()

    async def coordinate_complete_magazine_generation(self, user_input: str = None,
                                                      image_folder: str = None,
                                                      available_templates: List[str] = None) -> Dict:
        """ì™„ì „ í†µí•© ë§¤ê±°ì§„ ìƒì„± í”„ë¡œì„¸ìŠ¤"""

        self.logger.info("=== ì™„ì „ í†µí•© ë§¤ê±°ì§„ ìƒì„± í”„ë¡œì„¸ìŠ¤ ì‹œì‘ ===")

        try:
            # í…œí”Œë¦¿ì´ ì œê³µë˜ì§€ ì•Šì€ ê²½ìš° ë™ì  ìŠ¤ìº”
            if not available_templates:
                self.logger.info("í…œí”Œë¦¿ ëª©ë¡ì´ ì œê³µë˜ì§€ ì•ŠìŒ. ë™ì  ìŠ¤ìº” ì‹¤í–‰")
                available_templates = await self.template_scanner.scan_jsx_templates()

            # í…œí”Œë¦¿ ë©”íƒ€ë°ì´í„° ë¡œê¹…
            template_metadata = await self.template_scanner.get_template_metadata()
            self.logger.info(f"í…œí”Œë¦¿ ë©”íƒ€ë°ì´í„°: {template_metadata}")

            # âœ… ì‹¤ì œ ì²˜ë¦¬ ë‹¨ê³„ë“¤ ì‹¤í–‰
            # 1ë‹¨ê³„: ì´ë¯¸ì§€ ë¶„ì„
            image_results = await self._execute_image_analysis_stage()

            # 2ë‹¨ê³„: ì½˜í…ì¸  ìƒì„±
            magazine_content = await self._execute_content_creation_stage(image_results)

            # 3ë‹¨ê³„: ë©€í‹°ëª¨ë‹¬ ì²˜ë¦¬
            final_result = await self._execute_multimodal_processing_stage(
                magazine_content, image_results, available_templates
            )

            self.logger.info("=== ì™„ì „ í†µí•© ë§¤ê±°ì§„ ìƒì„± í”„ë¡œì„¸ìŠ¤ ì™„ë£Œ ===")
            return final_result

        except Exception as e:
            self.logger.error(f"ì™„ì „ í†µí•© ë§¤ê±°ì§„ ìƒì„± ì‹¤íŒ¨: {e}")

    async def _execute_image_analysis_stage(self) -> List[Dict]:
        """1ë‹¨ê³„: ì´ë¯¸ì§€ ë¶„ì„ ì‹¤í–‰ (ê¸°ì¡´ ì‹œìŠ¤í…œ í™œìš©)"""
        self.logger.info("1ë‹¨ê³„: ì´ë¯¸ì§€ ë¶„ì„ ì‹œì‘")

        images = self.blob_manager.get_images()
        self.logger.info(f"ì´ë¯¸ì§€ {len(images)}ê°œ ë°œê²¬")

        crew = Crew(agents=[self.image_analyzer.create_agent()], verbose=False)
        try:
            if hasattr(self.image_analyzer, 'analyze_images_batch_async'):
                results = await self.image_analyzer.analyze_images_batch_async(images, max_concurrent=5)
            else:
                loop = asyncio.get_event_loop()
                results = await loop.run_in_executor(None, self.image_analyzer.analyze_images, images, crew)
            for result in results:
                # user_idê°€ ì—†ë‹¤ë©´ ê¸°ë³¸ê°’ ë¶€ì—¬ (ì˜ˆ: 'unknown_user')

                if 'user_id' not in result:
                    result['user_id'] = 'unknown_user'
                save_to_cosmos(image_container, result,
                               partition_key_field='user_id')

            # # âœ… ê²°ê³¼ ì €ì¥ (ê¸°ì¡´ file_manager í™œìš©)
            #     analysis_path = os.path.join(self.file_manager.output_folder, "image_analysis_results.json")
            #     self.file_manager.save_json(results, analysis_path)

            # âœ… ìƒˆë¡œìš´ ë¡œê¹… ë°©ì‹ ì ìš©
            await self.logging_manager.log_image_analysis_completion(len(images), len(results))

            self.logger.info(f"1ë‹¨ê³„: ì´ë¯¸ì§€ ë¶„ì„ ì™„ë£Œ - {len(results)}ê°œ ê²°ê³¼")
            return results

        except Exception as e:
            self.logger.error(f"ì´ë¯¸ì§€ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return []

    async def _execute_content_creation_stage(self, image_results: List[Dict]) -> str:
        """2ë‹¨ê³„: ì½˜í…ì¸  ìƒì„± ì‹¤í–‰ (ê¸°ì¡´ ì‹œìŠ¤í…œ í™œìš©)"""
        self.logger.info("2ë‹¨ê³„: ì½˜í…ì¸  ìƒì„± ì‹œì‘")

        text_blobs = self.blob_manager.get_texts()
        texts = [self.blob_manager.read_text_file(
            text_blob) for text_blob in text_blobs]

        try:
            if hasattr(self.content_creator, 'execute_content_creation') and asyncio.iscoroutinefunction(self.content_creator.execute_content_creation):
                magazine_content = await self.content_creator.execute_content_creation(texts, image_results)
            else:
                magazine_content = await asyncio.get_event_loop().run_in_executor(
                    None, self.content_creator.execute_content_creation_sync, texts, image_results
                )

            if isinstance(magazine_content, str):
                try:
                    magazine_content_dict = json.loads(magazine_content)
                except Exception:
                    magazine_content_dict = {"content": magazine_content}
            else:
                magazine_content_dict = magazine_content

            if 'mag_id' not in magazine_content_dict:
                magazine_content_dict['mag_id'] = magazine_content_dict.get(
                    'mag_id', 'unknown_mag')

            save_to_cosmos(magazine_container,
                           magazine_content_dict, partition_key_field='mag_id')

            # # âœ… ê²°ê³¼ ì €ì¥ (ê¸°ì¡´ file_manager í™œìš©)
            # content_path = os.path.join(
            #     self.file_manager.output_folder, "magazine_content.json")
            # self.file_manager.save_magazine_content_json(
            #     magazine_content, content_path)

            # âœ… ìƒˆë¡œìš´ ë¡œê¹… ë°©ì‹ ì ìš©
            await self.logging_manager.log_content_creation_completion(len(texts), len(image_results), len(magazine_content))

            self.logger.info(f"2ë‹¨ê³„: ì½˜í…ì¸  ìƒì„± ì™„ë£Œ - {len(magazine_content)}ì")
            return magazine_content

        except Exception as e:
            self.logger.error(f"ì½˜í…ì¸  ìƒì„± ì‹¤íŒ¨: {e}")
            return "ê¸°ë³¸ ì—¬í–‰ ë§¤ê±°ì§„ ì½˜í…ì¸ "

    async def _execute_multimodal_processing_stage(self, magazine_content: str,
                                                   image_results: List[Dict],
                                                   available_templates: List[str]) -> Dict:
        """3ë‹¨ê³„: í†µí•© ë©€í‹°ëª¨ë‹¬ ì²˜ë¦¬ ì‹¤í–‰ (ì´ë¯¸ì§€ ë‹¤ì–‘ì„± ìµœì í™” í¬í•¨)"""
        self.logger.info("3ë‹¨ê³„: í†µí•© ë©€í‹°ëª¨ë‹¬ ì²˜ë¦¬ ì‹œì‘")

        try:
            parsed_content = self._parse_magazine_content_to_sections(
                magazine_content)
            self.logger.info(
                f"íŒŒì‹±ëœ ì„¹ì…˜ ìˆ˜: {len(parsed_content.get('sections', []))}")

            input_data = {
                "magazine_content": parsed_content,
                "image_analysis": image_results
            }

            # âœ… ì´ë¯¸ì§€ ë‹¤ì–‘ì„± ìµœì í™” ë¡œê¹…
            self.logger.info(f"ì´ë¯¸ì§€ ë‹¤ì–‘ì„± ìµœì í™” ëŒ€ìƒ: {len(image_results)}ê°œ ì´ë¯¸ì§€")

            # ì˜ë¯¸ì  ë¶„ì„ ìˆ˜í–‰
            semantic_analysis = await self.semantic_engine.analyze_text_image_semantics(
                input_data["magazine_content"],
                input_data["image_analysis"]
            )

            # âœ… ë‘ ê°€ì§€ í‚¤ ëª¨ë‘ ì§€ì›
            text_semantics = semantic_analysis.get('text_semantics', [])
            if not text_semantics:
                # ì´ì „ ë²„ì „ í˜¸í™˜ì„±
                semantic_mappings = semantic_analysis.get(
                    'semantic_mappings', [])
                text_semantics = semantic_mappings  # ë§¤í•‘ì„ í…ìŠ¤íŠ¸ ì˜ë¯¸ë¡œ ì‚¬ìš©

            self.logger.info(f"ì˜ë¯¸ ë¶„ì„ëœ í…ìŠ¤íŠ¸ ì„¹ì…˜: {len(text_semantics)}")

            # âœ… ì˜ë¯¸ì  ë¶„ì„ ë¡œê¹…
            await self.logging_manager.log_semantic_analysis_completion(semantic_analysis)

            self.logger.info(
                f"ì˜ë¯¸ ë¶„ì„ëœ í…ìŠ¤íŠ¸ ì„¹ì…˜: {len(semantic_analysis.get('text_semantics', []))}")

            # ì‹¤ì‹œê°„ ë ˆì´ì•„ì›ƒ ìƒì„±
            layout_results = await self.layout_generator.generate_optimized_layouts(
                semantic_analysis,
                available_templates
            )

            # âœ… ë ˆì´ì•„ì›ƒ ìƒì„± ë¡œê¹…
            await self.logging_manager.log_layout_generation_completion(layout_results)

            # âœ… ë©€í‹°ëª¨ë‹¬ ì—ì´ì „íŠ¸ë¡œ í†µí•© ì²˜ë¦¬ (ì´ë¯¸ì§€ ë‹¤ì–‘ì„± ìµœì í™” í¬í•¨)
            unified_results = await self.multimodal_agent.process_magazine_unified(
                input_data["magazine_content"],
                input_data["image_analysis"],
                available_templates
            )

            # âœ… ë©€í‹°ëª¨ë‹¬ ì²˜ë¦¬ ë¡œê¹…
            await self.logging_manager.log_multimodal_processing_completion(unified_results)

            # âœ… ë‹¤ì–‘ì„± ìµœì í™” ê²°ê³¼ ë¡œê¹…
            if unified_results.get("diversity_optimization_applied"):
                optimization_stats = unified_results.get(
                    "optimization_stats", {})
                total_used = unified_results.get("total_images_used", 0)
                utilization_rate = total_used / \
                    len(image_results) if image_results else 0

                await self.logging_manager.log_diversity_optimization_completion({
                    "utilization_rate": utilization_rate,
                    "total_images_processed": len(image_results),
                    "total_images_used": total_used,
                    "optimization_stats": optimization_stats
                })

                self.logger.info(f"âœ… ì´ë¯¸ì§€ ë‹¤ì–‘ì„± ìµœì í™” ì ìš© - í™œìš©ë¥ : {utilization_rate:.2%}, "
                                 f"CLIP ì‚¬ìš©: {optimization_stats.get('clip_available', False)}")

            # ê²°ê³¼ í†µí•©
            integrated_data = await self._integrate_processing_results(
                semantic_analysis, layout_results, unified_results
            )

            self.logger.info(
                f"í†µí•©ëœ ì½˜í…ì¸  ì„¹ì…˜: {len(integrated_data.get('content_sections', []))}")

            # JSX ì»´í¬ë„ŒíŠ¸ ìƒì„±
            jsx_results = await self.jsx_generator.generate_jsx_with_multimodal_context(
                integrated_data
            )

            # âœ… JSX ìƒì„± ë¡œê¹…
            await self.logging_manager.log_jsx_generation_completion(
                len(jsx_results.get('jsx_components', [])), jsx_results
            )

            self.logger.info(
                f"ìƒì„±ëœ JSX ì»´í¬ë„ŒíŠ¸: {len(jsx_results.get('jsx_components', []))}")

            # ìµœì¢… ê²°ê³¼ íŒ¨í‚¤ì§•
            final_result = await self._package_final_results(
                integrated_data, jsx_results, input_data
            )

            # âœ… ë‹¤ì–‘ì„± ìµœì í™” ë©”íƒ€ë°ì´í„° ì¶”ê°€
            final_result["diversity_optimization"] = {
                "applied": unified_results.get("diversity_optimization_applied", False),
                "total_images_processed": len(image_results),
                "total_images_used": unified_results.get("total_images_used", 0),
                "optimization_stats": unified_results.get("optimization_stats", {})
            }

            # ê²°ê³¼ ì €ì¥
            await self._save_results_with_file_manager(final_result)

            self.logger.info("3ë‹¨ê³„: í†µí•© ë©€í‹°ëª¨ë‹¬ ì²˜ë¦¬ ì™„ë£Œ (ì´ë¯¸ì§€ ë‹¤ì–‘ì„± ìµœì í™” í¬í•¨)")
            return final_result

        except Exception as e:
            self.logger.error(f"ë©€í‹°ëª¨ë‹¬ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")

    def _parse_magazine_content_to_sections(self, magazine_content: str) -> Dict:
        """ë§¤ê±°ì§„ ì½˜í…ì¸ ë¥¼ ì„¹ì…˜ìœ¼ë¡œ íŒŒì‹± (JSON ìš°ì„  ì²˜ë¦¬)"""
        try:
            # JSON í˜•ì‹ íŒŒì‹± ì‹œë„
            import json
            parsed_json = json.loads(magazine_content)

            if isinstance(parsed_json, dict) and "sections" in parsed_json:
                # JSON êµ¬ì¡°ê°€ ì˜¬ë°”ë¥¸ ê²½ìš°
                sections = []
                for section in parsed_json["sections"]:
                    if isinstance(section, dict):
                        sections.append({
                            "title": section.get("title", "ì œëª© ì—†ìŒ"),
                            "subtitle": section.get("subtitle", ""),
                            "content": section.get("body", ""),
                            "image_keywords": section.get("image_keywords", [])
                        })

                self.logger.info(f"JSON íŒŒì‹± ì„±ê³µ: {len(sections)}ê°œ ì„¹ì…˜")
                return {
                    "title": parsed_json.get("magazine_title", "ì—¬í–‰ ë§¤ê±°ì§„"),
                    "subtitle": parsed_json.get("magazine_subtitle", ""),
                    "sections": sections
                }

        except json.JSONDecodeError:
            self.logger.info("JSON íŒŒì‹± ì‹¤íŒ¨, í…ìŠ¤íŠ¸ ê¸°ë°˜ íŒŒì‹± ì‹œë„")

        # ê¸°ì¡´ í…ìŠ¤íŠ¸ ê¸°ë°˜ íŒŒì‹± (í´ë°±)
        if "===" in magazine_content:
            return self._split_by_headers(magazine_content)
        else:
            # ê¸¸ì´ ë‹¨ì¶•
            return self._split_by_length(magazine_content, max_length=500)

    def _split_by_headers(self, content: str) -> Dict:
        """í—¤ë” ê¸°ë°˜ ì„¹ì…˜ ë¶„í•  (ê°œì„ ëœ ë²„ì „)"""
        sections = []
        lines = content.split('\n')
        current_section = {"title": "", "content": ""}

        for line in lines:
            line = line.strip()

            # êµ¬ì¡°ì  ë§ˆì»¤ ì œê±°
            if "magazine layout design structure" in line.lower():
                continue

            if line.startswith("===") and line.endswith("==="):
                # ì´ì „ ì„¹ì…˜ ì €ì¥
                if current_section["content"]:
                    # ë‚´ìš© ê¸¸ì´ ì œí•œ
                    if len(current_section["content"]) > 500:
                        current_section["content"] = current_section["content"][:497] + "..."
                    sections.append(current_section)

                # ìƒˆ ì„¹ì…˜ ì‹œì‘
                title = line.replace("===", "").strip()
                current_section = {"title": title, "content": ""}
            else:
                if line:
                    current_section["content"] += line + " "

        # ë§ˆì§€ë§‰ ì„¹ì…˜ ì €ì¥
        if current_section["content"]:
            if len(current_section["content"]) > 500:
                current_section["content"] = current_section["content"][:497] + "..."
            sections.append(current_section)

        self.logger.info(f"í—¤ë” ê¸°ë°˜ íŒŒì‹±: {len(sections)}ê°œ ì„¹ì…˜")
        return {
            "title": "ì—¬í–‰ ë§¤ê±°ì§„",
            "subtitle": "",
            "sections": sections
        }

    def _split_by_length(self, content: str, max_length: int = 1000) -> List[Dict]:
        """ê¸¸ì´ ê¸°ë°˜ ì„¹ì…˜ ë¶„í• """

        sections = []
        paragraphs = [p.strip() for p in content.split('\n\n') if p.strip()]

        current_section = ""
        section_count = 1

        for paragraph in paragraphs:
            if len(current_section + paragraph) > max_length and current_section:
                # í˜„ì¬ ì„¹ì…˜ ì €ì¥
                sections.append({
                    "title": f"ì—¬í–‰ ì´ì•¼ê¸° {section_count}",
                    "content": current_section.strip()
                })
                current_section = paragraph
                section_count += 1
            else:
                current_section += "\n\n" + paragraph if current_section else paragraph

        # ë§ˆì§€ë§‰ ì„¹ì…˜ ì €ì¥
        if current_section:
            sections.append({
                "title": f"ì—¬í–‰ ì´ì•¼ê¸° {section_count}",
                "content": current_section.strip()
            })

        return sections

    async def _integrate_processing_results(self, semantic_analysis: Dict,
                                            layout_results: Dict,
                                            unified_results: Dict) -> Dict:
        """ì²˜ë¦¬ ê²°ê³¼ë“¤ í†µí•©"""

        integrated_data = {
            "selected_templates": unified_results.get("selected_templates", []),
            "content_sections": unified_results.get("content_sections", []),
            "semantic_analysis": semantic_analysis,
            "optimized_layouts": layout_results.get("optimized_layouts", []),
            "integration_metadata": {
                "multimodal_processing": True,
                "semantic_optimization": True,
                "layout_optimization": True,
                "processing_timestamp": asyncio.get_event_loop().time(),
                "total_sections": len(unified_results.get("content_sections", [])),
                "semantic_confidence": semantic_analysis.get("analysis_metadata", {}).get("mapping_confidence", 0.0),
                "ai_search_enhanced": semantic_analysis.get("analysis_metadata", {}).get("ai_search_enhanced", False)
            }
        }

        return integrated_data

    async def _package_final_results(self, integrated_data: Dict,
                                     jsx_results: Dict,
                                     input_data: Dict) -> Dict:
        """ìµœì¢… ê²°ê³¼ íŒ¨í‚¤ì§•"""

        final_result = {
            "template_data": integrated_data,
            "jsx_components": jsx_results.get("jsx_components", []),
            "processing_summary": {
                "total_sections": len(integrated_data.get("content_sections", [])),
                "total_jsx_components": len(jsx_results.get("jsx_components", [])),
                "semantic_confidence": integrated_data.get("integration_metadata", {}).get("semantic_confidence", 0.0),
                "multimodal_optimization": True,
                "responsive_design": True,
                "style_optimization": True
            },
            "execution_logs": {
                "image_analysis_completed": True,
                "content_creation_completed": True,
                "semantic_analysis_completed": True,
                "layout_generation_completed": True,
                "multimodal_processing_completed": True,
                "jsx_generation_completed": True,
                "integration_completed": True
            },
            "source_data": {
                "magazine_content_sections": len(input_data.get("magazine_content", {}).get("sections", [])),
                "image_analysis_count": len(input_data.get("image_analysis", [])),
                "available_templates": integrated_data.get("selected_templates", [])
            }
        }

        return final_result

    async def _save_results_with_file_manager(self, final_result: Dict) -> None:
        """ê²°ê³¼ ì €ì¥ (ì™„ì „íˆ ê°œì„ ëœ File Manager í™œìš©)"""

        try:
            # 1. ê¸°ë³¸ JSON ì €ì¥ (SystemCoordinator ì—­í• )
            outputs_data = {
                "processing_summary": final_result.get("processing_summary", {}),
                "execution_logs": final_result.get("execution_logs", {}),
                "timestamp": asyncio.get_event_loop().time()
            }

            if "source_data" in final_result:
                outputs_data["source_data"] = final_result["source_data"]
            else:
                outputs_data["source_data"] = {
                    "magazine_content_sections": 0,
                    "image_analysis_count": 0,
                    "available_templates": []
                }

            # session_id íŒŒí‹°ì…˜ í‚¤
            if 'session_id' not in outputs_data:
                outputs_data['session_id'] = final_result.get(
                    'session_id', 'unknown_session')

            # Cosmos DBì— ì €ì¥ (íŒŒí‹°ì…˜ í‚¤: session_id)
            save_to_cosmos(logging_container, outputs_data,
                           partition_key_field='session_id')
            self.logger.info("âœ… outputs ë°ì´í„° Cosmos DB ì €ì¥ ì™„ë£Œ")

            # outputs_path = os.path.join(
            #     self.file_manager.output_folder, "latest_outputs.json")
            # self.file_manager.save_json(outputs_data, outputs_path)

            # âœ… 2. template_data.json ì €ì¥ (File Managerì— ìœ„ì„)
            # template_data = final_result.get("template_data", {})
            # if template_data and template_data.get("content_sections"):
            #     template_path = os.path.join(
            #         self.file_manager.output_folder, "template_data.json")
            #     await self.file_manager.save_template_data_async(template_data, template_path)
            #     self.logger.info(
            #         f"âœ… template_data.json ì €ì¥: {len(template_data.get('content_sections', []))}ê°œ ì„¹ì…˜")

            # âœ… 2. template_dataë¥¼ Cosmos DBì— ì €ì¥ (ë¡œì»¬ íŒŒì¼ ëŒ€ì‹ )
            template_data = final_result.get("template_data", {})
            if template_data and template_data.get("content_sections"):
                # template_dataì— í•„ìš”í•œ ë©”íƒ€ë°ì´í„° ì¶”ê°€
                template_document = {
                    "id": f"template_{int(asyncio.get_event_loop().time())}",
                    "template_id": template_data.get("template_id", f"template_{int(asyncio.get_event_loop().time())}"),
                    "content_sections": template_data.get("content_sections", []),
                    "selected_templates": template_data.get("selected_templates", []),
                    "semantic_analysis": template_data.get("semantic_analysis", {}),
                    "optimized_layouts": template_data.get("optimized_layouts", []),
                    "integration_metadata": template_data.get("integration_metadata", {}),
                    "created_at": asyncio.get_event_loop().time(),
                    "document_type": "template_data"
                }

                # Cosmos DBì— ì €ì¥ (íŒŒí‹°ì…˜ í‚¤: template_id)
                save_to_cosmos(temmplate_container, template_document,
                               partition_key_field='user_id')

                self.logger.info(
                    f"âœ… template_data Cosmos DB ì €ì¥ ì™„ë£Œ: {len(template_data.get('content_sections', []))}ê°œ ì„¹ì…˜")

            #  3. React ì•± ìƒì„± ìš”ì²­
            jsx_components = final_result.get("jsx_components", [])
            if template_data.get("content_sections") and jsx_components:
                project_name = f"magazine_app_{int(asyncio.get_event_loop().time())}"
                project_folder = self.file_manager.create_project_folder(
                    project_name)

                # JSX ì €ì¥ì€ ì—¬ê¸°ì„œë§Œ í•œ ë²ˆë§Œ ìˆ˜í–‰
                self.file_manager.create_magazine_react_app(
                    project_folder=project_folder,
                    saved_components=jsx_components,
                    template_data=template_data
                )

                self.logger.info(f"âœ… React ì•± ìƒì„± ì™„ë£Œ: {project_folder}")
                self.logger.info(
                    f"ğŸ“± ì‹¤í–‰ ë°©ë²•: cd {project_folder} && npm install && npm run dev")

        except Exception as e:
            self.logger.error(f"ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}")
            raise
