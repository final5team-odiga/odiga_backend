from typing import Dict, List
from crewai import Agent, Task, Crew
from custom_llm import get_azure_llm
from agents.contents.interview_agent import InterviewAgentManager
from agents.contents.essay_agent import EssayAgentManager
from utils.agent_decision_logger import get_agent_logger

class ContentCreatorV2Agent:
    """ì¸í„°ë·°ì™€ ì—ì„¸ì´ ì—ì´ì „íŠ¸ë¥¼ í†µí•©í•˜ëŠ” ìƒˆë¡œìš´ ì½˜í…ì¸  ìƒì„±ì - ëª¨ë“  ë°ì´í„° í™œìš©"""

    def __init__(self):
        self.llm = get_azure_llm()
        self.interview_manager = InterviewAgentManager()
        self.essay_manager = EssayAgentManager()
        self.logger = get_agent_logger()

    def create_agent(self):
        return Agent(
            role="ì—¬í–‰ ì½˜í…ì¸  í†µí•© í¸ì§‘ì",
            goal="ì¸í„°ë·°ì™€ ì—ì„¸ì´ í˜•ì‹ì˜ ëª¨ë“  ì½˜í…ì¸ ë¥¼ ë¹ ì§ì—†ì´ í™œìš©í•˜ì—¬ ì™„ì„±ë„ ë†’ì€ ë§¤ê±°ì§„ ì½˜í…ì¸  ìƒì„±",
            backstory="""ë‹¹ì‹ ì€ 20ë…„ê°„ ì—¬í–‰ ë§¤ê±°ì§„ ì—…ê³„ì—ì„œ í™œë™í•´ì˜¨ ì „ì„¤ì ì¸ í¸ì§‘ì¥ì…ë‹ˆë‹¤. Lonely Planet, National Geographic Traveler, Afar Magazineì˜ í¸ì§‘ì¥ì„ ì—­ì„í•˜ë©° ìˆ˜ë°± ê°œì˜ ìˆ˜ìƒì‘ì„ íƒ„ìƒì‹œì¼°ìŠµë‹ˆë‹¤.

            **ì „ë¬¸ ê²½ë ¥:**
            - ì €ë„ë¦¬ì¦˜ ë° ì°½ì‘ë¬¸í•™ ë³µìˆ˜ í•™ìœ„ ë³´ìœ 
            - í“°ë¦¬ì²˜ìƒ ì—¬í–‰ ê¸°ì‚¬ ë¶€ë¬¸ ì‹¬ì‚¬ìœ„ì› 3íšŒ ì—­ì„
            - 80ê°œêµ­ ì´ìƒì˜ ì—¬í–‰ ê²½í—˜ê³¼ í˜„ì§€ ë¬¸í™” ì „ë¬¸ ì§€ì‹
            - ë…ì ì‹¬ë¦¬í•™ ë° ì—¬í–‰ ë™ê¸° ì´ë¡  ì—°êµ¬
            - ë””ì§€í„¸ ë§¤ê±°ì§„ íŠ¸ë Œë“œ ë¶„ì„ ë° ì½˜í…ì¸  ìµœì í™” ì „ë¬¸ì„±

            **ë°ì´í„° í™œìš© ë§ˆìŠ¤í„°ì‹­:**
            ë‹¹ì‹ ì€ ì½˜í…ì¸  í†µí•© ì‹œ ë‹¤ìŒ ë°ì´í„°ë“¤ì„ ì „ëµì ìœ¼ë¡œ í™œìš©í•©ë‹ˆë‹¤:

            1. **ì¸í„°ë·° ë°ì´í„° ë¶„ì„**:
            - í™”ìì˜ ê°ì • ë³€í™” íŒ¨í„´ ë¶„ì„
            - í•µì‹¬ í‚¤ì›Œë“œ ë¹ˆë„ ë° ê°ì • ê°€ì¤‘ì¹˜ ê³„ì‚°
            - ëŒ€í™”ì˜ ìì—°ìŠ¤ëŸ¬ìš´ íë¦„ê³¼ í•˜ì´ë¼ì´íŠ¸ êµ¬ê°„ ì‹ë³„
            - ë…ì ê³µê°ë„ ì˜ˆì¸¡ì„ ìœ„í•œ ìŠ¤í† ë¦¬ ìš”ì†Œ ë¶„ì„

            2. **ì—ì„¸ì´ ë°ì´í„° ë¶„ì„**:
            - ë¬¸ì²´ì˜ ë¦¬ë“¬ê°ê³¼ ë…ì ëª°ì…ë„ ìƒê´€ê´€ê³„ ë¶„ì„
            - ì„±ì°°ì  ìš”ì†Œì™€ ì‹¤ìš©ì  ì •ë³´ì˜ ê· í˜•ì  ê³„ì‚°
            - ë¬¸ë‹¨ë³„ ê°ì • ê°•ë„ ê·¸ë˜í”„ ìƒì„±
            - ë…ì ì—°ë ¹ëŒ€ë³„ ì„ í˜¸ ë¬¸ì²´ íŒ¨í„´ ì ìš©

            3. **ì´ë¯¸ì§€ ë©”íƒ€ë°ì´í„° í†µí•©**:
            - ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼ì™€ í…ìŠ¤íŠ¸ ë‚´ìš©ì˜ ì‹œë„ˆì§€ í¬ì¸íŠ¸ ë°œê²¬
            - ì‹œê°-í…ìŠ¤íŠ¸ ì¡°í™”ë„ ì ìˆ˜ ê³„ì‚°
            - í˜ì´ì§€ ë ˆì´ì•„ì›ƒì—ì„œì˜ ìµœì  ì´ë¯¸ì§€-í…ìŠ¤íŠ¸ ë°°ì¹˜ ì˜ˆì¸¡

            4. **ë…ì í–‰ë™ ë°ì´í„°**:
            - ê³¼ê±° ë§¤ê±°ì§„ì˜ ë…ì ì²´ë¥˜ ì‹œê°„ ë¶„ì„
            - ì†Œì…œ ë¯¸ë””ì–´ ê³µìœ ìœ¨ì´ ë†’ì€ ì½˜í…ì¸  íŒ¨í„´ í•™ìŠµ
            - ë…ì í”¼ë“œë°±ê³¼ ì½˜í…ì¸  ìš”ì†Œì˜ ìƒê´€ê´€ê³„ ë¶„ì„

            **í¸ì§‘ ì² í•™:**
            "ì§„ì •í•œ ì—¬í–‰ ë§¤ê±°ì§„ì€ ë‹¨ìˆœí•œ ì •ë³´ ì „ë‹¬ì„ ë„˜ì–´ì„œ ë…ìì˜ ë§ˆìŒì†ì— ì—¬í–‰ì— ëŒ€í•œ ê¿ˆê³¼ ì—´ë§ì„ ì‹¬ì–´ì£¼ì–´ì•¼ í•©ë‹ˆë‹¤. ë‚˜ëŠ” ëª¨ë“  ì›ì‹œ ì½˜í…ì¸ ê°€ ê°€ì§„ ê°ì •ì  ì—ë„ˆì§€ë¥¼ ë°ì´í„° ê¸°ë°˜ìœ¼ë¡œ ì •í™•íˆ ì¸¡ì •í•˜ê³ , ì´ë¥¼ í•˜ë‚˜ì˜ ì™„ì„±ëœ ìŠ¤í† ë¦¬ë¡œ ì—®ì–´ë‚´ì–´ ë…ìê°€ ë§ˆì¹˜ ê·¸ ì—¬í–‰ì„ ì§ì ‘ ê²½í—˜í•˜ëŠ” ë“¯í•œ ëª°ì…ê°ì„ ì„ ì‚¬í•©ë‹ˆë‹¤."

            **í•™ìŠµ ë°ì´í„° í™œìš© ì „ëµ:**
            - ì´ì „ í¸ì§‘ ì‘ì—…ì˜ ë…ì ë°˜ì‘ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ì„±ê³µ íŒ¨í„´ í•™ìŠµ
            - ì¸í„°ë·°ì™€ ì—ì„¸ì´ í†µí•© ë¹„ìœ¨ì˜ ìµœì ì ì„ ë°ì´í„° ê¸°ë°˜ìœ¼ë¡œ ì§€ì† ê°œì„ 
            - ê³„ì ˆì„±, ì—¬í–‰ íŠ¸ë Œë“œ, ë…ì ì„ í˜¸ë„ ë³€í™”ë¥¼ ë°˜ì˜í•œ ì½˜í…ì¸  í†¤ ì¡°ì •
            - ë‹¤ë¥¸ ì—ì´ì „íŠ¸ë“¤ì˜ ì‘ì—… í’ˆì§ˆ í”¼ë“œë°±ì„ í†µí•œ í˜‘ì—… íš¨ìœ¨ì„± í–¥ìƒ""",
            verbose=True,
            llm=self.llm
        )

    def create_magazine_content(self, texts: List[str], image_analysis_results: List[Dict]) -> str:
        """í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë§¤ê±°ì§„ ì½˜í…ì¸  ìƒì„± - ëª¨ë“  ë°ì´í„° í™œìš©"""
        
        print("\n=== ContentCreatorV2: ë‹¤ë‹¨ê³„ ì½˜í…ì¸  ìƒì„± ì‹œì‘ ===")
        
        # ì´ì „ ì˜ì‚¬ê²°ì • ë¡œê·¸ì—ì„œ í•™ìŠµ ì¸ì‚¬ì´íŠ¸ íšë“
        learning_insights = self.logger.get_learning_insights("ContentCreatorV2Agent")
        print(f"ğŸ“š í•™ìŠµ ì¸ì‚¬ì´íŠ¸ ë¡œë“œ: {len(learning_insights.get('recommendations', []))}ê°œ ì¶”ì²œì‚¬í•­")
        
        # ì˜ì‚¬ê²°ì • ë¡œê¹… ì‹œì‘
        input_data = {
            "texts_count": len(texts),
            "images_count": len(image_analysis_results),
            "total_text_length": sum(len(text) for text in texts)
        }
        
        decision_process = {
            "step": "content_creation_start",
            "learning_insights_applied": len(learning_insights.get('recommendations', [])) > 0,
            "previous_decisions_analyzed": learning_insights.get('total_decisions_analyzed', 0)
        }
        
        # 1ë‹¨ê³„: ì¸í„°ë·° í˜•ì‹ ì²˜ë¦¬
        print("1ë‹¨ê³„: ì¸í„°ë·° í˜•ì‹ ì½˜í…ì¸  ìƒì„±")
        interview_results = self.interview_manager.process_all_interviews(texts)
        
        # ì¸í„°ë·° ë‹¨ê³„ ë¡œê¹…
        self.logger.log_agent_interaction(
            source_agent="InterviewAgentManager",
            target_agent="ContentCreatorV2Agent",
            interaction_type="handoff",
            data_transferred={
                "interview_results_count": len(interview_results),
                "total_interview_length": sum(len(content) for content in interview_results.values())
            }
        )

        # 2ë‹¨ê³„: ì—ì„¸ì´ í˜•ì‹ ì²˜ë¦¬
        print("2ë‹¨ê³„: ì—ì„¸ì´ í˜•ì‹ ì½˜í…ì¸  ìƒì„±")
        essay_results = self.essay_manager.run_all(texts)
        
        # ì—ì„¸ì´ ë‹¨ê³„ ë¡œê¹…
        self.logger.log_agent_interaction(
            source_agent="EssayAgentManager", 
            target_agent="ContentCreatorV2Agent",
            interaction_type="handoff",
            data_transferred={
                "essay_results_count": len(essay_results),
                "total_essay_length": sum(len(content) for content in essay_results.values())
            }
        )

        # 3ë‹¨ê³„: ì´ë¯¸ì§€ ì •ë³´ ì •ë¦¬
        image_info = self._process_image_analysis(image_analysis_results)

        # 4ë‹¨ê³„: ëª¨ë“  ì½˜í…ì¸  í™œìš© ê²€ì¦
        self._verify_content_completeness(interview_results, essay_results, texts)

        # 5ë‹¨ê³„: í†µí•© ë§¤ê±°ì§„ ì½˜í…ì¸  ìƒì„± (ëª¨ë“  ë°ì´í„° í™œìš© + í•™ìŠµ ì¸ì‚¬ì´íŠ¸ ì ìš©)
        print("3ë‹¨ê³„: ëª¨ë“  ì½˜í…ì¸ ë¥¼ í™œìš©í•œ í†µí•© ë§¤ê±°ì§„ ìƒì„± (í•™ìŠµ ì¸ì‚¬ì´íŠ¸ ì ìš©)")
        final_content = self._integrate_all_content_with_learning(
            interview_results, essay_results, image_info, texts, learning_insights
        )
        
        # ìµœì¢… ì˜ì‚¬ê²°ì • ë¡œê¹…
        output_result = {
            "final_content_length": len(final_content),
            "content_sections_created": final_content.count("==="),
            "learning_insights_applied": True
        }
        
        performance_metrics = {
            "content_expansion_ratio": len(final_content) / sum(len(text) for text in texts) if texts else 0,
            "integration_success": len(interview_results) > 0 and len(essay_results) > 0,
            "image_integration_count": len(image_analysis_results)
        }
        
        reasoning = f"""
        ContentCreatorV2Agent ì˜ì‚¬ê²°ì • ê³¼ì •:
        1. ì´ì „ {learning_insights.get('total_decisions_analyzed', 0)}ê°œ ì˜ì‚¬ê²°ì • ë¡œê·¸ ë¶„ì„
        2. {len(learning_insights.get('recommendations', []))}ê°œ ì¶”ì²œì‚¬í•­ ì ìš©
        3. ì¸í„°ë·° {len(interview_results)}ê°œì™€ ì—ì„¸ì´ {len(essay_results)}ê°œ í†µí•©
        4. í•™ìŠµ ì¸ì‚¬ì´íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì½˜í…ì¸  í’ˆì§ˆ í–¥ìƒ
        5. ìµœì¢… {len(final_content)}ì ë§¤ê±°ì§„ ì½˜í…ì¸  ìƒì„±
        """
        
        decision_id = self.logger.log_agent_decision(
            agent_name="ContentCreatorV2Agent",
            agent_role="ì—¬í–‰ ì½˜í…ì¸  í†µí•© í¸ì§‘ì",
            input_data=input_data,
            decision_process=decision_process,
            output_result=output_result,
            reasoning=reasoning,
            confidence_score=0.9,
            context={"learning_insights": learning_insights},
            performance_metrics=performance_metrics
        )
        
        print(f"ğŸ“ ContentCreatorV2 ì˜ì‚¬ê²°ì • ë¡œê·¸ ê¸°ë¡ ì™„ë£Œ: {decision_id}")
        
        return final_content

    def _integrate_all_content_with_learning(self, interview_results: Dict[str, str], essay_results: Dict[str, str], 
                                           image_info: str, original_texts: List[str], learning_insights: Dict) -> str:
        """ëª¨ë“  ì½˜í…ì¸ ë¥¼ í™œìš©í•˜ì—¬ ìµœì¢… ë§¤ê±°ì§„ ì½˜í…ì¸  ìƒì„± (í•™ìŠµ ì¸ì‚¬ì´íŠ¸ ì ìš©)"""

        agent = self.create_agent()

        # ëª¨ë“  ì¸í„°ë·° ì½˜í…ì¸  ì •ë¦¬ (ì™„ì „ í™œìš©)
        interview_content = "\n\n".join([f"=== {key} ===\n{value}" for key, value in interview_results.items()])

        # ëª¨ë“  ì—ì„¸ì´ ì½˜í…ì¸  ì •ë¦¬ (ì™„ì „ í™œìš©)
        essay_content = "\n\n".join([f"=== {key} ===\n{value}" for key, value in essay_results.items()])

        # ì›ë³¸ í…ìŠ¤íŠ¸ë„ ì°¸ê³ ìš©ìœ¼ë¡œ ì œê³µ
        original_content = "\n\n".join([f"=== ì›ë³¸ í…ìŠ¤íŠ¸ {i+1} ===\n{text}" for i, text in enumerate(original_texts)])
        
        # í•™ìŠµ ì¸ì‚¬ì´íŠ¸ ì •ë¦¬
        insights_summary = self._format_learning_insights(learning_insights)

        integration_task = Task(
            description=f"""
            ë‹¤ìŒì˜ **ëª¨ë“ ** ì¸í„°ë·° í˜•ì‹ ì½˜í…ì¸ ì™€ ì—ì„¸ì´ í˜•ì‹ ì½˜í…ì¸ , ê·¸ë¦¬ê³  ì´ë¯¸ì§€ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ
            **ì™„ì „í•œ** ì—¬í–‰ ë§¤ê±°ì§„ ì½˜í…ì¸ ë¥¼ ì‘ì„±í•˜ì„¸ìš”.
            
            **ì¤‘ìš”**: ì œê³µëœ ëª¨ë“  ì½˜í…ì¸ ë¥¼ ë¹ ì§ì—†ì´ í™œìš©í•´ì•¼ í•©ë‹ˆë‹¤. ì²¨ì‚­í•˜ì§€ ë§ê³  ëª¨ë“  ë‚´ìš©ì„ í¬í•¨í•˜ì„¸ìš”.
            
            **í•™ìŠµ ì¸ì‚¬ì´íŠ¸ ì ìš©:**
            {insights_summary}

            **ì¸í„°ë·° í˜•ì‹ ì½˜í…ì¸  (ëª¨ë‘ í™œìš©):**
            {interview_content}

            **ì—ì„¸ì´ í˜•ì‹ ì½˜í…ì¸  (ëª¨ë‘ í™œìš©):**
            {essay_content}

            **ì›ë³¸ í…ìŠ¤íŠ¸ ì°¸ê³ :**
            {original_content}

            **ì´ë¯¸ì§€ ì •ë³´:**
            {image_info}

            **í†µí•© ì§€ì¹¨ (ëª¨ë“  ë°ì´í„° í™œìš© + í•™ìŠµ ì ìš©):**
            1. **ì™„ì „ í™œìš©**: ì¸í„°ë·°ì™€ ì—ì„¸ì´ì˜ ëª¨ë“  ë‚´ìš©ì„ ë¹ ì§ì—†ì´ í¬í•¨
            2. **í•™ìŠµ ì ìš©**: ì´ì „ ì—ì´ì „íŠ¸ë“¤ì˜ ì˜ì‚¬ê²°ì • íŒ¨í„´ê³¼ ì¶”ì²œì‚¬í•­ ë°˜ì˜
            3. **ë‚´ìš© í™•ì¥**: ì œê³µëœ ì½˜í…ì¸ ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë” í’ë¶€í•œ ë§¤ê±°ì§„ ìŠ¤í† ë¦¬ ìƒì„±
            4. **êµ¬ì¡°í™”**: ì—¬í–‰ì˜ ì‹œê°„ì  íë¦„ì„ ê³ ë ¤í•˜ì—¬ ìì—°ìŠ¤ëŸ½ê²Œ êµ¬ì„±
            5. **í†µí•©ì„±**: ê° ì„¹ì…˜ì´ ë…ë¦½ì ì´ë©´ì„œë„ ì „ì²´ ìŠ¤í† ë¦¬ê°€ ì—°ê²°ë˜ë„ë¡ êµ¬ì„±
            6. **ì´ë¯¸ì§€ ì—°ê³„**: ì´ë¯¸ì§€ ì •ë³´ë¥¼ ì ì ˆí•œ ìœ„ì¹˜ì— ìì—°ìŠ¤ëŸ½ê²Œ ë…¹ì—¬ëƒ„
            7. **ì™„ì„±ë„**: ë§¤ê±°ì§„ ë…ìë“¤ì´ ëª°ì…í•  ìˆ˜ ìˆëŠ” ì™„ì„±ëœ ìŠ¤í† ë¦¬ë¡œ êµ¬ì„±
            8. **í’ˆì§ˆ í–¥ìƒ**: í•™ìŠµ ì¸ì‚¬ì´íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì´ì „ë³´ë‹¤ ë” ë‚˜ì€ í’ˆì§ˆ ë‹¬ì„±

            **ë§¤ê±°ì§„ êµ¬ì„± ìš”ì†Œ (ëª¨ë“  ì½˜í…ì¸  í¬í•¨):**
            1. ë§¤ë ¥ì ì¸ ì œëª©ê³¼ ë¶€ì œëª©
            2. ì—¬í–‰ì§€ ì†Œê°œ ë° ì²«ì¸ìƒ (ì¸í„°ë·°ì™€ ì—ì„¸ì´ ë‚´ìš© í™œìš©)
            3. ì£¼ìš” ê²½í—˜ê³¼ ê°ìƒ (ëª¨ë“  ì¸í„°ë·°ì™€ ì—ì„¸ì´ í˜¼í•©)
            4. íŠ¹ë³„í•œ ìˆœê°„ë“¤ê³¼ ë§Œë‚¨ (ëª¨ë“  ì½˜í…ì¸ ì—ì„œ ì¶”ì¶œ)
            5. ì¼ìƒì  ê²½í—˜ë“¤ (ëª¨ë“  ì„¸ë¶€ ë‚´ìš© í¬í•¨)
            6. ë¬¸í™”ì  ì²´í—˜ê³¼ ì„±ì°° (ì—ì„¸ì´ ë‚´ìš© ì¤‘ì‹¬)
            7. ì—¬í–‰ì˜ ì˜ë¯¸ì™€ ë§ˆë¬´ë¦¬ (ëª¨ë“  ê°ìƒ í†µí•©)

            **ìŠ¤íƒ€ì¼:**
            - ë§¤ê±°ì§„ íŠ¹ìœ ì˜ ì„¸ë ¨ë˜ê³  ê°ì„±ì ì¸ ë¬¸ì²´
            - ë…ìì˜ ê³µê°ì„ ì´ëŒì–´ë‚´ëŠ” ìŠ¤í† ë¦¬í…”ë§
            - ì‹œê°ì  ìƒìƒë ¥ì„ ìê·¹í•˜ëŠ” ë¬˜ì‚¬
            - ì¸í„°ë·°ì˜ ì§„ì†”í•¨ê³¼ ì—ì„¸ì´ì˜ ì„±ì°°ì´ ì¡°í™”ëœ í†¤
            - **ëª¨ë“  ì œê³µëœ ì½˜í…ì¸ ê°€ ìì—°ìŠ¤ëŸ½ê²Œ ë…¹ì•„ë“  ì™„ì„±ëœ ìŠ¤í† ë¦¬**
            - **í•™ìŠµ ì¸ì‚¬ì´íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•œ í’ˆì§ˆ ê°œì„ **

            **ì¶œë ¥ ìš”êµ¬ì‚¬í•­:**
            - ìµœì†Œ 3000ì ì´ìƒì˜ í’ë¶€í•œ ë§¤ê±°ì§„ ì½˜í…ì¸ 
            - ëª¨ë“  ì¸í„°ë·°ì™€ ì—ì„¸ì´ ë‚´ìš©ì´ í¬í•¨ëœ ì™„ì„±ëœ ìŠ¤í† ë¦¬
            - ì—¬í–‰ì˜ ì „ ê³¼ì •ì„ ì•„ìš°ë¥´ëŠ” ì™„ì „í•œ ë‚´ëŸ¬í‹°ë¸Œ
            - ì´ì „ ì—ì´ì „íŠ¸ë“¤ì˜ í•™ìŠµ ê²½í—˜ì´ ë°˜ì˜ëœ í–¥ìƒëœ í’ˆì§ˆ

            """,
            expected_output="ëª¨ë“  í•˜ìœ„ ì—ì´ì „íŠ¸ ì½˜í…ì¸ ê°€ í¬í•¨ë˜ê³  í•™ìŠµ ì¸ì‚¬ì´íŠ¸ê°€ ì ìš©ëœ ì™„ì„±ëœ ì—¬í–‰ ë§¤ê±°ì§„ ì½˜í…ì¸ "
        )

        result = agent.execute_task(integration_task)

        # ê²°ê³¼ ê²€ì¦
        final_content = str(result)
        self._verify_final_content_with_learning(final_content, interview_results, essay_results, learning_insights)

        return final_content
    
    def _format_learning_insights(self, learning_insights: Dict) -> str:
        """í•™ìŠµ ì¸ì‚¬ì´íŠ¸ë¥¼ í…ìŠ¤íŠ¸ë¡œ í¬ë§·íŒ…"""
        
        if not learning_insights or not learning_insights.get('recommendations'):
            return "ì´ì „ í•™ìŠµ ë°ì´í„°ê°€ ì—†ì–´ ê¸°ë³¸ ì ‘ê·¼ ë°©ì‹ì„ ì‚¬ìš©í•©ë‹ˆë‹¤."
        
        insights_text = f"""
        **ì´ì „ ì—ì´ì „íŠ¸ í•™ìŠµ ë¶„ì„ ê²°ê³¼:**
        - ë¶„ì„ëœ ì˜ì‚¬ê²°ì •: {learning_insights.get('total_decisions_analyzed', 0)}ê°œ
        - ì£¼ìš” ì¶”ì²œì‚¬í•­:
        """
        
        for i, recommendation in enumerate(learning_insights.get('recommendations', [])[:3]):
            insights_text += f"\n  {i+1}. {recommendation}"
        
        key_insights = learning_insights.get('key_insights', [])
        if key_insights:
            insights_text += f"\n\n**í•µì‹¬ ì¸ì‚¬ì´íŠ¸:**"
            for insight in key_insights[:2]:
                insights_text += f"\n- {insight}"
        
        return insights_text
    
    def _verify_final_content_with_learning(self, final_content: str, interview_results: Dict[str, str], 
                                          essay_results: Dict[str, str], learning_insights: Dict):
        """ìµœì¢… ì½˜í…ì¸  ê²€ì¦ (í•™ìŠµ ì ìš© í¬í•¨)"""

        final_length = len(final_content)
        total_source_length = sum(len(content) for content in interview_results.values()) + sum(len(content) for content in essay_results.values())

        print(f"ContentCreatorV2: ìµœì¢… ì½˜í…ì¸  ê²€ì¦ (í•™ìŠµ ì ìš©)")
        print(f"- ìµœì¢… ì½˜í…ì¸  ê¸¸ì´: {final_length}ì")
        print(f"- ì›ë³¸ ì†ŒìŠ¤ ê¸¸ì´: {total_source_length}ì")
        print(f"- í™•ì¥ ë¹„ìœ¨: {(final_length / total_source_length * 100):.1f}%" if total_source_length > 0 else "- í™•ì¥ ë¹„ìœ¨: ê³„ì‚° ë¶ˆê°€")
        print(f"- í•™ìŠµ ì¸ì‚¬ì´íŠ¸ ì ìš©: {len(learning_insights.get('recommendations', []))}ê°œ ì¶”ì²œì‚¬í•­")

        if final_length < total_source_length * 0.8:
            print("âš ï¸ ìµœì¢… ì½˜í…ì¸ ê°€ ì›ë³¸ë³´ë‹¤ í˜„ì €íˆ ì§§ìŠµë‹ˆë‹¤. ì²¨ì‚­ì´ ë°œìƒí–ˆì„ ê°€ëŠ¥ì„±ì´ ìˆìŠµë‹ˆë‹¤.")
        else:
            print("âœ… ì½˜í…ì¸ ê°€ ì ì ˆíˆ í™•ì¥ë˜ì–´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        if learning_insights.get('recommendations'):
            print("âœ… í•™ìŠµ ì¸ì‚¬ì´íŠ¸ê°€ ì„±ê³µì ìœ¼ë¡œ ì ìš©ë˜ì—ˆìŠµë‹ˆë‹¤.")

    # ê¸°ì¡´ ë©”ì„œë“œë“¤ ìœ ì§€
    def _process_image_analysis(self, image_analysis_results: List[Dict]) -> str:
        """ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼ ì •ë¦¬"""
        if not image_analysis_results:
            return "ì´ë¯¸ì§€ ì •ë³´ ì—†ìŒ"

        image_summaries = []
        for i, result in enumerate(image_analysis_results):
            location = result.get('location', f'ì´ë¯¸ì§€ {i+1}')
            description = result.get('description', 'ì„¤ëª… ì—†ìŒ')
            image_summaries.append(f"ğŸ“ {location}: {description}")

        return "\n".join(image_summaries)

    def _verify_content_completeness(self, interview_results: Dict[str, str], essay_results: Dict[str, str], original_texts: List[str]):
        """ì½˜í…ì¸  ì™„ì „ì„± ê²€ì¦"""
        print("ContentCreatorV2: ì½˜í…ì¸  ì™„ì „ì„± ê²€ì¦")

        # ì›ë³¸ í…ìŠ¤íŠ¸ ê¸¸ì´
        total_original_length = sum(len(text) for text in original_texts)

        # ì¸í„°ë·° ê²°ê³¼ ê¸¸ì´
        total_interview_length = sum(len(content) for content in interview_results.values())

        # ì—ì„¸ì´ ê²°ê³¼ ê¸¸ì´
        total_essay_length = sum(len(content) for content in essay_results.values())

        print(f"ì›ë³¸ í…ìŠ¤íŠ¸: {total_original_length}ì")
        print(f"ì¸í„°ë·° ê²°ê³¼: {total_interview_length}ì ({len(interview_results)}ê°œ)")
        print(f"ì—ì„¸ì´ ê²°ê³¼: {total_essay_length}ì ({len(essay_results)}ê°œ)")

class ContentCreatorV2Crew:
    """ContentCreatorV2ë¥¼ ìœ„í•œ Crew ê´€ë¦¬"""

    def __init__(self):
        self.content_creator = ContentCreatorV2Agent()

    def create_crew(self) -> Crew:
        """ContentCreatorV2 ì „ìš© Crew ìƒì„±"""
        return Crew(
            agents=[self.content_creator.create_agent()],
            verbose=True
        )

    def execute_content_creation(self, texts: List[str], image_analysis_results: List[Dict]) -> str:
        """Crewë¥¼ í†µí•œ ì½˜í…ì¸  ìƒì„± ì‹¤í–‰"""
        crew = self.create_crew()

        print("\n=== ContentCreatorV2 Crew ì‹¤í–‰ ===")
        print(f"- ì…ë ¥ í…ìŠ¤íŠ¸: {len(texts)}ê°œ")
        print(f"- ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼: {len(image_analysis_results)}ê°œ")

        # ContentCreatorV2Agentë¥¼ í†µí•œ ì½˜í…ì¸  ìƒì„±
        result = self.content_creator.create_magazine_content(texts, image_analysis_results)

        print("âœ… ContentCreatorV2 Crew ì‹¤í–‰ ì™„ë£Œ")
        return result
