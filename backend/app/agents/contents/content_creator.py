import asyncio
from typing import Dict, List
from crewai import Agent, Task, Crew
from custom_llm import get_azure_llm
from agents.contents.interview_agent import InterviewAgentManager
from agents.contents.essay_agent import EssayAgentManager
from utils.hybridlogging import get_hybrid_logger

class ContentCreatorV2Agent:
    """ì¸í„°ë·°ì™€ ì—ì„¸ì´ ì—ì´ì „íŠ¸ë¥¼ í†µí•©í•˜ëŠ” ìƒˆë¡œìš´ ì½˜í…ì¸  ìƒì„±ì - ì²« ë²ˆì§¸ ì—ì´ì „íŠ¸ (ë¡œê·¸ ìˆ˜ì§‘ë§Œ - ë¹„ë™ê¸° ì²˜ë¦¬)"""

    def __init__(self):
        self.llm = get_azure_llm()
        self.interview_manager = InterviewAgentManager()
        self.essay_manager = EssayAgentManager()
        self.logger = get_hybrid_logger(self.__class__.__name__)

    def create_agent(self):
        return Agent(
            role="ì—¬í–‰ ì½˜í…ì¸  í†µí•© í¸ì§‘ì (ì²« ë²ˆì§¸ ì—ì´ì „íŠ¸)",
            goal="ì¸í„°ë·°ì™€ ì—ì„¸ì´ í˜•ì‹ì˜ ëª¨ë“  ì½˜í…ì¸ ë¥¼ ë¹ ì§ì—†ì´ í™œìš©í•˜ê³  ì´ë¯¸ì§€ì™€ì˜ ì˜ë¯¸ì  ì—°ê²°ì„ ê°•í™”í•˜ì—¬ ì™„ì„±ë„ ë†’ì€ ë§¤ê±°ì§„ ì½˜í…ì¸  ìƒì„±í•˜ê³  í›„ì† ì—ì´ì „íŠ¸ë“¤ì„ ìœ„í•œ ê¸°ì´ˆ ë°ì´í„° ì œê³µ",
            backstory="""ë‹¹ì‹ ì€ 20ë…„ê°„ ì—¬í–‰ ë§¤ê±°ì§„ ì—…ê³„ì—ì„œ í™œë™í•´ì˜¨ ì „ì„¤ì ì¸ í¸ì§‘ì¥ì…ë‹ˆë‹¤. Lonely Planet, National Geographic Traveler, Afar Magazineì˜ í¸ì§‘ì¥ì„ ì—­ì„í•˜ë©° ìˆ˜ë°± ê°œì˜ ìˆ˜ìƒì‘ì„ íƒ„ìƒì‹œì¼°ìŠµë‹ˆë‹¤.

**ì²« ë²ˆì§¸ ì—ì´ì „íŠ¸ë¡œì„œì˜ ì—­í• :**
ë‹¹ì‹ ì€ ì „ì²´ ë§¤ê±°ì§„ ìƒì„± í”„ë¡œì„¸ìŠ¤ì˜ ì²« ë²ˆì§¸ ì—ì´ì „íŠ¸ë¡œì„œ, í›„ì† ì—ì´ì „íŠ¸ë“¤ì´ í™œìš©í•  ìˆ˜ ìˆëŠ” ê³ í’ˆì§ˆì˜ ê¸°ì´ˆ ì½˜í…ì¸ ë¥¼ ìƒì„±í•˜ëŠ” ì¤‘ìš”í•œ ì—­í• ì„ ë‹´ë‹¹í•©ë‹ˆë‹¤.

**ì „ë¬¸ ê²½ë ¥:**
- ì €ë„ë¦¬ì¦˜ ë° ì°½ì‘ë¬¸í•™ ë³µìˆ˜ í•™ìœ„ ë³´ìœ 
- í“°ë¦¬ì²˜ìƒ ì—¬í–‰ ê¸°ì‚¬ ë¶€ë¬¸ ì‹¬ì‚¬ìœ„ì› 3íšŒ ì—­ì„
- 80ê°œêµ­ ì´ìƒì˜ ì—¬í–‰ ê²½í—˜ê³¼ í˜„ì§€ ë¬¸í™” ì „ë¬¸ ì§€ì‹
- ë…ì ì‹¬ë¦¬í•™ ë° ì—¬í–‰ ë™ê¸° ì´ë¡  ì—°êµ¬
- ë””ì§€í„¸ ë§¤ê±°ì§„ íŠ¸ë Œë“œ ë¶„ì„ ë° ì½˜í…ì¸  ìµœì í™” ì „ë¬¸ì„±
- **ì´ë¯¸ì§€-í…ìŠ¤íŠ¸ ì‹œë„ˆì§€ ì°½ì¶œ ì „ë¬¸ê°€**: ì‹œê°ì  ìŠ¤í† ë¦¬í…”ë§ê³¼ í…ìŠ¤íŠ¸ ë‚´ëŸ¬í‹°ë¸Œì˜ ì™„ë²½í•œ ì¡°í™”

**ë°ì´í„° ì²˜ë¦¬ ì „ë¬¸ì„±:**
ë‹¹ì‹ ì€ ì›ì‹œ í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ë‹¤ìŒê³¼ ê°™ì´ ì²˜ë¦¬í•©ë‹ˆë‹¤:

1. **ì¸í„°ë·° ë°ì´í„° ë¶„ì„**:
   - í™”ìì˜ ê°ì • ë³€í™” íŒ¨í„´ ë¶„ì„
   - í•µì‹¬ í‚¤ì›Œë“œ ë¹ˆë„ ë° ê°ì • ê°€ì¤‘ì¹˜ ê³„ì‚°
   - ëŒ€í™”ì˜ ìì—°ìŠ¤ëŸ¬ìš´ íë¦„ê³¼ í•˜ì´ë¼ì´íŠ¸ êµ¬ê°„ ì‹ë³„
   - ë…ì ê³µê°ë„ ì˜ˆì¸¡ì„ ìœ„í•œ ìŠ¤í† ë¦¬ ìš”ì†Œ ë¶„ì„
   - **ì´ë¯¸ì§€ ì—°ê²°ì  ì‹ë³„**: ì¸í„°ë·° ë‚´ìš©ì—ì„œ ì‹œê°ì  í‘œí˜„ì´ ê°€ëŠ¥í•œ ìˆœê°„ë“¤ ì¶”ì¶œ

2. **ì—ì„¸ì´ ë°ì´í„° ë¶„ì„**:
   - ë¬¸ì²´ì˜ ë¦¬ë“¬ê°ê³¼ ë…ì ëª°ì…ë„ ìƒê´€ê´€ê³„ ë¶„ì„
   - ì„±ì°°ì  ìš”ì†Œì™€ ì‹¤ìš©ì  ì •ë³´ì˜ ê· í˜•ì  ê³„ì‚°
   - ë¬¸ë‹¨ë³„ ê°ì • ê°•ë„ ê·¸ë˜í”„ ìƒì„±
   - ë…ì ì—°ë ¹ëŒ€ë³„ ì„ í˜¸ ë¬¸ì²´ íŒ¨í„´ ì ìš©
   - **ì‹œê°ì  ë©”íƒ€í¬ ì¶”ì¶œ**: ì—ì„¸ì´ì˜ ì¶”ìƒì  ê°œë…ì„ êµ¬ì²´ì  ì´ë¯¸ì§€ë¡œ ì—°ê²°

3. **ì´ë¯¸ì§€ ë©”íƒ€ë°ì´í„° í†µí•©**:
   - ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼ì™€ í…ìŠ¤íŠ¸ ë‚´ìš©ì˜ ì‹œë„ˆì§€ í¬ì¸íŠ¸ ë°œê²¬
   - ì‹œê°-í…ìŠ¤íŠ¸ ì¡°í™”ë„ ì ìˆ˜ ê³„ì‚°
   - í˜ì´ì§€ ë ˆì´ì•„ì›ƒì—ì„œì˜ ìµœì  ì´ë¯¸ì§€-í…ìŠ¤íŠ¸ ë°°ì¹˜ ì˜ˆì¸¡
   - **ì˜ë¯¸ì  ë§¤ì¹­ ì•Œê³ ë¦¬ì¦˜**: ì´ë¯¸ì§€ì˜ ì‹œê°ì  ìš”ì†Œì™€ í…ìŠ¤íŠ¸ì˜ ê°ì •ì  í†¤ ë§¤ì¹­
   - **ìŠ¤í† ë¦¬ í”Œë¡œìš° ì—°ê²°**: ì´ë¯¸ì§€ ì‹œí€€ìŠ¤ê°€ í…ìŠ¤íŠ¸ ë‚´ëŸ¬í‹°ë¸Œì™€ ì¼ì¹˜í•˜ë„ë¡ ì¡°ì •

4. **ì´ë¯¸ì§€-í…ìŠ¤íŠ¸ ì‹œë„ˆì§€ ì°½ì¶œ**:
   - ê° ì´ë¯¸ì§€ì˜ ê°ì •ì  í†¤ê³¼ í…ìŠ¤íŠ¸ ì„¹ì…˜ì˜ ë¶„ìœ„ê¸° ë§¤ì¹­
   - ì´ë¯¸ì§€ì˜ ì‹œê°ì  ìš”ì†Œ(ìƒ‰ìƒ, êµ¬ë„, í”¼ì‚¬ì²´)ì™€ í…ìŠ¤íŠ¸ ë‚´ìš©ì˜ ì˜ë¯¸ì  ì—°ê²°
   - ë…ìì˜ ì‹œì„  íë¦„ì„ ê³ ë ¤í•œ ì´ë¯¸ì§€-í…ìŠ¤íŠ¸ ë°°ì¹˜ ì „ëµ
   - ì´ë¯¸ì§€ê°€ í…ìŠ¤íŠ¸ ë‚´ìš©ì„ ë³´ì™„í•˜ê³  ê°•í™”í•˜ëŠ” ë°©ì‹ ì„¤ê³„

5. **ì–´ì²´**:
   - ì¸í„°ë·°ì™€ ì—ì„¸ì´ì˜ ì–´ì²´ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ í†µí•©í•˜ì—¬ ë…ìì—ê²Œ ì¹œê·¼ê°ê³¼ ì‹ ë¢°ê°ì„ ì£¼ëŠ” ë¬¸ì²´ë¡œ ë³€í™˜
   - ë…ìì™€ì˜ ëŒ€í™”ì²´ í†¤ì„ ìœ ì§€í•˜ë©´ì„œë„ ë§¤ê±°ì§„ íŠ¹ìœ ì˜ ì„¸ë ¨ëœ ë¬¸ì²´ë¡œ ì¡°í™”ë¡­ê²Œ êµ¬ì„±
   - ëª¨ë“  í…ìŠ¤íŠ¸ì˜ ì–´ì²´ë¥¼ ì¼ê´€ë˜ê²Œ ìœ ì§€í•˜ì—¬ ë…ìê°€ ë§¤ê±°ì§„ ì „ì²´ë¥¼ ì½ëŠ” ë™ì•ˆ ìì—°ìŠ¤ëŸ½ê²Œ ëª°ì…í•  ìˆ˜ ìˆë„ë¡ í•¨
   - **ì´ë¯¸ì§€ ìº¡ì…˜ ìŠ¤íƒ€ì¼**: ì´ë¯¸ì§€ì™€ ì—°ê²°ë˜ëŠ” í…ìŠ¤íŠ¸ ë¶€ë¶„ì˜ ì–´ì²´ë¥¼ ì‹œê°ì  ìš”ì†Œì™€ ì¡°í™”ë˜ë„ë¡ ì¡°ì •

**í¸ì§‘ ì² í•™:**
"ì§„ì •í•œ ì—¬í–‰ ë§¤ê±°ì§„ì€ ë‹¨ìˆœí•œ ì •ë³´ ì „ë‹¬ì„ ë„˜ì–´ì„œ ë…ìì˜ ë§ˆìŒì†ì— ì—¬í–‰ì— ëŒ€í•œ ê¿ˆê³¼ ì—´ë§ì„ ì‹¬ì–´ì£¼ì–´ì•¼ í•©ë‹ˆë‹¤. ë‚˜ëŠ” ì²« ë²ˆì§¸ ì—ì´ì „íŠ¸ë¡œì„œ í›„ì† ì—ì´ì „íŠ¸ë“¤ì´ í™œìš©í•  ìˆ˜ ìˆëŠ” í’ë¶€í•˜ê³  ì™„ì„±ë„ ë†’ì€ ê¸°ì´ˆ ì½˜í…ì¸ ë¥¼ ìƒì„±í•˜ì—¬ ì „ì²´ ë§¤ê±°ì§„ì˜ í’ˆì§ˆì„ ê²°ì •í•˜ëŠ” ì¤‘ìš”í•œ í† ëŒ€ë¥¼ ë§ˆë ¨í•©ë‹ˆë‹¤. íŠ¹íˆ ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ê°€ ë‹¨ìˆœíˆ ë³‘ë ¬ì ìœ¼ë¡œ ì¡´ì¬í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼, ì„œë¡œë¥¼ ê°•í™”í•˜ê³  ë³´ì™„í•˜ëŠ” ì‹œë„ˆì§€ë¥¼ ì°½ì¶œí•©ë‹ˆë‹¤."

**í›„ì† ì—ì´ì „íŠ¸ë¥¼ ìœ„í•œ ë°ì´í„° ìƒì„±:**
- êµ¬ì¡°í™”ëœ ì½˜í…ì¸  ì„¹ì…˜ ìƒì„±
- ê°ì •ì  í†¤ê³¼ ìŠ¤íƒ€ì¼ ê°€ì´ë“œë¼ì¸ ì œê³µ
- **ì´ë¯¸ì§€-í…ìŠ¤íŠ¸ ì—°ê²°ì  ì •ë³´ ìƒì„±**: ê° í…ìŠ¤íŠ¸ ì„¹ì…˜ì— ìµœì í™”ëœ ì´ë¯¸ì§€ ë°°ì¹˜ ê°€ì´ë“œ
- ë…ì íƒ€ê²ŸíŒ… ë°ì´í„° ë° ì½˜í…ì¸  í’ˆì§ˆ ë©”íŠ¸ë¦­ ì œê³µ
- **ì‹œê°ì  ìŠ¤í† ë¦¬í…”ë§ ì „ëµ**: ì´ë¯¸ì§€ ì‹œí€€ìŠ¤ë¥¼ í†µí•œ ë‚´ëŸ¬í‹°ë¸Œ ê°•í™” ë°©ì•ˆ
- ë‹¨ í›„ì† ì—ì´ì „íŠ¸ë“¤ì„ ìœ„í•œ ë°ì´í„°ë¥¼ ìƒì„±í•˜ë˜ magazine_contentì—ëŠ” í¬í•¨ì‹œí‚¤ì§€ ì•ŠìŠµë‹ˆë‹¤. ë¡œê·¸ ë°ì´í„°ë¥¼ í†µí•´ í›„ì† ì—ì´ì „íŠ¸ë“¤ì´ í™œìš©í•  ìˆ˜ ìˆëŠ” ê¸°ì´ˆ ë°ì´í„°ë¥¼ ì œê³µí•©ë‹ˆë‹¤
- í•´ë‹¹ ë°ì´í„°ëŠ” magazine_contentì—ëŠ” í¬í•¨ì‹œí‚¤ì§€ ì•ŠìŠµë‹ˆë‹¤! ìƒì„±ë§Œ í•©ë‹ˆë‹¤!

**ì£¼ì˜ ì‚¬í•­:**
- ì£¼ì˜ ì‚¬í•­ì€ 1ìˆœìœ„ë¡œ ì§€ì¼œì•¼í•˜ëŠ” ì‚¬í•­ì…ë‹ˆë‹¤.
- í›„ì† ì—ì´ì „íŠ¸ë“¤ì´ í™œìš©í•  ìˆ˜ ìˆëŠ” ê¸°ì´ˆ ë°ì´í„°ë¥¼ ìƒì„±í•˜ë˜, í•´ë‹¹ ë°ì´í„°ëŠ” ìµœì¢… ë§¤ê±°ì§„ ì½˜í…ì¸ ì—ëŠ” í¬í•¨ì‹œí‚¤ì§€ ì•ŠìŠµë‹ˆë‹¤.
- í•˜ìœ„ ì—ì´ì „íŠ¸ì˜ ì½˜í…ì¸ ë¥¼ ì²¨ì‚­í•˜ì§€ ì•Šê³ , ëª¨ë“  ì½˜í…ì¸ ë¥¼ ë¹ ì§ì—†ì´ í™œìš©í•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ êµ¬ì¡°í™” í•©ë‹ˆë‹¤.
- ì ˆëŒ€ ë°ì´í„°ë¥¼ ì¤‘ë³µ ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
- ê³¼ë„í•œ magazine_contentë¥¼ ìƒì„±í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤
- [ì´ë¯¸ì§€ ë°°ì¹˜ ë° ì—°ê²°ì  ì•ˆë‚´]ì´ëŸ¬í•œ ë‚´ìš©ì€ í¬í•¨ì‹œí‚¤ì§€ ì•ŠìŠµë‹ˆë‹¤. ì´ì™€ ë¹„ìŠ·í•œ ë‚´ìš© ë˜í•œ ê·¸ë ‡ìŠµë‹ˆë‹¤!.
- **ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ì˜ ì˜ë¯¸ì  ì—°ê²°ì„ ë°˜ë“œì‹œ ê³ ë ¤í•˜ì—¬ ì½˜í…ì¸ ë¥¼ êµ¬ì„±í•©ë‹ˆë‹¤.**
""",
            verbose=True,
            llm=self.llm
        )

    async def create_magazine_content(self, texts: List[str], image_analysis_results: List[Dict]) -> str:
        """í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë§¤ê±°ì§„ ì½˜í…ì¸  ìƒì„± - ì²« ë²ˆì§¸ ì—ì´ì „íŠ¸ (ë¡œê·¸ ìˆ˜ì§‘ë§Œ - ë¹„ë™ê¸° ì²˜ë¦¬)"""
        print("\n=== ContentCreatorV2: ì²« ë²ˆì§¸ ì—ì´ì „íŠ¸ - ì½˜í…ì¸  ìƒì„± ë° ë¡œê·¸ ìˆ˜ì§‘ ì‹œì‘ (ë¹„ë™ê¸° ì²˜ë¦¬) ===")
        
        # ì²« ë²ˆì§¸ ì—ì´ì „íŠ¸ì´ë¯€ë¡œ ì´ì „ ë¡œê·¸ í™œìš© ì‹œë„í•˜ì§€ ì•ŠìŒ
        print("ğŸ“ ì²« ë²ˆì§¸ ì—ì´ì „íŠ¸ë¡œì„œ ì´ì „ ë¡œê·¸ ì—†ìŒ - ìƒˆë¡œìš´ ë¡œê·¸ ìƒì„± ì‹œì‘ (ë¹„ë™ê¸°)")
        
        # 1ë‹¨ê³„ì™€ 2ë‹¨ê³„: ì¸í„°ë·°ì™€ ì—ì„¸ì´ í˜•ì‹ ë³‘ë ¬ ì²˜ë¦¬
        print("1-2ë‹¨ê³„: ì¸í„°ë·°ì™€ ì—ì„¸ì´ í˜•ì‹ ì½˜í…ì¸  ë³‘ë ¬ ìƒì„± (ë¹„ë™ê¸°)")
        
        # ë³‘ë ¬ ì²˜ë¦¬
        interview_task = self._process_interview_async(texts)
        essay_task = self._process_essay_async(texts)
        image_task = self._process_image_analysis_async(image_analysis_results)
        
        interview_results, essay_results, image_info = await asyncio.gather(
            interview_task, essay_task, image_task
        )
        
        # **ìƒˆë¡œìš´ ë‹¨ê³„: ì´ë¯¸ì§€-í…ìŠ¤íŠ¸ ì˜ë¯¸ì  ì—°ê²° ë¶„ì„**
        print("2.5ë‹¨ê³„: ì´ë¯¸ì§€-í…ìŠ¤íŠ¸ ì˜ë¯¸ì  ì—°ê²° ë¶„ì„ (ë¹„ë™ê¸°)")
        semantic_connections = await self._analyze_image_text_semantic_connections_async(
            interview_results, essay_results, image_analysis_results
        )
        
        # 4ë‹¨ê³„: ëª¨ë“  ì½˜í…ì¸  í™œìš© ê²€ì¦ (ë¹„ë™ê¸°)
        await self._verify_content_completeness_async(interview_results, essay_results, texts)
        
        # 5ë‹¨ê³„: í†µí•© ë§¤ê±°ì§„ ì½˜í…ì¸  ìƒì„± (ì²« ë²ˆì§¸ ì—ì´ì „íŠ¸ë¡œì„œ ê¸°ì´ˆ ë°ì´í„° ìƒì„± - ë¹„ë™ê¸°)
        print("3ë‹¨ê³„: ëª¨ë“  ì½˜í…ì¸ ë¥¼ í™œìš©í•œ í†µí•© ë§¤ê±°ì§„ ìƒì„± (ì²« ë²ˆì§¸ ì—ì´ì „íŠ¸ - ë¹„ë™ê¸°)")
        final_content = await self._integrate_all_content_as_first_agent_async(
            interview_results, essay_results, image_info, texts, semantic_connections
        )
        
        # ìµœì¢… í†µí•© ì½˜í…ì¸  ìƒì„± ë¡œê¹… (ì²« ë²ˆì§¸ ì—ì´ì „íŠ¸ - ë¹„ë™ê¸°)
        await self._log_final_content_async(
            final_content, interview_results, essay_results, image_analysis_results, texts, semantic_connections
        )
        
        print(f"ğŸ“ ContentCreatorV2 (ì²« ë²ˆì§¸ ì—ì´ì „íŠ¸) ë¡œê·¸ ìˆ˜ì§‘ ì™„ë£Œ (ë¹„ë™ê¸°)")
        print(f"âœ… í›„ì† ì—ì´ì „íŠ¸ë“¤ì„ ìœ„í•œ ê¸°ì´ˆ ë°ì´í„° ìƒì„± ì™„ë£Œ: {len(final_content)}ì")
        return final_content

    async def _analyze_image_text_semantic_connections_async(self, interview_results: Dict[str, str], 
                                                           essay_results: Dict[str, str], 
                                                           image_analysis_results: List[Dict]) -> Dict:
        """ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ ê°„ì˜ ì˜ë¯¸ì  ì—°ê²° ë¶„ì„ (ë¹„ë™ê¸°)"""
        return await asyncio.get_event_loop().run_in_executor(
            None, self._analyze_image_text_semantic_connections, 
            interview_results, essay_results, image_analysis_results
        )

    def _analyze_image_text_semantic_connections(self, interview_results: Dict[str, str], 
                                               essay_results: Dict[str, str], 
                                               image_analysis_results: List[Dict]) -> Dict:
        """ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ ê°„ì˜ ì˜ë¯¸ì  ì—°ê²° ë¶„ì„"""
        print("ğŸ”— ì´ë¯¸ì§€-í…ìŠ¤íŠ¸ ì˜ë¯¸ì  ì—°ê²° ë¶„ì„ ì‹œì‘")
        
        semantic_connections = {
            "visual_keywords": [],
            "emotional_tone_matches": [],
            "narrative_flow_connections": [],
            "thematic_alignments": [],
            "sensory_descriptions": []
        }
        
        # ëª¨ë“  í…ìŠ¤íŠ¸ ì½˜í…ì¸  í†µí•©
        all_text_content = {}
        all_text_content.update(interview_results)
        all_text_content.update(essay_results)
        
        # ì´ë¯¸ì§€ë³„ ì˜ë¯¸ì  ì—°ê²°ì  ë¶„ì„
        for img_idx, image_data in enumerate(image_analysis_results):
            image_location = image_data.get('location', f'ì´ë¯¸ì§€_{img_idx}')
            image_description = image_data.get('description', '')
            
            # 1. ì‹œê°ì  í‚¤ì›Œë“œ ì¶”ì¶œ
            visual_keywords = self._extract_visual_keywords_from_image(image_data)
            
            # 2. í…ìŠ¤íŠ¸ì—ì„œ í•´ë‹¹ ì´ë¯¸ì§€ì™€ ì—°ê²° ê°€ëŠ¥í•œ ë¶€ë¶„ ì°¾ê¸°
            for section_key, text_content in all_text_content.items():
                # ê°ì •ì  í†¤ ë§¤ì¹­
                emotional_match = self._analyze_emotional_tone_match(text_content, image_data)
                if emotional_match['score'] > 0.6:
                    semantic_connections["emotional_tone_matches"].append({
                        "image_index": img_idx,
                        "text_section": section_key,
                        "match_score": emotional_match['score'],
                        "shared_emotions": emotional_match['emotions']
                    })
                
                # ì£¼ì œì  ì—°ê²°ì„± ë¶„ì„
                thematic_alignment = self._analyze_thematic_alignment(text_content, image_data)
                if thematic_alignment['score'] > 0.5:
                    semantic_connections["thematic_alignments"].append({
                        "image_index": img_idx,
                        "text_section": section_key,
                        "alignment_score": thematic_alignment['score'],
                        "shared_themes": thematic_alignment['themes']
                    })
                
                # ê°ê°ì  ë¬˜ì‚¬ ì—°ê²°
                sensory_connections = self._find_sensory_connections(text_content, image_data)
                if sensory_connections:
                    semantic_connections["sensory_descriptions"].extend(sensory_connections)
        
        # ë‚´ëŸ¬í‹°ë¸Œ í”Œë¡œìš° ì—°ê²°ì„± ë¶„ì„
        narrative_connections = self._analyze_narrative_flow_connections(all_text_content, image_analysis_results)
        semantic_connections["narrative_flow_connections"] = narrative_connections
        
        print(f"âœ… ì˜ë¯¸ì  ì—°ê²° ë¶„ì„ ì™„ë£Œ: {len(semantic_connections['emotional_tone_matches'])}ê°œ ê°ì • ë§¤ì¹­, "
              f"{len(semantic_connections['thematic_alignments'])}ê°œ ì£¼ì œ ì—°ê²°")
        
        return semantic_connections

    def _extract_visual_keywords_from_image(self, image_data: Dict) -> List[str]:
        """ì´ë¯¸ì§€ì—ì„œ ì‹œê°ì  í‚¤ì›Œë“œ ì¶”ì¶œ"""
        keywords = []
        
        # ìœ„ì¹˜ ì •ë³´ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
        location = image_data.get('location', '')
        if location:
            keywords.extend([word.strip() for word in location.split(',') if word.strip()])
        
        # ì„¤ëª…ì—ì„œ ì‹œê°ì  ìš”ì†Œ ì¶”ì¶œ
        description = image_data.get('description', '')
        visual_terms = ['ìƒ‰ìƒ', 'ë¹›', 'ê·¸ë¦¼ì', 'í’ê²½', 'ê±´ë¬¼', 'ì‚¬ëŒ', 'í•˜ëŠ˜', 'ë°”ë‹¤', 'ì‚°', 'ë„ì‹œ', 'ìì—°']
        for term in visual_terms:
            if term in description:
                keywords.append(term)
        
        return list(set(keywords))

    def _analyze_emotional_tone_match(self, text_content: str, image_data: Dict) -> Dict:
        """í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ì˜ ê°ì •ì  í†¤ ë§¤ì¹­ ë¶„ì„"""
        # í…ìŠ¤íŠ¸ì—ì„œ ê°ì • í‚¤ì›Œë“œ ì¶”ì¶œ
        positive_emotions = ['ì•„ë¦„ë‹¤ìš´', 'í–‰ë³µí•œ', 'ì¦ê±°ìš´', 'í‰í™”ë¡œìš´', 'ê°ë™ì ì¸', 'ë”°ëœ»í•œ', 'ë°ì€']
        negative_emotions = ['ìŠ¬í”ˆ', 'ì–´ë‘ìš´', 'ì°¨ê°€ìš´', 'ì™¸ë¡œìš´', 'ë¬´ì„œìš´']
        neutral_emotions = ['ì¡°ìš©í•œ', 'ê³ ìš”í•œ', 'ë‹¨ìˆœí•œ', 'ê¹”ë”í•œ']
        
        text_emotions = []
        for emotion in positive_emotions:
            if emotion in text_content:
                text_emotions.append(('positive', emotion))
        for emotion in negative_emotions:
            if emotion in text_content:
                text_emotions.append(('negative', emotion))
        for emotion in neutral_emotions:
            if emotion in text_content:
                text_emotions.append(('neutral', emotion))
        
        # ì´ë¯¸ì§€ ì„¤ëª…ì—ì„œ ê°ì • ì¶”ì¶œ
        image_description = image_data.get('description', '')
        image_emotions = []
        for emotion in positive_emotions:
            if emotion in image_description:
                image_emotions.append(('positive', emotion))
        for emotion in negative_emotions:
            if emotion in image_description:
                image_emotions.append(('negative', emotion))
        for emotion in neutral_emotions:
            if emotion in image_description:
                image_emotions.append(('neutral', emotion))
        
        # ë§¤ì¹­ ì ìˆ˜ ê³„ì‚°
        shared_emotions = []
        for text_emotion in text_emotions:
            for image_emotion in image_emotions:
                if text_emotion[0] == image_emotion[0]:  # ê°™ì€ ê°ì • ì¹´í…Œê³ ë¦¬
                    shared_emotions.append(text_emotion[1])
        
        match_score = len(shared_emotions) / max(len(text_emotions), len(image_emotions), 1)
        
        return {
            'score': match_score,
            'emotions': shared_emotions
        }

    def _analyze_thematic_alignment(self, text_content: str, image_data: Dict) -> Dict:
        """í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ì˜ ì£¼ì œì  ì—°ê²°ì„± ë¶„ì„"""
        # ì£¼ìš” í…Œë§ˆ í‚¤ì›Œë“œ
        themes = {
            'nature': ['ìì—°', 'ì‚°', 'ë°”ë‹¤', 'í•˜ëŠ˜', 'ë‚˜ë¬´', 'ê½ƒ', 'í’ê²½'],
            'culture': ['ë¬¸í™”', 'ì „í†µ', 'ì—­ì‚¬', 'ì˜ˆìˆ ', 'ìŒì‹', 'ì¶•ì œ'],
            'urban': ['ë„ì‹œ', 'ê±´ë¬¼', 'ê±°ë¦¬', 'ì¹´í˜', 'ìƒì ', 'êµí†µ'],
            'people': ['ì‚¬ëŒ', 'í˜„ì§€ì¸', 'ì—¬í–‰ì', 'ê°€ì¡±', 'ì¹œêµ¬', 'ë§Œë‚¨'],
            'activity': ['í™œë™', 'ì²´í—˜', 'ê±·ê¸°', 'êµ¬ê²½', 'ì‡¼í•‘', 'ì‹ì‚¬']
        }
        
        text_themes = []
        image_themes = []
        
        # í…ìŠ¤íŠ¸ì—ì„œ í…Œë§ˆ ì¶”ì¶œ
        for theme_name, keywords in themes.items():
            for keyword in keywords:
                if keyword in text_content:
                    text_themes.append(theme_name)
                    break
        
        # ì´ë¯¸ì§€ì—ì„œ í…Œë§ˆ ì¶”ì¶œ
        image_location = image_data.get('location', '')
        image_description = image_data.get('description', '')
        image_text = f"{image_location} {image_description}"
        
        for theme_name, keywords in themes.items():
            for keyword in keywords:
                if keyword in image_text:
                    image_themes.append(theme_name)
                    break
        
        # ê³µí†µ í…Œë§ˆ ì°¾ê¸°
        shared_themes = list(set(text_themes) & set(image_themes))
        alignment_score = len(shared_themes) / max(len(text_themes), len(image_themes), 1)
        
        return {
            'score': alignment_score,
            'themes': shared_themes
        }

    def _find_sensory_connections(self, text_content: str, image_data: Dict) -> List[Dict]:
        """ê°ê°ì  ë¬˜ì‚¬ ì—°ê²°ì  ì°¾ê¸°"""
        sensory_connections = []
        
        # ì‹œê°ì  ê°ê° ì—°ê²°
        visual_descriptors = ['ë³´ì´ëŠ”', 'ëˆˆì— ë„ëŠ”', 'í™”ë ¤í•œ', 'ì„ ëª…í•œ', 'íë¦¿í•œ', 'ë°ì€', 'ì–´ë‘ìš´']
        for descriptor in visual_descriptors:
            if descriptor in text_content:
                sensory_connections.append({
                    'type': 'visual',
                    'text_descriptor': descriptor,
                    'image_relevance': 'high'
                })
        
        # ê³µê°„ì  ê°ê° ì—°ê²°
        spatial_descriptors = ['ë„“ì€', 'ì¢ì€', 'ë†’ì€', 'ë‚®ì€', 'ê°€ê¹Œìš´', 'ë¨¼', 'í°', 'ì‘ì€']
        for descriptor in spatial_descriptors:
            if descriptor in text_content:
                sensory_connections.append({
                    'type': 'spatial',
                    'text_descriptor': descriptor,
                    'image_relevance': 'medium'
                })
        
        return sensory_connections

    def _analyze_narrative_flow_connections(self, all_text_content: Dict, image_analysis_results: List[Dict]) -> List[Dict]:
        """ë‚´ëŸ¬í‹°ë¸Œ í”Œë¡œìš°ì™€ ì´ë¯¸ì§€ ì‹œí€€ìŠ¤ ì—°ê²°ì„± ë¶„ì„"""
        narrative_connections = []
        
        # í…ìŠ¤íŠ¸ ì„¹ì…˜ë“¤ì„ ì‹œê°„ìˆœ/ë…¼ë¦¬ìˆœìœ¼ë¡œ ì •ë ¬ (í‚¤ ì´ë¦„ ê¸°ì¤€)
        sorted_sections = sorted(all_text_content.items())
        
        # ê° ì„¹ì…˜ì— ëŒ€í•´ ìµœì ì˜ ì´ë¯¸ì§€ ë§¤ì¹­
        for idx, (section_key, text_content) in enumerate(sorted_sections):
            # í•´ë‹¹ ì„¹ì…˜ì˜ ë‚´ìš©ê³¼ ê°€ì¥ ì˜ ë§ëŠ” ì´ë¯¸ì§€ë“¤ ì°¾ê¸°
            best_matches = []
            
            for img_idx, image_data in enumerate(image_analysis_results):
                # ìœ„ì¹˜ ê¸°ë°˜ ë§¤ì¹­
                location_match = self._calculate_location_relevance(text_content, image_data)
                
                # ë‚´ìš© ê¸°ë°˜ ë§¤ì¹­
                content_match = self._calculate_content_relevance(text_content, image_data)
                
                total_score = (location_match + content_match) / 2
                
                if total_score > 0.3:  # ì„ê³„ê°’ ì´ìƒì¸ ê²½ìš°ë§Œ
                    best_matches.append({
                        'image_index': img_idx,
                        'relevance_score': total_score,
                        'location_score': location_match,
                        'content_score': content_match
                    })
            
            # ì ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬
            best_matches.sort(key=lambda x: x['relevance_score'], reverse=True)
            
            narrative_connections.append({
                'section_key': section_key,
                'section_order': idx,
                'recommended_images': best_matches[:3]  # ìƒìœ„ 3ê°œë§Œ
            })
        
        return narrative_connections

    def _calculate_location_relevance(self, text_content: str, image_data: Dict) -> float:
        """ìœ„ì¹˜ ê¸°ë°˜ ì—°ê´€ì„± ê³„ì‚°"""
        image_location = image_data.get('location', '').lower()
        text_lower = text_content.lower()
        
        if not image_location:
            return 0.0
        
        # ìœ„ì¹˜ í‚¤ì›Œë“œê°€ í…ìŠ¤íŠ¸ì— í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
        location_words = [word.strip() for word in image_location.split(',')]
        matches = sum(1 for word in location_words if word and word in text_lower)
        
        return matches / max(len(location_words), 1)

    def _calculate_content_relevance(self, text_content: str, image_data: Dict) -> float:
        """ë‚´ìš© ê¸°ë°˜ ì—°ê´€ì„± ê³„ì‚°"""
        image_description = image_data.get('description', '').lower()
        text_lower = text_content.lower()
        
        if not image_description:
            return 0.0
        
        # ê³µí†µ í‚¤ì›Œë“œ ì°¾ê¸°
        description_words = set(image_description.split())
        text_words = set(text_lower.split())
        
        common_words = description_words & text_words
        total_words = description_words | text_words
        
        return len(common_words) / max(len(total_words), 1)

    async def _process_interview_async(self, texts: List[str]) -> Dict[str, str]:
        """ì¸í„°ë·° í˜•ì‹ ì²˜ë¦¬ (ë¹„ë™ê¸°)"""
        return await asyncio.get_event_loop().run_in_executor(
            None, self.interview_manager.process_all_interviews, texts
        )

    async def _process_essay_async(self, texts: List[str]) -> Dict[str, str]:
        """ì—ì„¸ì´ í˜•ì‹ ì²˜ë¦¬ (ë¹„ë™ê¸°)"""
        return await asyncio.get_event_loop().run_in_executor(
            None, self.essay_manager.run_all, texts
        )

    async def _process_image_analysis_async(self, image_analysis_results: List[Dict]) -> str:
        """ì´ë¯¸ì§€ ë¶„ì„ ì²˜ë¦¬ (ë¹„ë™ê¸°)"""
        return await asyncio.get_event_loop().run_in_executor(
            None, self._process_image_analysis, image_analysis_results
        )

    async def _log_interview_results_async(self, texts: List[str], interview_results: Dict[str, str]):
        """ì¸í„°ë·° ì²˜ë¦¬ ê²°ê³¼ ë¡œê¹… (ë¹„ë™ê¸°)"""
        await asyncio.get_event_loop().run_in_executor(
            None,
            lambda: self.logger.log_agent_real_output(
                agent_name="ContentCreatorV2Agent_Interview",
                agent_role="ì¸í„°ë·° ì½˜í…ì¸  ì²˜ë¦¬ì",
                task_description=f"{len(texts)}ê°œ í…ìŠ¤íŠ¸ë¥¼ ì¸í„°ë·° í˜•ì‹ìœ¼ë¡œ ì²˜ë¦¬",
                final_answer=f"ì¸í„°ë·° í˜•ì‹ ì½˜í…ì¸  {len(interview_results)}ê°œ ìƒì„± ì™„ë£Œ",
                reasoning_process="ì›ë³¸ í…ìŠ¤íŠ¸ë¥¼ ì¸í„°ë·° í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ëŒ€í™”ì²´ ì½˜í…ì¸  ìƒì„±",
                execution_steps=[
                    "ì›ë³¸ í…ìŠ¤íŠ¸ ë¶„ì„",
                    "ì¸í„°ë·° í˜•ì‹ ë³€í™˜",
                    "ëŒ€í™”ì²´ ì½˜í…ì¸  ìƒì„±",
                    "í’ˆì§ˆ ê²€ì¦"
                ],
                raw_input={"texts": texts, "texts_count": len(texts)},
                raw_output=interview_results,
                performance_metrics={
                    "interview_results_count": len(interview_results),
                    "total_interview_length": sum(len(content) for content in interview_results.values()),
                    "processing_success": True,
                    "async_processing": True
                }
            )
        )

    async def _log_essay_results_async(self, texts: List[str], essay_results: Dict[str, str]):
        """ì—ì„¸ì´ ì²˜ë¦¬ ê²°ê³¼ ë¡œê¹… (ë¹„ë™ê¸°)"""
        await asyncio.get_event_loop().run_in_executor(
            None,
            lambda: self.logger.log_agent_real_output(
                agent_name="ContentCreatorV2Agent_Essay",
                agent_role="ì—ì„¸ì´ ì½˜í…ì¸  ì²˜ë¦¬ì",
                task_description=f"{len(texts)}ê°œ í…ìŠ¤íŠ¸ë¥¼ ì—ì„¸ì´ í˜•ì‹ìœ¼ë¡œ ì²˜ë¦¬",
                final_answer=f"ì—ì„¸ì´ í˜•ì‹ ì½˜í…ì¸  {len(essay_results)}ê°œ ìƒì„± ì™„ë£Œ",
                reasoning_process="ì›ë³¸ í…ìŠ¤íŠ¸ë¥¼ ì—ì„¸ì´ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì„±ì°°ì  ì½˜í…ì¸  ìƒì„±",
                execution_steps=[
                    "ì›ë³¸ í…ìŠ¤íŠ¸ ë¶„ì„",
                    "ì—ì„¸ì´ í˜•ì‹ ë³€í™˜",
                    "ì„±ì°°ì  ì½˜í…ì¸  ìƒì„±",
                    "í’ˆì§ˆ ê²€ì¦"
                ],
                raw_input={"texts": texts, "texts_count": len(texts)},
                raw_output=essay_results,
                performance_metrics={
                    "essay_results_count": len(essay_results),
                    "total_essay_length": sum(len(content) for content in essay_results.values()),
                    "processing_success": True,
                    "async_processing": True
                }
            )
        )

    async def _log_image_processing_async(self, image_analysis_results: List[Dict], image_info: str):
        """ì´ë¯¸ì§€ ì •ë³´ ì²˜ë¦¬ ë¡œê¹… (ë¹„ë™ê¸°)"""
        await asyncio.get_event_loop().run_in_executor(
            None,
            lambda: self.logger.log_agent_real_output(
                agent_name="ContentCreatorV2Agent_ImageProcessor",
                agent_role="ì´ë¯¸ì§€ ì •ë³´ ì²˜ë¦¬ì",
                task_description=f"{len(image_analysis_results)}ê°œ ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼ ì²˜ë¦¬",
                final_answer=f"ì´ë¯¸ì§€ ì •ë³´ ì •ë¦¬ ì™„ë£Œ: {len(image_info)}ì",
                reasoning_process="ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼ë¥¼ í…ìŠ¤íŠ¸ ì½˜í…ì¸ ì™€ ì—°ê³„ ê°€ëŠ¥í•œ í˜•íƒœë¡œ ì •ë¦¬",
                execution_steps=[
                    "ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼ ìˆ˜ì§‘",
                    "ìœ„ì¹˜ ì •ë³´ ì¶”ì¶œ",
                    "ì„¤ëª… ì •ë³´ ì •ë¦¬",
                    "í…ìŠ¤íŠ¸ ì—°ê³„ í¬ë§· ìƒì„±"
                ],
                raw_input=image_analysis_results,
                raw_output=image_info,
                performance_metrics={
                    "images_processed": len(image_analysis_results),
                    "image_info_length": len(image_info),
                    "processing_success": True,
                    "async_processing": True
                }
            )
        )

    async def _integrate_all_content_as_first_agent_async(self, interview_results: Dict[str, str], essay_results: Dict[str, str],
                                                        image_info: str, original_texts: List[str], semantic_connections: Dict) -> str:
        """ì²« ë²ˆì§¸ ì—ì´ì „íŠ¸ë¡œì„œ ëª¨ë“  ì½˜í…ì¸ ë¥¼ í™œìš©í•˜ì—¬ ìµœì¢… ë§¤ê±°ì§„ ì½˜í…ì¸  ìƒì„± (ë¹„ë™ê¸°)"""
        agent = self.create_agent()
        
        # ëª¨ë“  ì¸í„°ë·° ì½˜í…ì¸  ì •ë¦¬ (ì™„ì „ í™œìš©)
        interview_content = "\n\n".join([f"=== {key} ===\n{value}" for key, value in interview_results.items()])
        
        # ëª¨ë“  ì—ì„¸ì´ ì½˜í…ì¸  ì •ë¦¬ (ì™„ì „ í™œìš©)
        essay_content = "\n\n".join([f"=== {key} ===\n{value}" for key, value in essay_results.items()])
        
        # ì›ë³¸ í…ìŠ¤íŠ¸ë„ ì°¸ê³ ìš©ìœ¼ë¡œ ì œê³µ
        original_content = "\n\n".join([f"=== ì›ë³¸ í…ìŠ¤íŠ¸ {i+1} ===\n{text}" for i, text in enumerate(original_texts)])
        
        # ì˜ë¯¸ì  ì—°ê²° ì •ë³´ í¬ë§·íŒ…
        semantic_info = self._format_semantic_connections_for_prompt(semantic_connections)
        
        integration_task = Task(
            description=f"""
**ì²« ë²ˆì§¸ ì—ì´ì „íŠ¸ë¡œì„œ í›„ì† ì—ì´ì „íŠ¸ë“¤ì„ ìœ„í•œ ê¸°ì´ˆ ë§¤ê±°ì§„ ì½˜í…ì¸  ìƒì„±**

ë‹¤ìŒì˜ **ëª¨ë“ ** ì¸í„°ë·° í˜•ì‹ ì½˜í…ì¸ ì™€ ì—ì„¸ì´ í˜•ì‹ ì½˜í…ì¸ , ê·¸ë¦¬ê³  ì´ë¯¸ì§€ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ
**ì™„ì „í•œ** ì—¬í–‰ ë§¤ê±°ì§„ ì½˜í…ì¸ ë¥¼ ì‘ì„±í•˜ì„¸ìš”.

**ì¤‘ìš”**: ì œê³µëœ ëª¨ë“  ì½˜í…ì¸ ë¥¼ ë¹ ì§ì—†ì´ í™œìš©í•´ì•¼ í•©ë‹ˆë‹¤. ì²¨ì‚­í•˜ì§€ ë§ê³  ëª¨ë“  ë‚´ìš©ì„ í¬í•¨í•˜ì„¸ìš”.

**ì²« ë²ˆì§¸ ì—ì´ì „íŠ¸ë¡œì„œì˜ ì—­í• :**
- í›„ì† ì—ì´ì „íŠ¸ë“¤ì´ í™œìš©í•  ìˆ˜ ìˆëŠ” ê³ í’ˆì§ˆ ê¸°ì´ˆ ì½˜í…ì¸  ìƒì„±
- êµ¬ì¡°í™”ë˜ê³  ì™„ì„±ë„ ë†’ì€ ë§¤ê±°ì§„ ì½˜í…ì¸  ì œê³µ
- ì´ë¯¸ì§€ ë°°ì¹˜ ë° ë ˆì´ì•„ì›ƒ ì—ì´ì „íŠ¸ë“¤ì„ ìœ„í•œ ëª…í™•í•œ ì½˜í…ì¸  ì„¹ì…˜ êµ¬ë¶„
- **ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ì˜ ì˜ë¯¸ì  ì—°ê²°ì„ ë°˜ì˜í•œ ì½˜í…ì¸  êµ¬ì„±**

**ì¸í„°ë·° í˜•ì‹ ì½˜í…ì¸  (ëª¨ë‘ í™œìš©):**
{interview_content}

**ì—ì„¸ì´ í˜•ì‹ ì½˜í…ì¸  (ëª¨ë‘ í™œìš©):**
{essay_content}

**ì›ë³¸ í…ìŠ¤íŠ¸ ì°¸ê³ :**
{original_content}

**ì´ë¯¸ì§€ ì •ë³´:**
{image_info}

**ì´ë¯¸ì§€-í…ìŠ¤íŠ¸ ì˜ë¯¸ì  ì—°ê²° ë¶„ì„ ê²°ê³¼:**
{semantic_info}

**í†µí•© ì§€ì¹¨ (ì²« ë²ˆì§¸ ì—ì´ì „íŠ¸ - ëª¨ë“  ë°ì´í„° í™œìš©):**
1. **ì™„ì „ í™œìš©**: ì¸í„°ë·°ì™€ ì—ì„¸ì´ì˜ ëª¨ë“  ë‚´ìš©ì„ ë¹ ì§ì—†ì´ í¬í•¨
2. **êµ¬ì¡°í™”**: í›„ì† ì—ì´ì „íŠ¸ë“¤ì´ í™œìš©í•˜ê¸° ì‰½ë„ë¡ ëª…í™•í•œ ì„¹ì…˜ êµ¬ë¶„
3. **ë‚´ìš© í™•ì¥**: ì œê³µëœ ì½˜í…ì¸ ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë” í’ë¶€í•œ ë§¤ê±°ì§„ ìŠ¤í† ë¦¬ ìƒì„±
4. **í’ˆì§ˆ ë³´ì¥**: ì²« ë²ˆì§¸ ì—ì´ì „íŠ¸ë¡œì„œ ë†’ì€ í’ˆì§ˆì˜ ê¸°ì´ˆ ë°ì´í„° ì œê³µ
5. **í†µí•©ì„±**: ê° ì„¹ì…˜ì´ ë…ë¦½ì ì´ë©´ì„œë„ ì „ì²´ ìŠ¤í† ë¦¬ê°€ ì—°ê²°ë˜ë„ë¡ êµ¬ì„±
6. **ì´ë¯¸ì§€ ì—°ê³„**: ì´ë¯¸ì§€ ì •ë³´ë¥¼ ì ì ˆí•œ ìœ„ì¹˜ì— ìì—°ìŠ¤ëŸ½ê²Œ ë…¹ì—¬ëƒ„
7. **ì™„ì„±ë„**: ë§¤ê±°ì§„ ë…ìë“¤ì´ ëª°ì…í•  ìˆ˜ ìˆëŠ” ì™„ì„±ëœ ìŠ¤í† ë¦¬ë¡œ êµ¬ì„±
8. **í™•ì¥ì„±**: í›„ì† ì—ì´ì „íŠ¸ë“¤ì´ ì¶”ê°€ ì‘ì—…í•  ìˆ˜ ìˆëŠ” ì—¬ì§€ ì œê³µ
9. **ì˜ë¯¸ì  ì—°ê²°**: ì´ë¯¸ì§€-í…ìŠ¤íŠ¸ ë¶„ì„ ê²°ê³¼ë¥¼ ë°˜ì˜í•˜ì—¬ ì‹œê°ì  ìš”ì†Œì™€ í…ìŠ¤íŠ¸ê°€ ì¡°í™”ë¡­ê²Œ êµ¬ì„±

**ë§¤ê±°ì§„ êµ¬ì„± ìš”ì†Œ (ëª¨ë“  ì½˜í…ì¸  í¬í•¨):**
1. ë§¤ë ¥ì ì¸ ì œëª©ê³¼ ë¶€ì œëª©
2. ì—¬í–‰ì§€ ì†Œê°œ ë° ì²«ì¸ìƒ (ì¸í„°ë·°ì™€ ì—ì„¸ì´ ë‚´ìš© í™œìš©)
3. ì£¼ìš” ê²½í—˜ê³¼ ê°ìƒ (ëª¨ë“  ì¸í„°ë·°ì™€ ì—ì„¸ì´ í˜¼í•©)
4. íŠ¹ë³„í•œ ìˆœê°„ë“¤ê³¼ ë§Œë‚¨ (ëª¨ë“  ì½˜í…ì¸ ì—ì„œ ì¶”ì¶œ)
5. ì¼ìƒì  ê²½í—˜ë“¤ (ëª¨ë“  ì„¸ë¶€ ë‚´ìš© í¬í•¨)
6. ë¬¸í™”ì  ì²´í—˜ê³¼ ì„±ì°° (ì—ì„¸ì´ ë‚´ìš© ì¤‘ì‹¬)
7. ì—¬í–‰ì˜ ì˜ë¯¸ì™€ ë§ˆë¬´ë¦¬ (ëª¨ë“  ê°ìƒ í†µí•©)

**ìŠ¤íƒ€ì¼ (ì²« ë²ˆì§¸ ì—ì´ì „íŠ¸ ê¸°ì¤€):**
- ë§¤ê±°ì§„ íŠ¹ìœ ì˜ ì„¸ë ¨ë˜ê³  ê°ì„±ì ì¸ ë¬¸ì²´
- ë…ìì˜ ê³µê°ì„ ì´ëŒì–´ë‚´ëŠ” ìŠ¤í† ë¦¬í…”ë§
- ì‹œê°ì  ìƒìƒë ¥ì„ ìê·¹í•˜ëŠ” ë¬˜ì‚¬
- ì¸í„°ë·°ì˜ ì§„ì†”í•¨ê³¼ ì—ì„¸ì´ì˜ ì„±ì°°ì´ ì¡°í™”ëœ í†¤
- **ëª¨ë“  ì œê³µëœ ì½˜í…ì¸ ê°€ ìì—°ìŠ¤ëŸ½ê²Œ ë…¹ì•„ë“  ì™„ì„±ëœ ìŠ¤í† ë¦¬**
- **í›„ì† ì—ì´ì „íŠ¸ë“¤ì´ ì‘ì—…í•˜ê¸° ì¢‹ì€ êµ¬ì¡°í™”ëœ í˜•íƒœ**
- **ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ê°€ ì„œë¡œë¥¼ ë³´ì™„í•˜ê³  ê°•í™”í•˜ëŠ” ì‹œë„ˆì§€ ì°½ì¶œ**

**ì´ë¯¸ì§€-í…ìŠ¤íŠ¸ ì‹œë„ˆì§€ ì°½ì¶œ ìš”êµ¬ì‚¬í•­:**
- ê° í…ìŠ¤íŠ¸ ì„¹ì…˜ì—ì„œ ì‹œê°ì  ìš”ì†Œë¥¼ ì—°ìƒì‹œí‚¤ëŠ” ë¬˜ì‚¬ í¬í•¨
- ì´ë¯¸ì§€ì˜ ê°ì •ì  í†¤ê³¼ ì¼ì¹˜í•˜ëŠ” ë¬¸ì²´ ì‚¬ìš©
- ë…ìê°€ í…ìŠ¤íŠ¸ë¥¼ ì½ìœ¼ë©´ì„œ ìì—°ìŠ¤ëŸ½ê²Œ ì´ë¯¸ì§€ë¥¼ ë– ì˜¬ë¦´ ìˆ˜ ìˆë„ë¡ êµ¬ì„±
- ì´ë¯¸ì§€ ì‹œí€€ìŠ¤ê°€ í…ìŠ¤íŠ¸ì˜ ë‚´ëŸ¬í‹°ë¸Œ í”Œë¡œìš°ì™€ ì¼ì¹˜í•˜ë„ë¡ ì„¹ì…˜ ë°°ì¹˜

**ì¶œë ¥ ìš”êµ¬ì‚¬í•­:**
- ìµœì†Œ 3000ì ì´ìƒì˜ í’ë¶€í•œ ë§¤ê±°ì§„ ì½˜í…ì¸ 
- ëª¨ë“  ì¸í„°ë·°ì™€ ì—ì„¸ì´ ë‚´ìš©ì´ í¬í•¨ëœ ì™„ì„±ëœ ìŠ¤í† ë¦¬
- ì—¬í–‰ì˜ ì „ ê³¼ì •ì„ ì•„ìš°ë¥´ëŠ” ì™„ì „í•œ ë‚´ëŸ¬í‹°ë¸Œ
- ì´ë¯¸ì§€ ë°°ì¹˜ ì—ì´ì „íŠ¸ë¥¼ ìœ„í•œ ì´ë¯¸ì§€ ì—°ê²°ì  ì •ë³´ í¬í•¨
- **ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ì˜ ì˜ë¯¸ì  ì—°ê²°ì´ ëª…í™•íˆ ë“œëŸ¬ë‚˜ëŠ” êµ¬ì„±**

**í…œí”Œë¦¿ ìƒì„± ê·œì¹™:**
- ëª¨ë“  í…ìŠ¤íŠ¸ ì„¹ì…˜ì€ ë…ìì˜ ì¸ì§€ íë¦„ì„ ê³ ë ¤í•˜ì—¬ ìì—°ìŠ¤ëŸ½ê²Œ ì´ì–´ì ¸ì•¼ í•©ë‹ˆë‹¤.
- ì¤‘ë³µì„ ì ˆëŒ€ë¡œ í•˜ì§€ì•Šê³  ë§Œë“­ë‹ˆë‹¤!!
- **ê° ì„¹ì…˜ì—ì„œ í•´ë‹¹í•˜ëŠ” ì´ë¯¸ì§€ì˜ ì‹œê°ì  íŠ¹ì„±ì„ í…ìŠ¤íŠ¸ë¡œ í‘œí˜„í•©ë‹ˆë‹¤.**
- **ì´ë¯¸ì§€ê°€ ì „ë‹¬í•˜ëŠ” ê°ì •ê³¼ ë¶„ìœ„ê¸°ë¥¼ í…ìŠ¤íŠ¸ì— ë°˜ì˜í•©ë‹ˆë‹¤.**

**JSX ìµœì í™” êµ¬ì¡°í™” ì§€ì¹¨:**
    1. **ëª…í™•í•œ JSON êµ¬ì¡°**: ê° ì„¹ì…˜ì„ ëª…í™•í•œ JSON ê°ì²´ë¡œ êµ¬ë¶„
    2. **êµ¬ì¡°ì  ë§ˆì»¤ ì œê±°**: "magazine layout design structure" ê°™ì€ ë¶ˆí•„ìš”í•œ ë§ˆì»¤ ì™„ì „ ì œê±°
    3. **ì„¹ì…˜ë³„ ëª…í™•í•œ êµ¬ë¶„**: title, subtitle, bodyê°€ ëª…í™•íˆ ë¶„ë¦¬ëœ êµ¬ì¡°
    4. **íŠ¹ìˆ˜ë¬¸ì ì œê±°**: JSX íŒŒì‹±ì„ ë°©í•´í•˜ëŠ” íŠ¹ìˆ˜ë¬¸ì ì •ë¦¬
    6. **ì¼ê´€ëœ í†¤**: ëª¨ë“  ì„¹ì…˜ì—ì„œ ì¼ê´€ëœ ë¬¸ì²´ ìœ ì§€

    **ì¶œë ¥ í˜•ì‹ (ë°˜ë“œì‹œ ì´ êµ¬ì¡°ë¡œë§Œ ì¶œë ¥):**

    {{
    "magazine_title": "ë§¤ë ¥ì ì¸ ì „ì²´ ì œëª©",
    "magazine_subtitle": "í¥ë¯¸ë¡œìš´ ë¶€ì œëª©",
    "sections": [
        {{
        "section_id": 1,
        "title": "ì„¹ì…˜ ì œëª©",
        "subtitle": "ì„¹ì…˜ ë¶€ì œëª©",
        "body": "ì™„ì „í•œ ë³¸ë¬¸ ë‚´ìš© (íŠ¹ìˆ˜ë¬¸ì ì œê±°)",
        "image_keywords": ["ê´€ë ¨", "ì´ë¯¸ì§€", "í‚¤ì›Œë“œ"]
        }},
        {{
        "section_id": 2,
        "title": "ì„¹ì…˜ ì œëª©",
        "subtitle": "ì„¹ì…˜ ë¶€ì œëª©", 
        "body": "ì™„ì „í•œ ë³¸ë¬¸ ë‚´ìš© (íŠ¹ìˆ˜ë¬¸ì ì œê±°)",
        "image_keywords": ["ê´€ë ¨", "ì´ë¯¸ì§€", "í‚¤ì›Œë“œ"]
        }}
    ]
    }}

    **ì¤‘ìš” ì œì•½ì‚¬í•­:**
    - ìœ„ì˜ JSON í˜•ì‹ë§Œ ì¶œë ¥í•˜ê³  ë‹¤ë¥¸ í…ìŠ¤íŠ¸ëŠ” í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”
    - êµ¬ì¡°ì  ë§ˆì»¤ë‚˜ ë©”íƒ€ë°ì´í„°ëŠ” ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”
    - ëª¨ë“  í…ìŠ¤íŠ¸ëŠ” JSXì—ì„œ ì•ˆì „í•˜ê²Œ íŒŒì‹±ë  ìˆ˜ ìˆë„ë¡ ì •ë¦¬í•˜ì„¸ìš”
    - ê° ì„¹ì…˜ì˜ bodyëŠ” ì™„ì „í•œ ë¬¸ì¥ìœ¼ë¡œ êµ¬ì„±
""",
            agent=agent,
            expected_output="ëª¨ë“  í•˜ìœ„ ì—ì´ì „íŠ¸ ì½˜í…ì¸ ê°€ í¬í•¨ë˜ê³  ì´ë¯¸ì§€-í…ìŠ¤íŠ¸ ì˜ë¯¸ì  ì—°ê²°ì´ ê°•í™”ëœ ì™„ì„±ëœ ì—¬í–‰ ë§¤ê±°ì§„ ì½˜í…ì¸ "
        )
        
        # ë¹„ë™ê¸° íƒœìŠ¤í¬ ì‹¤í–‰
        result = await asyncio.get_event_loop().run_in_executor(
            None, agent.execute_task, integration_task
        )
        
        # ê²°ê³¼ ê²€ì¦
        final_content = str(result)
        await self._verify_final_content_as_first_agent_async(final_content, interview_results, essay_results)
        
        return final_content

    def _format_semantic_connections_for_prompt(self, semantic_connections: Dict) -> str:
        """ì˜ë¯¸ì  ì—°ê²° ì •ë³´ë¥¼ í”„ë¡¬í”„íŠ¸ìš©ìœ¼ë¡œ í¬ë§·íŒ…"""
        formatted_info = []
        
        # ê°ì •ì  í†¤ ë§¤ì¹­ ì •ë³´
        if semantic_connections.get("emotional_tone_matches"):
            formatted_info.append("**ê°ì •ì  í†¤ ë§¤ì¹­:**")
            for match in semantic_connections["emotional_tone_matches"]:
                formatted_info.append(f"- ì´ë¯¸ì§€ {match['image_index']}: {match['text_section']} (ë§¤ì¹­ë„: {match['match_score']:.2f})")
        
        # ì£¼ì œì  ì—°ê²°ì„± ì •ë³´
        if semantic_connections.get("thematic_alignments"):
            formatted_info.append("\n**ì£¼ì œì  ì—°ê²°ì„±:**")
            for alignment in semantic_connections["thematic_alignments"]:
                formatted_info.append(f"- ì´ë¯¸ì§€ {alignment['image_index']}: {alignment['text_section']} (ì—°ê²°ë„: {alignment['alignment_score']:.2f})")
        
        # ë‚´ëŸ¬í‹°ë¸Œ í”Œë¡œìš° ì—°ê²°
        if semantic_connections.get("narrative_flow_connections"):
            formatted_info.append("\n**ë‚´ëŸ¬í‹°ë¸Œ í”Œë¡œìš° ì—°ê²°:**")
            for connection in semantic_connections["narrative_flow_connections"]:
                if connection.get("recommended_images"):
                    formatted_info.append(f"- {connection['section_key']}: ì¶”ì²œ ì´ë¯¸ì§€ {[img['image_index'] for img in connection['recommended_images'][:2]]}")
        
        return "\n".join(formatted_info) if formatted_info else "ì˜ë¯¸ì  ì—°ê²° ì •ë³´ ì—†ìŒ"

    async def _verify_content_completeness_async(self, interview_results: Dict[str, str], essay_results: Dict[str, str], original_texts: List[str]):
        """ì½˜í…ì¸  ì™„ì „ì„± ê²€ì¦ (ë¹„ë™ê¸°)"""
        await asyncio.get_event_loop().run_in_executor(
            None, self._verify_content_completeness, interview_results, essay_results, original_texts
        )

    async def _verify_final_content_as_first_agent_async(self, final_content: str, interview_results: Dict[str, str], essay_results: Dict[str, str]):
        """ì²« ë²ˆì§¸ ì—ì´ì „íŠ¸ë¡œì„œ ìµœì¢… ì½˜í…ì¸  ê²€ì¦ (ë¹„ë™ê¸°)"""
        await asyncio.get_event_loop().run_in_executor(
            None, self._verify_final_content_as_first_agent, final_content, interview_results, essay_results
        )

    async def _log_final_content_async(self, final_content: str, interview_results: Dict[str, str],
                                     essay_results: Dict[str, str], image_analysis_results: List[Dict], 
                                     texts: List[str], semantic_connections: Dict):
        """ìµœì¢… í†µí•© ì½˜í…ì¸  ìƒì„± ë¡œê¹… (ìƒˆë¡œìš´ ë°©ì‹ ì ìš©)"""
        # âœ… LoggingManager ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
        from utils.logging_manager import LoggingManager
        logging_manager = LoggingManager()
        
        # âœ… ìƒˆë¡œìš´ ë¡œê¹… ë°©ì‹ìœ¼ë¡œ ì‘ë‹µ ë°ì´í„° ì €ì¥
        await logging_manager.log_agent_response(
            agent_name="ContentCreatorV2Agent",
            agent_role="ì—¬í–‰ ì½˜í…ì¸  í†µí•© í¸ì§‘ì (ì²« ë²ˆì§¸ ì—ì´ì „íŠ¸)",
            task_description=f"ì¸í„°ë·° {len(interview_results)}ê°œ, ì—ì„¸ì´ {len(essay_results)}ê°œ, ì´ë¯¸ì§€ {len(image_analysis_results)}ê°œë¥¼ í†µí•©í•œ ë§¤ê±°ì§„ ì½˜í…ì¸  ìƒì„± (ì´ë¯¸ì§€-í…ìŠ¤íŠ¸ ì˜ë¯¸ì  ì—°ê²° í¬í•¨)",
            response_data=final_content,  # âœ… ì‹¤ì œ ì‘ë‹µ ë°ì´í„°ë§Œ ì €ì¥
            metadata={
                "final_content_length": len(final_content),
                "content_expansion_ratio": len(final_content) / sum(len(text) for text in texts) if texts else 0,
                "integration_success": len(interview_results) > 0 and len(essay_results) > 0,
                "image_integration_count": len(image_analysis_results),
                "semantic_connections_count": sum(len(v) if isinstance(v, list) else 0 for v in semantic_connections.values()),
                "emotional_tone_matches": len(semantic_connections.get("emotional_tone_matches", [])),
                "thematic_alignments": len(semantic_connections.get("thematic_alignments", [])),
                "narrative_flow_connections": len(semantic_connections.get("narrative_flow_connections", [])),
                "first_agent_completion": True,
                "async_processing": True,
                "image_text_synergy_enabled": True
            }
        )

    # ë™ê¸° ë²„ì „ ë©”ì„œë“œë“¤ (í˜¸í™˜ì„± ìœ ì§€)
    def _verify_final_content_as_first_agent(self, final_content: str, interview_results: Dict[str, str], essay_results: Dict[str, str]):
        """ì²« ë²ˆì§¸ ì—ì´ì „íŠ¸ë¡œì„œ ìµœì¢… ì½˜í…ì¸  ê²€ì¦ (ë™ê¸° ë²„ì „)"""
        final_length = len(final_content)
        total_source_length = sum(len(content) for content in interview_results.values()) + sum(len(content) for content in essay_results.values())
        
        print(f"ContentCreatorV2 (ì²« ë²ˆì§¸ ì—ì´ì „íŠ¸): ìµœì¢… ì½˜í…ì¸  ê²€ì¦")
        print(f"- ìµœì¢… ì½˜í…ì¸  ê¸¸ì´: {final_length}ì")
        print(f"- ì›ë³¸ ì†ŒìŠ¤ ê¸¸ì´: {total_source_length}ì")
        print(f"- í™•ì¥ ë¹„ìœ¨: {(final_length / total_source_length * 100):.1f}%" if total_source_length > 0 else "- í™•ì¥ ë¹„ìœ¨: ê³„ì‚° ë¶ˆê°€")
        print(f"- ì²« ë²ˆì§¸ ì—ì´ì „íŠ¸ ì—­í• : ê¸°ì´ˆ ë°ì´í„° ìƒì„± ì™„ë£Œ")
        print(f"- ì´ë¯¸ì§€-í…ìŠ¤íŠ¸ ì‹œë„ˆì§€: í™œì„±í™”ë¨")
        
        if final_length < total_source_length * 0.8:
            print("âš ï¸ ìµœì¢… ì½˜í…ì¸ ê°€ ì›ë³¸ë³´ë‹¤ í˜„ì €íˆ ì§§ìŠµë‹ˆë‹¤. ì²¨ì‚­ì´ ë°œìƒí–ˆì„ ê°€ëŠ¥ì„±ì´ ìˆìŠµë‹ˆë‹¤.")
        else:
            print("âœ… ì½˜í…ì¸ ê°€ ì ì ˆíˆ í™•ì¥ë˜ì–´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        print("âœ… ì²« ë²ˆì§¸ ì—ì´ì „íŠ¸ë¡œì„œ í›„ì† ì—ì´ì „íŠ¸ë“¤ì„ ìœ„í•œ ê¸°ì´ˆ ë°ì´í„° ìƒì„± ì™„ë£Œ")
        print("âœ… ì´ë¯¸ì§€-í…ìŠ¤íŠ¸ ì˜ë¯¸ì  ì—°ê²° ê°•í™” ì™„ë£Œ")

    def _calculate_content_quality_score(self, final_content: str, interview_results: Dict[str, str], essay_results: Dict[str, str]) -> float:
        """ì½˜í…ì¸  í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°"""
        score = 0.0
        
        # ê¸¸ì´ ê¸°ë°˜ ì ìˆ˜ (25%)
        if len(final_content) > 3000:
            score += 0.25
        elif len(final_content) > 2000:
            score += 0.2
        elif len(final_content) > 1000:
            score += 0.1
        
        # êµ¬ì¡°í™” ì ìˆ˜ (25%)
        section_count = final_content.count("===")
        if section_count >= 5:
            score += 0.25
        elif section_count >= 3:
            score += 0.2
        elif section_count >= 1:
            score += 0.1
        
        # ì½˜í…ì¸  í†µí•© ì ìˆ˜ (25%)
        if interview_results and essay_results:
            score += 0.25
        elif interview_results or essay_results:
            score += 0.15
        
        # ì´ë¯¸ì§€-í…ìŠ¤íŠ¸ ì‹œë„ˆì§€ ì ìˆ˜ (25%)
        visual_descriptors = ['ë³´ì´ëŠ”', 'ëˆˆì— ë„ëŠ”', 'í™”ë ¤í•œ', 'ì„ ëª…í•œ', 'ë°ì€', 'ì–´ë‘ìš´', 'ì•„ë¦„ë‹¤ìš´']
        synergy_count = sum(1 for descriptor in visual_descriptors if descriptor in final_content)
        if synergy_count >= 5:
            score += 0.25
        elif synergy_count >= 3:
            score += 0.2
        elif synergy_count >= 1:
            score += 0.1
        
        return min(score, 1.0)

    # ê¸°ì¡´ ë©”ì„œë“œë“¤ ìœ ì§€
    def _process_image_analysis(self, image_analysis_results: List[Dict]) -> str:
        """ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼ ì •ë¦¬"""
        if not image_analysis_results:
            return "ì´ë¯¸ì§€ ì •ë³´ ì—†ìŒ"
        
        image_summaries = []
        for i, result in enumerate(image_analysis_results):
            location = result.get('location', f'ì´ë¯¸ì§€ {i+1}')
            description = result.get('description', 'ì„¤ëª… ì—†ìŒ')
            image_summaries.append(f"ğŸ“ {location}: {description}")
        
        return "\n".join(image_summaries)

    def _verify_content_completeness(self, interview_results: Dict[str, str], essay_results: Dict[str, str], original_texts: List[str]):
        """ì½˜í…ì¸  ì™„ì „ì„± ê²€ì¦"""
        print("ContentCreatorV2 (ì²« ë²ˆì§¸ ì—ì´ì „íŠ¸): ì½˜í…ì¸  ì™„ì „ì„± ê²€ì¦")
        
        # ì›ë³¸ í…ìŠ¤íŠ¸ ê¸¸ì´
        total_original_length = sum(len(text) for text in original_texts)
        
        # ì¸í„°ë·° ê²°ê³¼ ê¸¸ì´
        total_interview_length = sum(len(content) for content in interview_results.values())
        
        # ì—ì„¸ì´ ê²°ê³¼ ê¸¸ì´
        total_essay_length = sum(len(content) for content in essay_results.values())
        
        print(f"ì›ë³¸ í…ìŠ¤íŠ¸: {total_original_length}ì")
        print(f"ì¸í„°ë·° ê²°ê³¼: {total_interview_length}ì ({len(interview_results)}ê°œ)")
        print(f"ì—ì„¸ì´ ê²°ê³¼: {total_essay_length}ì ({len(essay_results)}ê°œ)")

    # ë™ê¸° ë²„ì „ ë©”ì„œë“œ (í˜¸í™˜ì„± ë³´ì¥)
    def create_magazine_content_sync(self, texts: List[str], image_analysis_results: List[Dict]) -> str:
        """ë™ê¸° ë²„ì „ ë§¤ê±°ì§„ ì½˜í…ì¸  ìƒì„± (í˜¸í™˜ì„± ìœ ì§€)"""
        return asyncio.run(self.create_magazine_content(texts, image_analysis_results))


class ContentCreatorV2Crew:
    """ContentCreatorV2ë¥¼ ìœ„í•œ Crew ê´€ë¦¬ (ë¹„ë™ê¸° ì²˜ë¦¬)"""

    def __init__(self):
        self.content_creator = ContentCreatorV2Agent()

    def create_crew(self) -> Crew:
        """ContentCreatorV2 ì „ìš© Crew ìƒì„±"""
        return Crew(
            agents=[self.content_creator.create_agent()],
            verbose=True
        )

    async def execute_content_creation(self, texts: List[str], image_analysis_results: List[Dict]) -> str:
        """Crewë¥¼ í†µí•œ ì½˜í…ì¸  ìƒì„± ì‹¤í–‰ (ì²« ë²ˆì§¸ ì—ì´ì „íŠ¸ - ë¹„ë™ê¸°)"""
        crew = self.create_crew()
        
        print("\n=== ContentCreatorV2 Crew ì‹¤í–‰ (ì²« ë²ˆì§¸ ì—ì´ì „íŠ¸ - ë¹„ë™ê¸°) ===")
        print(f"- ì…ë ¥ í…ìŠ¤íŠ¸: {len(texts)}ê°œ")
        print(f"- ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼: {len(image_analysis_results)}ê°œ")
        print(f"- ì—­í• : ì²« ë²ˆì§¸ ì—ì´ì „íŠ¸ (ë¡œê·¸ ìˆ˜ì§‘ ì‹œì‘)")
        print(f"- ì´ë¯¸ì§€-í…ìŠ¤íŠ¸ ì‹œë„ˆì§€: í™œì„±í™”")
        
        # ContentCreatorV2Agentë¥¼ í†µí•œ ì½˜í…ì¸  ìƒì„± (ë¹„ë™ê¸°)
        result = await self.content_creator.create_magazine_content(texts, image_analysis_results)
        
        print("âœ… ContentCreatorV2 Crew ì‹¤í–‰ ì™„ë£Œ (ì²« ë²ˆì§¸ ì—ì´ì „íŠ¸ - ë¹„ë™ê¸°)")
        print("âœ… í›„ì† ì—ì´ì „íŠ¸ë“¤ì„ ìœ„í•œ ë¡œê·¸ ë°ì´í„° ìƒì„± ì™„ë£Œ")
        print("âœ… ì´ë¯¸ì§€-í…ìŠ¤íŠ¸ ì˜ë¯¸ì  ì—°ê²° ê°•í™” ì™„ë£Œ")
        
        return result

    # ë™ê¸° ë²„ì „ ë©”ì„œë“œ (í˜¸í™˜ì„± ë³´ì¥)
    def execute_content_creation_sync(self, texts: List[str], image_analysis_results: List[Dict]) -> str:
        """ë™ê¸° ë²„ì „ ì½˜í…ì¸  ìƒì„± ì‹¤í–‰ (í˜¸í™˜ì„± ìœ ì§€)"""
        return asyncio.run(self.execute_content_creation(texts, image_analysis_results))
