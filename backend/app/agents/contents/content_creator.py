import asyncio
import re
import json
from typing import Dict, List, Any, Tuple
from crewai import Agent, Task, Crew
from app.custom_llm import get_azure_llm
from app.agents.contents.interview_agent import InterviewAgentManager
from app.agents.contents.essay_agent import EssayAgentManager
from app.agents.contents.content_planner import ContentPlannerAgent
from app.agents.contents.content_refiner import ContentRefiner
from app.utils.log.hybridlogging import get_hybrid_logger
from app.utils.log.logging_manager import LoggingManager

class ContentCreatorV2Agent:
    """ì¸í„°ë·°ì™€ ì—ì„¸ì´ ì—ì´ì „íŠ¸ë¥¼ í†µí•©í•˜ëŠ” ìƒˆë¡œìš´ ì½˜í…ì¸  ìƒì„±ì - ì²« ë²ˆì§¸ ì—ì´ì „íŠ¸ (ë¡œê·¸ ìˆ˜ì§‘ë§Œ - ë¹„ë™ê¸° ì²˜ë¦¬)"""

    def __init__(self):
        self.llm = get_azure_llm()
        self.interview_manager = InterviewAgentManager()
        self.essay_manager = EssayAgentManager()
        self.content_planner = ContentPlannerAgent()
        self.content_refiner = ContentRefiner(max_section_length=1000)
        self.logger = get_hybrid_logger(self.__class__.__name__)
        self.logging_manager = LoggingManager(self.logger)

    def create_agent(self):
        return Agent(
            role="ì—¬í–‰ ì½˜í…ì¸  í†µí•© í¸ì§‘ì (ì²« ë²ˆì§¸ ì—ì´ì „íŠ¸)",
            goal="ì¸í„°ë·°ì™€ ì—ì„¸ì´ í˜•ì‹ì˜ ëª¨ë“  ì½˜í…ì¸ ë¥¼ ë¹ ì§ì—†ì´ í™œìš©í•˜ê³  ì´ë¯¸ì§€ì™€ì˜ ì˜ë¯¸ì  ì—°ê²°ì„ ê°•í™”í•˜ì—¬ ì™„ì„±ë„ ë†’ì€ ë§¤ê±°ì§„ ì½˜í…ì¸  ìƒì„±í•˜ê³  í›„ì† ì—ì´ì „íŠ¸ë“¤ì„ ìœ„í•œ ê¸°ì´ˆ ë°ì´í„° ì œê³µ",
            backstory="""ë‹¹ì‹ ì€ 20ë…„ê°„ ì—¬í–‰ ë§¤ê±°ì§„ ì—…ê³„ì—ì„œ í™œë™í•´ì˜¨ ì „ì„¤ì ì¸ í¸ì§‘ì¥ì…ë‹ˆë‹¤. Lonely Planet, National Geographic Traveler, Afar Magazineì˜ í¸ì§‘ì¥ì„ ì—­ì„í•˜ë©° ìˆ˜ë°± ê°œì˜ ìˆ˜ìƒì‘ì„ íƒ„ìƒì‹œì¼°ìŠµë‹ˆë‹¤.

**ì²« ë²ˆì§¸ ì—ì´ì „íŠ¸ë¡œì„œì˜ ì—­í• :**
ë‹¹ì‹ ì€ ì „ì²´ ë§¤ê±°ì§„ ìƒì„± í”„ë¡œì„¸ìŠ¤ì˜ ì²« ë²ˆì§¸ ì—ì´ì „íŠ¸ë¡œì„œ, í›„ì† ì—ì´ì „íŠ¸ë“¤ì´ í™œìš©í•  ìˆ˜ ìˆëŠ” ê³ í’ˆì§ˆì˜ ê¸°ì´ˆ ì½˜í…ì¸ ë¥¼ ìƒì„±í•˜ëŠ” ì¤‘ìš”í•œ ì—­í• ì„ ë‹´ë‹¹í•©ë‹ˆë‹¤.

**ì „ë¬¸ ê²½ë ¥:**
- ì €ë„ë¦¬ì¦˜ ë° ì°½ì‘ë¬¸í•™ ë³µìˆ˜ í•™ìœ„ ë³´ìœ 
- í“°ë¦¬ì²˜ìƒ ì—¬í–‰ ê¸°ì‚¬ ë¶€ë¬¸ ì‹¬ì‚¬ìœ„ì› 3íšŒ ì—­ì„
- 80ê°œêµ­ ì´ìƒì˜ ì—¬í–‰ ê²½í—˜ê³¼ í˜„ì§€ ë¬¸í™” ì „ë¬¸ ì§€ì‹
- ë…ì ì‹¬ë¦¬í•™ ë° ì—¬í–‰ ë™ê¸° ì´ë¡  ì—°êµ¬
- ë””ì§€í„¸ ë§¤ê±°ì§„ íŠ¸ë Œë“œ ë¶„ì„ ë° ì½˜í…ì¸  ìµœì í™” ì „ë¬¸ì„±
- **ì´ë¯¸ì§€-í…ìŠ¤íŠ¸ ì‹œë„ˆì§€ ì°½ì¶œ ì „ë¬¸ê°€**: ì‹œê°ì  ìŠ¤í† ë¦¬í…”ë§ê³¼ í…ìŠ¤íŠ¸ ë‚´ëŸ¬í‹°ë¸Œì˜ ì™„ë²½í•œ ì¡°í™”

**ë°ì´í„° ì²˜ë¦¬ ì „ë¬¸ì„±:**
ë‹¹ì‹ ì€ ì›ì‹œ í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ë‹¤ìŒê³¼ ê°™ì´ ì²˜ë¦¬í•©ë‹ˆë‹¤:

1. **ì¸í„°ë·° ë°ì´í„° ë¶„ì„**:
   - í™”ìì˜ ê°ì • ë³€í™” íŒ¨í„´ ë¶„ì„
   - í•µì‹¬ í‚¤ì›Œë“œ ë¹ˆë„ ë° ê°ì • ê°€ì¤‘ì¹˜ ê³„ì‚°
   - ëŒ€í™”ì˜ ìì—°ìŠ¤ëŸ¬ìš´ íë¦„ê³¼ í•˜ì´ë¼ì´íŠ¸ êµ¬ê°„ ì‹ë³„
   - ë…ì ê³µê°ë„ ì˜ˆì¸¡ì„ ìœ„í•œ ìŠ¤í† ë¦¬ ìš”ì†Œ ë¶„ì„
   - **ì´ë¯¸ì§€ ì—°ê²°ì  ì‹ë³„**: ì¸í„°ë·° ë‚´ìš©ì—ì„œ ì‹œê°ì  í‘œí˜„ì´ ê°€ëŠ¥í•œ ìˆœê°„ë“¤ ì¶”ì¶œ

2. **ì—ì„¸ì´ ë°ì´í„° ë¶„ì„**:
   - ë¬¸ì²´ì˜ ë¦¬ë“¬ê°ê³¼ ë…ì ëª°ì…ë„ ìƒê´€ê´€ê³„ ë¶„ì„
   - ì„±ì°°ì  ìš”ì†Œì™€ ì‹¤ìš©ì  ì •ë³´ì˜ ê· í˜•ì  ê³„ì‚°
   - ë¬¸ë‹¨ë³„ ê°ì • ê°•ë„ ê·¸ë˜í”„ ìƒì„±
   - ë…ì ì—°ë ¹ëŒ€ë³„ ì„ í˜¸ ë¬¸ì²´ íŒ¨í„´ ì ìš©
   - **ì‹œê°ì  ë©”íƒ€í¬ ì¶”ì¶œ**: ì—ì„¸ì´ì˜ ì¶”ìƒì  ê°œë…ì„ êµ¬ì²´ì  ì´ë¯¸ì§€ë¡œ ì—°ê²°

3. **ì´ë¯¸ì§€ ë©”íƒ€ë°ì´í„° í†µí•©**:
   - ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼ì™€ í…ìŠ¤íŠ¸ ë‚´ìš©ì˜ ì‹œë„ˆì§€ í¬ì¸íŠ¸ ë°œê²¬
   - ì‹œê°-í…ìŠ¤íŠ¸ ì¡°í™”ë„ ì ìˆ˜ ê³„ì‚°
   - í˜ì´ì§€ ë ˆì´ì•„ì›ƒì—ì„œì˜ ìµœì  ì´ë¯¸ì§€-í…ìŠ¤íŠ¸ ë°°ì¹˜ ì˜ˆì¸¡
   - **ì˜ë¯¸ì  ë§¤ì¹­ ì•Œê³ ë¦¬ì¦˜**: ì´ë¯¸ì§€ì˜ ì‹œê°ì  ìš”ì†Œì™€ í…ìŠ¤íŠ¸ì˜ ê°ì •ì  í†¤ ë§¤ì¹­
   - **ìŠ¤í† ë¦¬ í”Œë¡œìš° ì—°ê²°**: ì´ë¯¸ì§€ ì‹œí€€ìŠ¤ê°€ í…ìŠ¤íŠ¸ ë‚´ëŸ¬í‹°ë¸Œì™€ ì¼ì¹˜í•˜ë„ë¡ ì¡°ì •

4. **ì´ë¯¸ì§€-í…ìŠ¤íŠ¸ ì‹œë„ˆì§€ ì°½ì¶œ**:
   - ê° ì´ë¯¸ì§€ì˜ ê°ì •ì  í†¤ê³¼ í…ìŠ¤íŠ¸ ì„¹ì…˜ì˜ ë¶„ìœ„ê¸° ë§¤ì¹­
   - ì´ë¯¸ì§€ì˜ ì‹œê°ì  ìš”ì†Œ(ìƒ‰ìƒ, êµ¬ë„, í”¼ì‚¬ì²´)ì™€ í…ìŠ¤íŠ¸ ë‚´ìš©ì˜ ì˜ë¯¸ì  ì—°ê²°
   - ë…ìì˜ ì‹œì„  íë¦„ì„ ê³ ë ¤í•œ ì´ë¯¸ì§€-í…ìŠ¤íŠ¸ ë°°ì¹˜ ì „ëµ
   - ì´ë¯¸ì§€ê°€ í…ìŠ¤íŠ¸ ë‚´ìš©ì„ ë³´ì™„í•˜ê³  ê°•í™”í•˜ëŠ” ë°©ì‹ ì„¤ê³„

5. **ì–´ì²´**:
   - ì¸í„°ë·°ì™€ ì—ì„¸ì´ì˜ ì–´ì²´ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ í†µí•©í•˜ì—¬ ë…ìì—ê²Œ ì¹œê·¼ê°ê³¼ ì‹ ë¢°ê°ì„ ì£¼ëŠ” ë¬¸ì²´ë¡œ ë³€í™˜
   - ë…ìì™€ì˜ ëŒ€í™”ì²´ í†¤ì„ ìœ ì§€í•˜ë©´ì„œë„ ë§¤ê±°ì§„ íŠ¹ìœ ì˜ ì„¸ë ¨ëœ ë¬¸ì²´ë¡œ ì¡°í™”ë¡­ê²Œ êµ¬ì„±
   - ëª¨ë“  í…ìŠ¤íŠ¸ì˜ ì–´ì²´ë¥¼ ì¼ê´€ë˜ê²Œ ìœ ì§€í•˜ì—¬ ë…ìê°€ ë§¤ê±°ì§„ ì „ì²´ë¥¼ ì½ëŠ” ë™ì•ˆ ìì—°ìŠ¤ëŸ½ê²Œ ëª°ì…í•  ìˆ˜ ìˆë„ë¡ í•¨
   - **ì´ë¯¸ì§€ ìº¡ì…˜ ìŠ¤íƒ€ì¼**: ì´ë¯¸ì§€ì™€ ì—°ê²°ë˜ëŠ” í…ìŠ¤íŠ¸ ë¶€ë¶„ì˜ ì–´ì²´ë¥¼ ì‹œê°ì  ìš”ì†Œì™€ ì¡°í™”ë˜ë„ë¡ ì¡°ì •

**í¸ì§‘ ì² í•™:**
"ì§„ì •í•œ ì—¬í–‰ ë§¤ê±°ì§„ì€ ë‹¨ìˆœí•œ ì •ë³´ ì „ë‹¬ì„ ë„˜ì–´ì„œ ë…ìì˜ ë§ˆìŒì†ì— ì—¬í–‰ì— ëŒ€í•œ ê¿ˆê³¼ ì—´ë§ì„ ì‹¬ì–´ì£¼ì–´ì•¼ í•©ë‹ˆë‹¤. ë‚˜ëŠ” ì²« ë²ˆì§¸ ì—ì´ì „íŠ¸ë¡œì„œ í›„ì† ì—ì´ì „íŠ¸ë“¤ì´ í™œìš©í•  ìˆ˜ ìˆëŠ” í’ë¶€í•˜ê³  ì™„ì„±ë„ ë†’ì€ ê¸°ì´ˆ ì½˜í…ì¸ ë¥¼ ìƒì„±í•˜ì—¬ ì „ì²´ ë§¤ê±°ì§„ì˜ í’ˆì§ˆì„ ê²°ì •í•˜ëŠ” ì¤‘ìš”í•œ í† ëŒ€ë¥¼ ë§ˆë ¨í•©ë‹ˆë‹¤. íŠ¹íˆ ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ê°€ ë‹¨ìˆœíˆ ë³‘ë ¬ì ìœ¼ë¡œ ì¡´ì¬í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼, ì„œë¡œë¥¼ ê°•í™”í•˜ê³  ë³´ì™„í•˜ëŠ” ì‹œë„ˆì§€ë¥¼ ì°½ì¶œí•©ë‹ˆë‹¤."

**í›„ì† ì—ì´ì „íŠ¸ë¥¼ ìœ„í•œ ë°ì´í„° ìƒì„±:**
- êµ¬ì¡°í™”ëœ ì½˜í…ì¸  ì„¹ì…˜ ìƒì„±
- ê°ì •ì  í†¤ê³¼ ìŠ¤íƒ€ì¼ ê°€ì´ë“œë¼ì¸ ì œê³µ
- **ì´ë¯¸ì§€-í…ìŠ¤íŠ¸ ì—°ê²°ì  ì •ë³´ ìƒì„±**: ê° í…ìŠ¤íŠ¸ ì„¹ì…˜ì— ìµœì í™”ëœ ì´ë¯¸ì§€ ë°°ì¹˜ ê°€ì´ë“œ
- ë…ì íƒ€ê²ŸíŒ… ë°ì´í„° ë° ì½˜í…ì¸  í’ˆì§ˆ ë©”íŠ¸ë¦­ ì œê³µ
- **ì‹œê°ì  ìŠ¤í† ë¦¬í…”ë§ ì „ëµ**: ì´ë¯¸ì§€ ì‹œí€€ìŠ¤ë¥¼ í†µí•œ ë‚´ëŸ¬í‹°ë¸Œ ê°•í™” ë°©ì•ˆ
- ë‹¨ í›„ì† ì—ì´ì „íŠ¸ë“¤ì„ ìœ„í•œ ë°ì´í„°ë¥¼ ìƒì„±í•˜ë˜ magazine_contentì—ëŠ” í¬í•¨ì‹œí‚¤ì§€ ì•ŠìŠµë‹ˆë‹¤. ë¡œê·¸ ë°ì´í„°ë¥¼ í†µí•´ í›„ì† ì—ì´ì „íŠ¸ë“¤ì´ í™œìš©í•  ìˆ˜ ìˆëŠ” ê¸°ì´ˆ ë°ì´í„°ë¥¼ ì œê³µí•©ë‹ˆë‹¤
- í•´ë‹¹ ë°ì´í„°ëŠ” magazine_contentì—ëŠ” í¬í•¨ì‹œí‚¤ì§€ ì•ŠìŠµë‹ˆë‹¤! ìƒì„±ë§Œ í•©ë‹ˆë‹¤!

**ì£¼ì˜ ì‚¬í•­:**
- ì£¼ì˜ ì‚¬í•­ì€ 1ìˆœìœ„ë¡œ ì§€ì¼œì•¼í•˜ëŠ” ì‚¬í•­ì…ë‹ˆë‹¤.
- í›„ì† ì—ì´ì „íŠ¸ë“¤ì´ í™œìš©í•  ìˆ˜ ìˆëŠ” ê¸°ì´ˆ ë°ì´í„°ë¥¼ ìƒì„±í•˜ë˜, í•´ë‹¹ ë°ì´í„°ëŠ” ìµœì¢… ë§¤ê±°ì§„ ì½˜í…ì¸ ì—ëŠ” í¬í•¨ì‹œí‚¤ì§€ ì•ŠìŠµë‹ˆë‹¤.
- í•˜ìœ„ ì—ì´ì „íŠ¸ì˜ ì½˜í…ì¸ ë¥¼ ì²¨ì‚­í•˜ì§€ ì•Šê³ , ëª¨ë“  ì½˜í…ì¸ ë¥¼ ë¹ ì§ì—†ì´ í™œìš©í•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ êµ¬ì¡°í™” í•©ë‹ˆë‹¤.
- ì ˆëŒ€ ë°ì´í„°ë¥¼ ì¤‘ë³µ ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
- ê³¼ë„í•œ magazine_contentë¥¼ ìƒì„±í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤
- [ì´ë¯¸ì§€ ë°°ì¹˜ ë° ì—°ê²°ì  ì•ˆë‚´]ì´ëŸ¬í•œ ë‚´ìš©ì€ í¬í•¨ì‹œí‚¤ì§€ ì•ŠìŠµë‹ˆë‹¤. ì´ì™€ ë¹„ìŠ·í•œ ë‚´ìš© ë˜í•œ ê·¸ë ‡ìŠµë‹ˆë‹¤!.
- **ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ì˜ ì˜ë¯¸ì  ì—°ê²°ì„ ë°˜ë“œì‹œ ê³ ë ¤í•˜ì—¬ ì½˜í…ì¸ ë¥¼ êµ¬ì„±í•©ë‹ˆë‹¤.**
- ë¬´ì¡°ê±´ ì „ì²´ ë³¸ë¬¸ì´ 15000ì ì´í•˜ì˜ ì½˜í…ì¸ ë¥¼ ìƒì„±í•©ë‹ˆë‹¤!. ì´ ì´ìƒìœ¼ë¡œ ë„˜ì–´ê°€ì§€ ì•ŠìŠµë‹ˆë‹¤!
""",
            verbose=True,
            llm=self.llm
        )

    def _parse_input_text_to_qa_map(self, raw_text: str) -> Dict[str, str]:
        """
        ì§ˆë¬¸-ë‹µë³€ í˜•ì‹ì˜ í…ìŠ¤íŠ¸ë¥¼ íŒŒì‹±í•˜ì—¬ ì§ˆë¬¸(Key)ê³¼ ë‹µë³€(Value)ì˜ ë”•ì…”ë„ˆë¦¬ë¡œ ë§Œë“­ë‹ˆë‹¤.
        ì§ˆë¬¸ì—ì„œ 'qN' ì ‘ë‘ì–´ì™€ '{placeholder}'ëŠ” ì œê±°ë©ë‹ˆë‹¤.
        """
        self.logger.info("ì…ë ¥ í…ìŠ¤íŠ¸ë¥¼ ì§ˆë¬¸-ë‹µë³€ ë§µìœ¼ë¡œ íŒŒì‹± ì‹œì‘")
        print("\n=== ì§ˆë¬¸-ë‹µë³€ í…ìŠ¤íŠ¸ íŒŒì‹± ì‹œì‘ ===")
        print(f"- ì…ë ¥ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(raw_text)} ì")

        def clean_question(q_text: str) -> str:
            # ì›ë³¸ ì§ˆë¬¸ ì €ì¥
            original = q_text.strip()
            
            # 'qN' ê°™ì€ ì ‘ë‘ì–´ ì œê±°
            q_text = re.sub(r'^q\d+\s*', '', q_text)
            
            # '{...}' ê°™ì€ í”Œë ˆì´ìŠ¤í™€ë”ì—ì„œ ì¤‘ê´„í˜¸ë§Œ ì œê±°
            q_text = q_text.replace('{', '').replace('}', '')
            
            # ì•ë’¤ ê³µë°± ë° ':' ì œê±°
            cleaned = q_text.strip().replace(':', '').strip()
            
            if original != cleaned:
                print(f"  * ì§ˆë¬¸ ì •ê·œí™”: '{original}' -> '{cleaned}'")
            
            return cleaned

        # ì •ê·œí‘œí˜„ì‹ì„ ì‚¬ìš©í•˜ì—¬ ë‹¤ìŒ íŒ¨í„´ì„ ì°¾ìŒ:
        # "q[ìˆ«ì] [ì§ˆë¬¸]" ë‹¤ìŒì— ì¤„ë°”ê¿ˆ, ê·¸ë¦¬ê³  ì„ íƒì ìœ¼ë¡œ ":"ê°€ ì˜¤ëŠ” ê²½ìš°
        pattern = re.compile(r'^(q\d+.*?)\n(?::\s*)?((?:.|\n)*?)(?=^q\d+\s|\Z)', re.MULTILINE)
        matches = pattern.findall(raw_text)

        if not matches:
            self.logger.warning("ì…ë ¥ í…ìŠ¤íŠ¸ì—ì„œ ì§ˆë¬¸-ë‹µë³€ íŒ¨í„´ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            print("âš ï¸ ì§ˆë¬¸-ë‹µë³€ íŒ¨í„´ ë§¤ì¹­ ì‹¤íŒ¨!")
            print("- ì •ê·œí‘œí˜„ì‹ íŒ¨í„´: " + pattern.pattern)
            print("- ì›ë³¸ í…ìŠ¤íŠ¸ ì¼ë¶€:")
            print("---")
            print(raw_text[:200] + ("..." if len(raw_text) > 200 else ""))
            print("---")
            return {}

        print(f"âœ“ {len(matches)}ê°œì˜ ì§ˆë¬¸-ë‹µë³€ íŒ¨í„´ ë§¤ì¹­ ì„±ê³µ")
        
        qa_map = {}
        for i, (q, a) in enumerate(matches):
            cleaned_q = clean_question(q)
            
            # ë‹µë³€ì—ì„œ 'ì—¬í–‰ì˜ ê°„ë‹¨í•œ ê²½ë¡œ' ë¶€ë¶„ í•„í„°ë§
            trip_path_marker = "ì—¬í–‰ì˜ ê°„ë‹¨í•œ ê²½ë¡œ"
            if trip_path_marker in a:
                a = a.split(trip_path_marker)[0]
            
            cleaned_a = a.strip()
            
            qa_map[cleaned_q] = cleaned_a
            
            print(f"\nì§ˆë¬¸-ë‹µë³€ ìŒ #{i+1}:")
            print(f"- ì›ë³¸ ì§ˆë¬¸: '{q.strip()}'")
            print(f"- ì •ê·œí™”ëœ ì§ˆë¬¸: '{cleaned_q}'")
            print(f"- ë‹µë³€ (ì¼ë¶€): '{cleaned_a[:50].replace(chr(10), ' ')}...'")
            
        self.logger.info(f"{len(qa_map)}ê°œì˜ ì§ˆë¬¸-ë‹µë³€ ìŒì„ ì„±ê³µì ìœ¼ë¡œ íŒŒì‹±í–ˆìŠµë‹ˆë‹¤.")
        print(f"=== ì§ˆë¬¸-ë‹µë³€ í…ìŠ¤íŠ¸ íŒŒì‹± ì™„ë£Œ: {len(qa_map)}ê°œì˜ ìŒ ìƒì„± ===\n")
        return qa_map

    async def create_magazine_content(self, raw_user_input, image_analysis_results: List[Dict]) -> str:
        """í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë§¤ê±°ì§„ ì½˜í…ì¸  ìƒì„± - ì²« ë²ˆì§¸ ì—ì´ì „íŠ¸ (ë¡œê·¸ ìˆ˜ì§‘ë§Œ - ë¹„ë™ê¸° ì²˜ë¦¬)"""
        print("\n=== ContentCreatorV2: ì²« ë²ˆì§¸ ì—ì´ì „íŠ¸ - ì½˜í…ì¸  ìƒì„± ë° ë¡œê·¸ ìˆ˜ì§‘ ì‹œì‘ (ë¹„ë™ê¸° ì²˜ë¦¬) ===")
        
        # ì…ë ¥ íŒŒì‹±
        qa_map = self._parse_input_text_to_qa_map(raw_user_input)
        if not qa_map:
            self.logger.error("íŒŒì‹±ëœ ì§ˆë¬¸-ë‹µë³€ì´ ì—†ì–´ ì½˜í…ì¸  ìƒì„±ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
            return json.dumps({"error": "No valid Q&A pairs found in input."})

        # 1ë‹¨ê³„ì™€ 2ë‹¨ê³„: ì¸í„°ë·°ì™€ ì—ì„¸ì´ í˜•ì‹ ë³‘ë ¬ ì²˜ë¦¬
        print("1-2ë‹¨ê³„: ì¸í„°ë·°ì™€ ì—ì„¸ì´ í˜•ì‹ ì½˜í…ì¸  ë³‘ë ¬ ìƒì„± (ë¹„ë™ê¸°)")
        
        # ë³‘ë ¬ ì²˜ë¦¬
        interview_task = self._process_interview_async(qa_map)
        essay_task = self._process_essay_async(qa_map)
        image_task = self._process_image_analysis_async(image_analysis_results)
        
        interview_results, essay_results, image_info = await asyncio.gather(
            interview_task, essay_task, image_task
        )
        
        # ì´ë¯¸ì§€-í…ìŠ¤íŠ¸ ì˜ë¯¸ì  ì—°ê²° ë¶„ì„
        print("2.5ë‹¨ê³„: ì´ë¯¸ì§€-í…ìŠ¤íŠ¸ ì˜ë¯¸ì  ì—°ê²° ë¶„ì„ (ë¹„ë™ê¸°)")
        semantic_connections = await self._analyze_image_text_semantic_connections_async(
            interview_results, essay_results, image_analysis_results
        )
        
        # ì½˜í…ì¸  í™œìš© ê²€ì¦
        await self._verify_content_completeness_async(interview_results, essay_results, qa_map)
        
        # ìƒˆë¡œìš´ 3ë‹¨ê³„: ì½˜í…ì¸  ë¶„ì„ ë° êµ¬ì¡° ì„¤ê³„
        print("3ë‹¨ê³„: ì½˜í…ì¸  ë¶„ì„ ë° êµ¬ì¡° ì„¤ê³„ (ë™ì  ì„¹ì…˜ ê²°ì •)")
        structure_plan = await self.content_planner.analyze_and_plan_structure(
            interview_results, essay_results, image_analysis_results
        )
        
        # ìƒˆë¡œìš´ 4ë‹¨ê³„: ì„¹ì…˜ë³„ ì½˜í…ì¸  ìƒì„±
        print("4ë‹¨ê³„: ì„¹ì…˜ë³„ ì½˜í…ì¸  ìƒì„±")
        sections_with_content = await self._generate_section_content(
            structure_plan, interview_results, essay_results, image_info, semantic_connections
        )
        
        # ìƒˆë¡œìš´ 5ë‹¨ê³„: ì½˜í…ì¸  ë¶„ëŸ‰ ê²€í†  ë° ì§€ëŠ¥ì  ë¶„í• 
        print("5ë‹¨ê³„: ì½˜í…ì¸  ë¶„ëŸ‰ ê²€í†  ë° ì§€ëŠ¥ì  ë¶„í• ")
        refined_sections = await self.content_refiner.refine_content(sections_with_content)
        
        # ìµœì¢… ë§¤ê±°ì§„ ì½˜í…ì¸  ì¡°í•©
        final_content = self._assemble_final_magazine_content(
            structure_plan, refined_sections
        )
        
        # ìµœì¢… í†µí•© ì½˜í…ì¸  ìƒì„± ë¡œê¹…
        await self._log_final_content_async(
            final_content, interview_results, essay_results, image_analysis_results, qa_map, semantic_connections
        )
        
        print(f"ğŸ“ ContentCreatorV2 (ì²« ë²ˆì§¸ ì—ì´ì „íŠ¸) ë¡œê·¸ ìˆ˜ì§‘ ì™„ë£Œ (ë¹„ë™ê¸°)")
        print(f"âœ… í›„ì† ì—ì´ì „íŠ¸ë“¤ì„ ìœ„í•œ ê¸°ì´ˆ ë°ì´í„° ìƒì„± ì™„ë£Œ: {len(final_content)}ì")
        return final_content

    async def _analyze_image_text_semantic_connections_async(self, interview_results: Dict[str, str], 
                                                           essay_results: Dict[str, str], 
                                                           image_analysis_results: List[Dict]) -> Dict:
        """ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ ê°„ì˜ ì˜ë¯¸ì  ì—°ê²° ë¶„ì„ (ë¹„ë™ê¸°)"""
        return await asyncio.get_event_loop().run_in_executor(
            None, self._analyze_image_text_semantic_connections, 
            interview_results, essay_results, image_analysis_results
        )

    def _analyze_image_text_semantic_connections(self, interview_results: Dict[str, str], 
                                               essay_results: Dict[str, str], 
                                               image_analysis_results: List[Dict]) -> Dict:
        """ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ ê°„ì˜ ì˜ë¯¸ì  ì—°ê²° ë¶„ì„"""
        print("ğŸ”— ì´ë¯¸ì§€-í…ìŠ¤íŠ¸ ì˜ë¯¸ì  ì—°ê²° ë¶„ì„ ì‹œì‘")
        
        semantic_connections = {
            "visual_keywords": [],
            "emotional_tone_matches": [],
            "narrative_flow_connections": [],
            "thematic_alignments": [],
            "sensory_descriptions": []
        }
        
        # ëª¨ë“  í…ìŠ¤íŠ¸ ì½˜í…ì¸  í†µí•©
        all_text_content = {}
        all_text_content.update(interview_results)
        all_text_content.update(essay_results)
        
        # ì´ë¯¸ì§€ë³„ ì˜ë¯¸ì  ì—°ê²°ì  ë¶„ì„
        for img_idx, image_data in enumerate(image_analysis_results):
            image_location = image_data.get('location', f'ì´ë¯¸ì§€_{img_idx}')
            image_description = image_data.get('description', '')
            
            # 1. ì‹œê°ì  í‚¤ì›Œë“œ ì¶”ì¶œ
            visual_keywords = self._extract_visual_keywords_from_image(image_data)
            
            # 2. í…ìŠ¤íŠ¸ì—ì„œ í•´ë‹¹ ì´ë¯¸ì§€ì™€ ì—°ê²° ê°€ëŠ¥í•œ ë¶€ë¶„ ì°¾ê¸°
            for section_key, text_content in all_text_content.items():
                # ê°ì •ì  í†¤ ë§¤ì¹­
                emotional_match = self._analyze_emotional_tone_match(text_content, image_data)
                if emotional_match['score'] > 0.6:
                    semantic_connections["emotional_tone_matches"].append({
                        "image_index": img_idx,
                        "text_section": section_key,
                        "match_score": emotional_match['score'],
                        "shared_emotions": emotional_match['emotions']
                    })
                
                # ì£¼ì œì  ì—°ê²°ì„± ë¶„ì„
                thematic_alignment = self._analyze_thematic_alignment(text_content, image_data)
                if thematic_alignment['score'] > 0.5:
                    semantic_connections["thematic_alignments"].append({
                        "image_index": img_idx,
                        "text_section": section_key,
                        "alignment_score": thematic_alignment['score'],
                        "shared_themes": thematic_alignment['themes']
                    })
                
                # ê°ê°ì  ë¬˜ì‚¬ ì—°ê²°
                sensory_connections = self._find_sensory_connections(text_content, image_data)
                if sensory_connections:
                    semantic_connections["sensory_descriptions"].extend(sensory_connections)
        
        # ë‚´ëŸ¬í‹°ë¸Œ í”Œë¡œìš° ì—°ê²°ì„± ë¶„ì„
        narrative_connections = self._analyze_narrative_flow_connections(all_text_content, image_analysis_results)
        semantic_connections["narrative_flow_connections"] = narrative_connections
        
        print(f"âœ… ì˜ë¯¸ì  ì—°ê²° ë¶„ì„ ì™„ë£Œ: {len(semantic_connections['emotional_tone_matches'])}ê°œ ê°ì • ë§¤ì¹­, "
              f"{len(semantic_connections['thematic_alignments'])}ê°œ ì£¼ì œ ì—°ê²°")
        
        return semantic_connections

    def _extract_visual_keywords_from_image(self, image_data: Dict) -> List[str]:
        """ì´ë¯¸ì§€ì—ì„œ ì‹œê°ì  í‚¤ì›Œë“œ ì¶”ì¶œ"""
        keywords = []
        
        # ìœ„ì¹˜ ì •ë³´ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
        location = image_data.get('location', '')
        if location:
            keywords.extend([word.strip() for word in location.split(',') if word.strip()])
        
        # ì„¤ëª…ì—ì„œ ì‹œê°ì  ìš”ì†Œ ì¶”ì¶œ
        description = image_data.get('description', '')
        visual_terms = ['ìƒ‰ìƒ', 'ë¹›', 'ê·¸ë¦¼ì', 'í’ê²½', 'ê±´ë¬¼', 'ì‚¬ëŒ', 'í•˜ëŠ˜', 'ë°”ë‹¤', 'ì‚°', 'ë„ì‹œ', 'ìì—°']
        for term in visual_terms:
            if term in description:
                keywords.append(term)
        
        return list(set(keywords))

    def _analyze_emotional_tone_match(self, text_content: str, image_data: Dict) -> Dict:
        """í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ì˜ ê°ì •ì  í†¤ ë§¤ì¹­ ë¶„ì„"""
        # í…ìŠ¤íŠ¸ì—ì„œ ê°ì • í‚¤ì›Œë“œ ì¶”ì¶œ
        positive_emotions = ['ì•„ë¦„ë‹¤ìš´', 'í–‰ë³µí•œ', 'ì¦ê±°ìš´', 'í‰í™”ë¡œìš´', 'ê°ë™ì ì¸', 'ë”°ëœ»í•œ', 'ë°ì€']
        negative_emotions = ['ìŠ¬í”ˆ', 'ì–´ë‘ìš´', 'ì°¨ê°€ìš´', 'ì™¸ë¡œìš´', 'ë¬´ì„œìš´']
        neutral_emotions = ['ì¡°ìš©í•œ', 'ê³ ìš”í•œ', 'ë‹¨ìˆœí•œ', 'ê¹”ë”í•œ']
        
        text_emotions = []
        for emotion in positive_emotions:
            if emotion in text_content:
                text_emotions.append(('positive', emotion))
        for emotion in negative_emotions:
            if emotion in text_content:
                text_emotions.append(('negative', emotion))
        for emotion in neutral_emotions:
            if emotion in text_content:
                text_emotions.append(('neutral', emotion))
        
        # ì´ë¯¸ì§€ ì„¤ëª…ì—ì„œ ê°ì • ì¶”ì¶œ
        image_description = image_data.get('description', '')
        image_emotions = []
        for emotion in positive_emotions:
            if emotion in image_description:
                image_emotions.append(('positive', emotion))
        for emotion in negative_emotions:
            if emotion in image_description:
                image_emotions.append(('negative', emotion))
        for emotion in neutral_emotions:
            if emotion in image_description:
                image_emotions.append(('neutral', emotion))
        
        # ë§¤ì¹­ ì ìˆ˜ ê³„ì‚°
        shared_emotions = []
        for text_emotion in text_emotions:
            for image_emotion in image_emotions:
                if text_emotion[0] == image_emotion[0]:  # ê°™ì€ ê°ì • ì¹´í…Œê³ ë¦¬
                    shared_emotions.append(text_emotion[1])
        
        match_score = len(shared_emotions) / max(len(text_emotions), len(image_emotions), 1)
        
        return {
            'score': match_score,
            'emotions': shared_emotions
        }

    def _analyze_thematic_alignment(self, text_content: str, image_data: Dict) -> Dict:
        """í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ì˜ ì£¼ì œì  ì—°ê²°ì„± ë¶„ì„"""
        # ì£¼ìš” í…Œë§ˆ í‚¤ì›Œë“œ
        themes = {
            'nature': ['ìì—°', 'ì‚°', 'ë°”ë‹¤', 'í•˜ëŠ˜', 'ë‚˜ë¬´', 'ê½ƒ', 'í’ê²½'],
            'culture': ['ë¬¸í™”', 'ì „í†µ', 'ì—­ì‚¬', 'ì˜ˆìˆ ', 'ìŒì‹', 'ì¶•ì œ'],
            'urban': ['ë„ì‹œ', 'ê±´ë¬¼', 'ê±°ë¦¬', 'ì¹´í˜', 'ìƒì ', 'êµí†µ'],
            'people': ['ì‚¬ëŒ', 'í˜„ì§€ì¸', 'ì—¬í–‰ì', 'ê°€ì¡±', 'ì¹œêµ¬', 'ë§Œë‚¨'],
            'activity': ['í™œë™', 'ì²´í—˜', 'ê±·ê¸°', 'êµ¬ê²½', 'ì‡¼í•‘', 'ì‹ì‚¬']
        }
        
        text_themes = []
        image_themes = []
        
        # í…ìŠ¤íŠ¸ì—ì„œ í…Œë§ˆ ì¶”ì¶œ
        for theme_name, keywords in themes.items():
            for keyword in keywords:
                if keyword in text_content:
                    text_themes.append(theme_name)
                    break
        
        # ì´ë¯¸ì§€ì—ì„œ í…Œë§ˆ ì¶”ì¶œ
        image_location = image_data.get('location', '')
        image_description = image_data.get('description', '')
        image_text = f"{image_location} {image_description}"
        
        for theme_name, keywords in themes.items():
            for keyword in keywords:
                if keyword in image_text:
                    image_themes.append(theme_name)
                    break
        
        # ê³µí†µ í…Œë§ˆ ì°¾ê¸°
        shared_themes = list(set(text_themes) & set(image_themes))
        alignment_score = len(shared_themes) / max(len(text_themes), len(image_themes), 1)
        
        return {
            'score': alignment_score,
            'themes': shared_themes
        }

    def _find_sensory_connections(self, text_content: str, image_data: Dict) -> List[Dict]:
        """ê°ê°ì  ë¬˜ì‚¬ ì—°ê²°ì  ì°¾ê¸°"""
        sensory_connections = []
        
        # ì‹œê°ì  ê°ê° ì—°ê²°
        visual_descriptors = ['ë³´ì´ëŠ”', 'ëˆˆì— ë„ëŠ”', 'í™”ë ¤í•œ', 'ì„ ëª…í•œ', 'íë¦¿í•œ', 'ë°ì€', 'ì–´ë‘ìš´']
        for descriptor in visual_descriptors:
            if descriptor in text_content:
                sensory_connections.append({
                    'type': 'visual',
                    'text_descriptor': descriptor,
                    'image_relevance': 'high'
                })
        
        # ê³µê°„ì  ê°ê° ì—°ê²°
        spatial_descriptors = ['ë„“ì€', 'ì¢ì€', 'ë†’ì€', 'ë‚®ì€', 'ê°€ê¹Œìš´', 'ë¨¼', 'í°', 'ì‘ì€']
        for descriptor in spatial_descriptors:
            if descriptor in text_content:
                sensory_connections.append({
                    'type': 'spatial',
                    'text_descriptor': descriptor,
                    'image_relevance': 'medium'
                })
        
        return sensory_connections

    def _analyze_narrative_flow_connections(self, all_text_content: Dict, image_analysis_results: List[Dict]) -> List[Dict]:
        """ë‚´ëŸ¬í‹°ë¸Œ í”Œë¡œìš°ì™€ ì´ë¯¸ì§€ ì‹œí€€ìŠ¤ ì—°ê²°ì„± ë¶„ì„"""
        narrative_connections = []
        
        # í…ìŠ¤íŠ¸ ì„¹ì…˜ë“¤ì„ ì‹œê°„ìˆœ/ë…¼ë¦¬ìˆœìœ¼ë¡œ ì •ë ¬ (í‚¤ ì´ë¦„ ê¸°ì¤€)
        sorted_sections = sorted(all_text_content.items())
        
        # ê° ì„¹ì…˜ì— ëŒ€í•´ ìµœì ì˜ ì´ë¯¸ì§€ ë§¤ì¹­
        for idx, (section_key, text_content) in enumerate(sorted_sections):
            # í•´ë‹¹ ì„¹ì…˜ì˜ ë‚´ìš©ê³¼ ê°€ì¥ ì˜ ë§ëŠ” ì´ë¯¸ì§€ë“¤ ì°¾ê¸°
            best_matches = []
            
            for img_idx, image_data in enumerate(image_analysis_results):
                # ìœ„ì¹˜ ê¸°ë°˜ ë§¤ì¹­
                location_match = self._calculate_location_relevance(text_content, image_data)
                
                # ë‚´ìš© ê¸°ë°˜ ë§¤ì¹­
                content_match = self._calculate_content_relevance(text_content, image_data)
                
                total_score = (location_match + content_match) / 2
                
                if total_score > 0.3:  # ì„ê³„ê°’ ì´ìƒì¸ ê²½ìš°ë§Œ
                    best_matches.append({
                        'image_index': img_idx,
                        'relevance_score': total_score,
                        'location_score': location_match,
                        'content_score': content_match
                    })
            
            # ì ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬
            best_matches.sort(key=lambda x: x['relevance_score'], reverse=True)
            
            narrative_connections.append({
                'section_key': section_key,
                'section_order': idx,
                'recommended_images': best_matches[:3]  # ìƒìœ„ 3ê°œë§Œ
            })
        
        return narrative_connections

    def _calculate_location_relevance(self, text_content: str, image_data: Dict) -> float:
        """ìœ„ì¹˜ ê¸°ë°˜ ì—°ê´€ì„± ê³„ì‚°"""
        image_location = image_data.get('location', '').lower()
        text_lower = text_content.lower()
        
        if not image_location:
            return 0.0
        
        # ìœ„ì¹˜ í‚¤ì›Œë“œê°€ í…ìŠ¤íŠ¸ì— í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
        location_words = [word.strip() for word in image_location.split(',')]
        matches = sum(1 for word in location_words if word and word in text_lower)
        
        return matches / max(len(location_words), 1)

    def _calculate_content_relevance(self, text_content: str, image_data: Dict) -> float:
        """ë‚´ìš© ê¸°ë°˜ ì—°ê´€ì„± ê³„ì‚°"""
        image_description = image_data.get('description', '').lower()
        text_lower = text_content.lower()
        
        if not image_description:
            return 0.0
        
        # ê³µí†µ í‚¤ì›Œë“œ ì°¾ê¸°
        description_words = set(image_description.split())
        text_words = set(text_lower.split())
        
        common_words = description_words & text_words
        total_words = description_words | text_words
        
        return len(common_words) / max(len(total_words), 1)

    async def _process_interview_async(self, qa_map: Dict[str, str]) -> Dict[str, str]:
        """ì¸í„°ë·° í˜•ì‹ ì²˜ë¦¬ (ë¹„ë™ê¸°)"""
        return await asyncio.get_event_loop().run_in_executor(
            None, self.interview_manager.process_all_interviews, qa_map
        )

    async def _process_essay_async(self, qa_map: Dict[str, str]) -> Dict[str, str]:
        """ì—ì„¸ì´ í˜•ì‹ ì²˜ë¦¬ (ë¹„ë™ê¸°)"""
        return await asyncio.get_event_loop().run_in_executor(
            None, self.essay_manager.run_all, qa_map
        )

    async def _process_image_analysis_async(self, image_analysis_results: List[Dict]) -> str:
        """ì´ë¯¸ì§€ ë¶„ì„ ì²˜ë¦¬ (ë¹„ë™ê¸°)"""
        return await asyncio.get_event_loop().run_in_executor(
            None, self._process_image_analysis, image_analysis_results
        )

    async def _log_interview_results_async(self, texts: List[str], interview_results: Dict[str, str]):
        """ì¸í„°ë·° ì²˜ë¦¬ ê²°ê³¼ ë¡œê¹… (ë¹„ë™ê¸°)"""
        await asyncio.get_event_loop().run_in_executor(
            None,
            lambda: self.logger.log_agent_real_output(
                agent_name="ContentCreatorV2Agent_Interview",
                agent_role="ì¸í„°ë·° ì½˜í…ì¸  ì²˜ë¦¬ì",
                task_description=f"{len(texts)}ê°œ í…ìŠ¤íŠ¸ë¥¼ ì¸í„°ë·° í˜•ì‹ìœ¼ë¡œ ì²˜ë¦¬",
                final_answer=f"ì¸í„°ë·° í˜•ì‹ ì½˜í…ì¸  {len(interview_results)}ê°œ ìƒì„± ì™„ë£Œ",
                reasoning_process="ì›ë³¸ í…ìŠ¤íŠ¸ë¥¼ ì¸í„°ë·° í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ëŒ€í™”ì²´ ì½˜í…ì¸  ìƒì„±",
                execution_steps=[
                    "ì›ë³¸ í…ìŠ¤íŠ¸ ë¶„ì„",
                    "ì¸í„°ë·° í˜•ì‹ ë³€í™˜",
                    "ëŒ€í™”ì²´ ì½˜í…ì¸  ìƒì„±",
                    "í’ˆì§ˆ ê²€ì¦"
                ],
                raw_input={"texts": texts, "texts_count": len(texts)},
                raw_output=interview_results,
                performance_metrics={
                    "interview_results_count": len(interview_results),
                    "total_interview_length": sum(len(content) for content in interview_results.values()),
                    "processing_success": True,
                    "async_processing": True
                }
            )
        )

    async def _log_essay_results_async(self, texts: List[str], essay_results: Dict[str, str]):
        """ì—ì„¸ì´ ì²˜ë¦¬ ê²°ê³¼ ë¡œê¹… (ë¹„ë™ê¸°)"""
        await asyncio.get_event_loop().run_in_executor(
            None,
            lambda: self.logger.log_agent_real_output(
                agent_name="ContentCreatorV2Agent_Essay",
                agent_role="ì—ì„¸ì´ ì½˜í…ì¸  ì²˜ë¦¬ì",
                task_description=f"{len(texts)}ê°œ í…ìŠ¤íŠ¸ë¥¼ ì—ì„¸ì´ í˜•ì‹ìœ¼ë¡œ ì²˜ë¦¬",
                final_answer=f"ì—ì„¸ì´ í˜•ì‹ ì½˜í…ì¸  {len(essay_results)}ê°œ ìƒì„± ì™„ë£Œ",
                reasoning_process="ì›ë³¸ í…ìŠ¤íŠ¸ë¥¼ ì—ì„¸ì´ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì„±ì°°ì  ì½˜í…ì¸  ìƒì„±",
                execution_steps=[
                    "ì›ë³¸ í…ìŠ¤íŠ¸ ë¶„ì„",
                    "ì—ì„¸ì´ í˜•ì‹ ë³€í™˜",
                    "ì„±ì°°ì  ì½˜í…ì¸  ìƒì„±",
                    "í’ˆì§ˆ ê²€ì¦"
                ],
                raw_input={"texts": texts, "texts_count": len(texts)},
                raw_output=essay_results,
                performance_metrics={
                    "essay_results_count": len(essay_results),
                    "total_essay_length": sum(len(content) for content in essay_results.values()),
                    "processing_success": True,
                    "async_processing": True
                }
            )
        )

    async def _log_image_processing_async(self, image_analysis_results: List[Dict], image_info: str):
        """ì´ë¯¸ì§€ ì •ë³´ ì²˜ë¦¬ ë¡œê¹… (ë¹„ë™ê¸°)"""
        await asyncio.get_event_loop().run_in_executor(
            None,
            lambda: self.logger.log_agent_real_output(
                agent_name="ContentCreatorV2Agent_ImageProcessor",
                agent_role="ì´ë¯¸ì§€ ì •ë³´ ì²˜ë¦¬ì",
                task_description=f"{len(image_analysis_results)}ê°œ ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼ ì²˜ë¦¬",
                final_answer=f"ì´ë¯¸ì§€ ì •ë³´ ì •ë¦¬ ì™„ë£Œ: {len(image_info)}ì",
                reasoning_process="ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼ë¥¼ í…ìŠ¤íŠ¸ ì½˜í…ì¸ ì™€ ì—°ê³„ ê°€ëŠ¥í•œ í˜•íƒœë¡œ ì •ë¦¬",
                execution_steps=[
                    "ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼ ìˆ˜ì§‘",
                    "ìœ„ì¹˜ ì •ë³´ ì¶”ì¶œ",
                    "ì„¤ëª… ì •ë³´ ì •ë¦¬",
                    "í…ìŠ¤íŠ¸ ì—°ê³„ í¬ë§· ìƒì„±"
                ],
                raw_input=image_analysis_results,
                raw_output=image_info,
                performance_metrics={
                    "images_processed": len(image_analysis_results),
                    "image_info_length": len(image_info),
                    "processing_success": True,
                    "async_processing": True
                }
            )
        )

    async def _generate_section_content(self, structure_plan: Dict, interview_results: Dict[str, str], 
                                  essay_results: Dict[str, str], image_info: str, 
                                  semantic_connections: Dict) -> List[Dict]:
        """êµ¬ì¡° ê³„íšì— ë”°ë¼ ê° ì„¹ì…˜ì˜ ì½˜í…ì¸  ìƒì„± (ê¸¸ì´ ì œí•œ ì¶”ê°€)"""
        
        sections = structure_plan.get('sections', [])
        self.logger.info(f"{len(sections)}ê°œ ì„¹ì…˜ì— ëŒ€í•œ ì½˜í…ì¸  ìƒì„± ì‹œì‘")
        
        # âœ… ì „ì²´ ì½˜í…ì¸  ê¸¸ì´ ì œí•œ ì„¤ì •
        MAX_TOTAL_CONTENT_LENGTH = 15000
        target_length_per_section = MAX_TOTAL_CONTENT_LENGTH // len(sections) if sections else 1000
        
        # ëª¨ë“  ì¸í„°ë·° ì½˜í…ì¸  ì •ë¦¬
        interview_content = "\n\n".join([f"=== {key} ===\n{value}" for key, value in interview_results.items()])
        
        # ëª¨ë“  ì—ì„¸ì´ ì½˜í…ì¸  ì •ë¦¬
        essay_content = "\n\n".join([f"=== {key} ===\n{value}" for key, value in essay_results.items()])
        
        # ì˜ë¯¸ì  ì—°ê²° ì •ë³´ í¬ë§·íŒ…
        semantic_info = self._format_semantic_connections_for_prompt(semantic_connections)
        
        sections_with_content = []
        agent = self.create_agent()
        
        # ê° ì„¹ì…˜ë³„ë¡œ ì½˜í…ì¸  ìƒì„±
        for section in sections:
            section_id = section.get('section_id', '0')
            title = section.get('title', '')
            subtitle = section.get('subtitle', '')
            summary = section.get('summary', '')
            
            self.logger.info(f"ì„¹ì…˜ {section_id}: '{title}' ì½˜í…ì¸  ìƒì„± ì¤‘ (ëª©í‘œ ê¸¸ì´: {target_length_per_section}ì)")
            
            # âœ… ê¸¸ì´ ì œí•œì´ í¬í•¨ëœ ì„¹ì…˜ë³„ ì½˜í…ì¸  ìƒì„± íƒœìŠ¤í¬
            section_task = Task(
                description=f"""
    **ì„¹ì…˜ {section_id} ì½˜í…ì¸  ìƒì„± (ê¸¸ì´ ì œí•œ ì ìš©)**

    ë‹¹ì‹ ì€ ì—¬í–‰ ë§¤ê±°ì§„ì˜ í•œ ì„¹ì…˜ì„ ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤. **ì¤‘ìš”: ì´ ì„¹ì…˜ì˜ ë³¸ë¬¸ì€ ë°˜ë“œì‹œ {target_length_per_section}ì ì´ë‚´ë¡œ ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤.**

    **ì„¹ì…˜ ì •ë³´:**
    - ì œëª©: {title}
    - ë¶€ì œëª©: {subtitle}
    - ìš”ì•½: {summary}
    - **ëª©í‘œ ê¸¸ì´: {target_length_per_section}ì ì´ë‚´ (ì—„ê²©í•œ ì œí•œ)**

    **í™œìš©í•  ì½˜í…ì¸ :**
    1. ì¸í„°ë·° í˜•ì‹ ì½˜í…ì¸ :
    {interview_content[:1500]}... (ìƒëµ)

    2. ì—ì„¸ì´ í˜•ì‹ ì½˜í…ì¸ :
    {essay_content[:1500]}... (ìƒëµ)

    3. ì´ë¯¸ì§€ ì •ë³´:
    {image_info[:300]}... (ìƒëµ)

    4. ì´ë¯¸ì§€-í…ìŠ¤íŠ¸ ì˜ë¯¸ì  ì—°ê²°:
    {semantic_info[:300]}... (ìƒëµ)

    **ì‘ì—… ì§€ì‹œ:**
    1. **ê¸¸ì´ ì œí•œ ì¤€ìˆ˜**: ë³¸ë¬¸ì€ ë°˜ë“œì‹œ {target_length_per_section}ì ì´ë‚´ë¡œ ì‘ì„±í•˜ì„¸ìš”.
    2. **ê°„ê²°í•˜ê³  í•µì‹¬ì ì¸ ë‚´ìš©**: ì œí•œëœ ê¸¸ì´ ë‚´ì—ì„œ ê°€ì¥ ì¤‘ìš”í•œ ë‚´ìš©ë§Œ ì„ ë³„í•˜ì—¬ í¬í•¨í•˜ì„¸ìš”.
    3. **ì™„ê²°ì„± ìœ ì§€**: ì§§ë”ë¼ë„ ì™„ì „í•œ ì´ì•¼ê¸° êµ¬ì¡°ë¥¼ ê°–ì¶”ì–´ì•¼ í•©ë‹ˆë‹¤.
    4. **í’ˆì§ˆ ìš°ì„ **: ê¸¸ì´ë¥¼ ë§ì¶”ê¸° ìœ„í•´ ë‚´ìš©ì˜ ì§ˆì„ ë–¨ì–´ëœ¨ë¦¬ì§€ ë§ˆì„¸ìš”.
    5. **ìì—°ìŠ¤ëŸ¬ìš´ ë§ˆë¬´ë¦¬**: ì§€ì •ëœ ê¸¸ì´ ë‚´ì—ì„œ ìì—°ìŠ¤ëŸ½ê²Œ ë§ˆë¬´ë¦¬ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.

    **ì¶œë ¥ í˜•ì‹:**
    ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•˜ì„¸ìš”. ë‹¤ë¥¸ ì„¤ëª…ì´ë‚˜ ì£¼ì„ì€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.

    {{
    "section_id": "{section_id}",
    "title": "{title}",
    "subtitle": "{subtitle}",
    "body": "ì´ ì„¹ì…˜ì˜ ë³¸ë¬¸ ë‚´ìš©... (ë°˜ë“œì‹œ {target_length_per_section}ì ì´ë‚´)"
    }}

    text

    **ì¤‘ìš” ì§€ì¹¨:**
    - **ì ˆëŒ€ì  ê¸¸ì´ ì œí•œ**: {target_length_per_section}ìë¥¼ ì´ˆê³¼í•˜ì§€ ë§ˆì„¸ìš”.
    - **í•µì‹¬ ë‚´ìš© ìš°ì„ **: ê°€ì¥ ì¤‘ìš”í•˜ê³  í¥ë¯¸ë¡œìš´ ë¶€ë¶„ë§Œ ì„ ë³„í•˜ì„¸ìš”.
    - **ì™„ì „í•œ ë¬¸ì¥**: ëª¨ë“  ë¬¸ì¥ì€ ì™„ì „í•œ í˜•íƒœì—¬ì•¼ í•©ë‹ˆë‹¤.
    - **ìì—°ìŠ¤ëŸ¬ìš´ íë¦„**: ì§§ì•„ë„ ì½ê¸° ìì—°ìŠ¤ëŸ¬ì›Œì•¼ í•©ë‹ˆë‹¤.
    """,
                agent=agent,
                expected_output=f"ì„¹ì…˜ {section_id} '{title}'ì— ëŒ€í•œ {target_length_per_section}ì ì´ë‚´ì˜ JSON í˜•ì‹ ì½˜í…ì¸ "
            )
            
            # ë¹„ë™ê¸° íƒœìŠ¤í¬ ì‹¤í–‰
            response = await asyncio.get_event_loop().run_in_executor(
                None, agent.execute_task, section_task
            )
            
            # JSON ì‘ë‹µ ì¶”ì¶œ ë° íŒŒì‹±
            import json
            import re
            
            # JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ
            json_match = re.search(r'``````', str(response), re.DOTALL)
            if json_match:
                json_str = json_match.group(1)
            else:
                json_str = str(response)
            
            # ë¶ˆí•„ìš”í•œ ë§ˆí¬ë‹¤ìš´ì´ë‚˜ ì„¤ëª… ì œê±°
            json_str = re.sub(r'``````', '', json_str).strip()
            
            try:
                # JSON íŒŒì‹±
                section_content = json.loads(json_str)
                
                # âœ… ê¸¸ì´ ê²€ì¦ ë° ì¡°ì •
                body_content = section_content.get('body', '')
                if len(body_content) > target_length_per_section:
                    # ê¸¸ì´ ì´ˆê³¼ ì‹œ ìë™ ì¡°ì •
                    truncated_body = body_content[:target_length_per_section-10] + "..."
                    section_content['body'] = truncated_body
                    self.logger.warning(f"ì„¹ì…˜ {section_id} ê¸¸ì´ ì´ˆê³¼ë¡œ ìë™ ì¡°ì •: {len(body_content)}ì â†’ {len(truncated_body)}ì")
                
                sections_with_content.append(section_content)
                self.logger.info(f"ì„¹ì…˜ {section_id}: '{title}' ì½˜í…ì¸  ìƒì„± ì™„ë£Œ ({len(section_content.get('body', ''))}ì)")
                
            except Exception as e:
                self.logger.error(f"ì„¹ì…˜ {section_id} ì½˜í…ì¸  íŒŒì‹± ì‹¤íŒ¨: {e}")
                # ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ì½˜í…ì¸  ìƒì„± (ê¸¸ì´ ì œí•œ ì ìš©)
                fallback_body = f"ì´ ì„¹ì…˜ì—ì„œëŠ” {summary} ë‚´ìš©ì„ ë‹¤ë£¹ë‹ˆë‹¤."
                if len(fallback_body) > target_length_per_section:
                    fallback_body = fallback_body[:target_length_per_section-3] + "..."
                
                sections_with_content.append({
                    "section_id": section_id,
                    "title": title,
                    "subtitle": subtitle,
                    "body": fallback_body
                })
        
        return sections_with_content

    def _assemble_final_magazine_content(self, structure_plan: Dict, sections: List[Dict]) -> str:
        """ìµœì¢… ë§¤ê±°ì§„ ì½˜í…ì¸  ì¡°í•©"""

        def sort_key(section: Dict) -> Tuple[int, int]:
            """ì„¹ì…˜ ë° í•˜ìœ„ ì„¹ì…˜ì„ ì˜¬ë°”ë¥´ê²Œ ì •ë ¬í•˜ê¸° ìœ„í•œ í‚¤ í•¨ìˆ˜"""
            # í•˜ìœ„ ì„¹ì…˜ì¸ ê²½ìš° (e.g., "1-1")
            sub_section_id = section.get('sub_section_id')
            if sub_section_id and '-' in str(sub_section_id):
                try:
                    parts = str(sub_section_id).split('-', 1)
                    parent_id = int(parts[0])
                    sub_id = int(parts[1])
                    return (parent_id, sub_id)
                except (ValueError, IndexError):
                    return (999, 999)  # Fallback for malformed IDs

            # ì¼ë°˜ ì„¹ì…˜ì¸ ê²½ìš° (e.g., "1")
            section_id = section.get('section_id')
            if section_id:
                try:
                    # section_idê°€ ìˆ«ìê°€ ì•„ë‹ ìˆ˜ ìˆëŠ” ê²½ìš°ë¥¼ ëŒ€ë¹„
                    return (int(section_id), 0)
                except (ValueError, TypeError):
                    return (999, 0)  # Fallback for malformed IDs
            
            # IDê°€ ì—†ëŠ” ì˜ˆì™¸ ì¼€ì´ìŠ¤
            return (999, 999)

        # ì„¹ì…˜ì„ ID ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
        sections.sort(key=sort_key)
        
        # ìµœì¢… ë§¤ê±°ì§„ ì½˜í…ì¸  êµ¬ì¡° ìƒì„±
        magazine_content = {
            "magazine_title": structure_plan.get('proposed_title', 'ì—¬í–‰ ê²½í—˜'),
            "magazine_subtitle": structure_plan.get('proposed_subtitle', 'íŠ¹ë³„í•œ ìˆœê°„ë“¤'),
            "sections": []
        }
        
        # ì„¹ì…˜ ì •ë³´ ì¶”ê°€
        for section in sections:
            # í•˜ìœ„ ì„¹ì…˜ì¸ ê²½ìš° (sub_section_idê°€ ìˆëŠ” ê²½ìš°)
            if 'sub_section_id' in section:
                parent_id = section.get('parent_section_id', '')
                
                # ì´ë¯¸ ë¶€ëª¨ ì„¹ì…˜ì´ ì¶”ê°€ë˜ì—ˆëŠ”ì§€ í™•ì¸
                parent_found = False
                for i, existing_section in enumerate(magazine_content['sections']):
                    if existing_section.get('section_id') == parent_id:
                        # ë¶€ëª¨ ì„¹ì…˜ì´ ìˆìœ¼ë©´ í•˜ìœ„ ì„¹ì…˜ ë°°ì—´ í™•ì¸
                        if 'sub_sections' not in existing_section:
                            existing_section['sub_sections'] = []
                        
                        # í•˜ìœ„ ì„¹ì…˜ ì¶”ê°€
                        existing_section['sub_sections'].append({
                            "sub_section_id": section.get('sub_section_id', ''),
                            "title": section.get('title', ''),
                            "subtitle": section.get('subtitle', ''),
                            "body": section.get('body', '')
                        })
                        parent_found = True
                        break
                
                # ë¶€ëª¨ ì„¹ì…˜ì´ ì•„ì§ ì¶”ê°€ë˜ì§€ ì•Šì•˜ìœ¼ë©´ ì„ì‹œ ë¶€ëª¨ ì„¹ì…˜ ìƒì„±
                if not parent_found:
                    magazine_content['sections'].append({
                        "section_id": parent_id,
                        "title": section.get('parent_section_title', f"ì„¹ì…˜ {parent_id}"),
                        "subtitle": "",
                        "sub_sections": [{
                            "sub_section_id": section.get('sub_section_id', ''),
                            "title": section.get('title', ''),
                            "subtitle": section.get('subtitle', ''),
                            "body": section.get('body', '')
                        }]
                    })
            else:
                # ì¼ë°˜ ì„¹ì…˜ì¸ ê²½ìš°
                magazine_content['sections'].append({
                    "section_id": section.get('section_id', ''),
                    "title": section.get('title', ''),
                    "subtitle": section.get('subtitle', ''),
                    "body": section.get('body', '')
                })
        
        # ì„¹ì…˜ ìˆ˜ ì¶”ê°€
        magazine_content['total_sections'] = len(magazine_content['sections'])
        
        # JSON ë¬¸ìì—´ë¡œ ë³€í™˜
        import json
        return json.dumps(magazine_content, ensure_ascii=False)

    def _format_semantic_connections_for_prompt(self, semantic_connections: Dict) -> str:
        """ì˜ë¯¸ì  ì—°ê²° ì •ë³´ë¥¼ í”„ë¡¬í”„íŠ¸ìš©ìœ¼ë¡œ í¬ë§·íŒ…"""
        formatted_info = []
        
        # ê°ì •ì  í†¤ ë§¤ì¹­ ì •ë³´
        if semantic_connections.get("emotional_tone_matches"):
            formatted_info.append("**ê°ì •ì  í†¤ ë§¤ì¹­:**")
            for match in semantic_connections["emotional_tone_matches"]:
                formatted_info.append(f"- ì´ë¯¸ì§€ {match['image_index']}: {match['text_section']} (ë§¤ì¹­ë„: {match['match_score']:.2f})")
        
        # ì£¼ì œì  ì—°ê²°ì„± ì •ë³´
        if semantic_connections.get("thematic_alignments"):
            formatted_info.append("\n**ì£¼ì œì  ì—°ê²°ì„±:**")
            for alignment in semantic_connections["thematic_alignments"]:
                formatted_info.append(f"- ì´ë¯¸ì§€ {alignment['image_index']}: {alignment['text_section']} (ì—°ê²°ë„: {alignment['alignment_score']:.2f})")
        
        # ë‚´ëŸ¬í‹°ë¸Œ í”Œë¡œìš° ì—°ê²°
        if semantic_connections.get("narrative_flow_connections"):
            formatted_info.append("\n**ë‚´ëŸ¬í‹°ë¸Œ í”Œë¡œìš° ì—°ê²°:**")
            for connection in semantic_connections["narrative_flow_connections"]:
                if connection.get("recommended_images"):
                    formatted_info.append(f"- {connection['section_key']}: ì¶”ì²œ ì´ë¯¸ì§€ {[img['image_index'] for img in connection['recommended_images'][:2]]}")
        
        return "\n".join(formatted_info) if formatted_info else "ì˜ë¯¸ì  ì—°ê²° ì •ë³´ ì—†ìŒ"

    async def _verify_content_completeness_async(self, interview_results: Dict[str, str], essay_results: Dict[str, str], qa_map: Dict[str, str]):
        """ì½˜í…ì¸  ì™„ì „ì„± ê²€ì¦ (ë¹„ë™ê¸°)"""
        await asyncio.get_event_loop().run_in_executor(
            None, self._verify_content_completeness, interview_results, essay_results, qa_map
        )

    async def _verify_final_content_as_first_agent_async(self, final_content: str, interview_results: Dict[str, str], essay_results: Dict[str, str]):
        """ì²« ë²ˆì§¸ ì—ì´ì „íŠ¸ë¡œì„œ ìµœì¢… ì½˜í…ì¸  ê²€ì¦ (ë¹„ë™ê¸°)"""
        await asyncio.get_event_loop().run_in_executor(
            None, self._verify_final_content_as_first_agent, final_content, interview_results, essay_results
        )

    async def _log_final_content_async(self, final_content: str, interview_results: Dict[str, str],
                                     essay_results: Dict[str, str], image_analysis_results: List[Dict], 
                                     qa_map: Dict[str, str], semantic_connections: Dict):
        """ìµœì¢… í†µí•© ì½˜í…ì¸  ìƒì„± ë¡œê¹… (ìƒˆë¡œìš´ ë°©ì‹ ì ìš©)"""
        # âœ… LoggingManager ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
        
        # âœ… ìƒˆë¡œìš´ ë¡œê¹… ë°©ì‹ìœ¼ë¡œ ì‘ë‹µ ë°ì´í„° ì €ì¥
        await self.logging_manager.log_agent_response(
            agent_name="ContentCreatorV2Agent",
            agent_role="ì—¬í–‰ ì½˜í…ì¸  í†µí•© í¸ì§‘ì (ì²« ë²ˆì§¸ ì—ì´ì „íŠ¸)",
            task_description=f"ì¸í„°ë·° {len(interview_results)}ê°œ, ì—ì„¸ì´ {len(essay_results)}ê°œ, ì´ë¯¸ì§€ {len(image_analysis_results)}ê°œë¥¼ í†µí•©í•œ ë§¤ê±°ì§„ ì½˜í…ì¸  ìƒì„± (ì´ë¯¸ì§€-í…ìŠ¤íŠ¸ ì˜ë¯¸ì  ì—°ê²° í¬í•¨)",
            response_data=final_content,  # âœ… ì‹¤ì œ ì‘ë‹µ ë°ì´í„°ë§Œ ì €ì¥
            metadata={
                "final_content_length": len(final_content),
                "content_expansion_ratio": len(final_content) / sum(len(text) for text in qa_map.values()) if qa_map else 0,
                "integration_success": len(interview_results) > 0 and len(essay_results) > 0,
                "image_integration_count": len(image_analysis_results),
                "semantic_connections_count": sum(len(v) if isinstance(v, list) else 0 for v in semantic_connections.values()),
                "emotional_tone_matches": len(semantic_connections.get("emotional_tone_matches", [])),
                "thematic_alignments": len(semantic_connections.get("thematic_alignments", [])),
                "narrative_flow_connections": len(semantic_connections.get("narrative_flow_connections", [])),
                "first_agent_completion": True,
                "async_processing": True,
                "image_text_synergy_enabled": True
            }
        )

    # ë™ê¸° ë²„ì „ ë©”ì„œë“œë“¤ (í˜¸í™˜ì„± ìœ ì§€)
    def _verify_final_content_as_first_agent(self, final_content: str, interview_results: Dict[str, str], essay_results: Dict[str, str]):
        """ì²« ë²ˆì§¸ ì—ì´ì „íŠ¸ë¡œì„œ ìµœì¢… ì½˜í…ì¸  ê²€ì¦ (ë™ê¸° ë²„ì „)"""
        final_length = len(final_content)
        total_source_length = sum(len(content) for content in interview_results.values()) + sum(len(content) for content in essay_results.values())
        
        print(f"ContentCreatorV2 (ì²« ë²ˆì§¸ ì—ì´ì „íŠ¸): ìµœì¢… ì½˜í…ì¸  ê²€ì¦")
        print(f"- ìµœì¢… ì½˜í…ì¸  ê¸¸ì´: {final_length}ì")
        print(f"- ì›ë³¸ ì†ŒìŠ¤ ê¸¸ì´: {total_source_length}ì")
        print(f"- í™•ì¥ ë¹„ìœ¨: {(final_length / total_source_length * 100):.1f}%" if total_source_length > 0 else "- í™•ì¥ ë¹„ìœ¨: ê³„ì‚° ë¶ˆê°€")
        print(f"- ì²« ë²ˆì§¸ ì—ì´ì „íŠ¸ ì—­í• : ê¸°ì´ˆ ë°ì´í„° ìƒì„± ì™„ë£Œ")
        print(f"- ì´ë¯¸ì§€-í…ìŠ¤íŠ¸ ì‹œë„ˆì§€: í™œì„±í™”ë¨")
        
        if final_length < total_source_length * 0.8:
            print("âš ï¸ ìµœì¢… ì½˜í…ì¸ ê°€ ì›ë³¸ë³´ë‹¤ í˜„ì €íˆ ì§§ìŠµë‹ˆë‹¤. ì²¨ì‚­ì´ ë°œìƒí–ˆì„ ê°€ëŠ¥ì„±ì´ ìˆìŠµë‹ˆë‹¤.")
        else:
            print("âœ… ì½˜í…ì¸ ê°€ ì ì ˆíˆ í™•ì¥ë˜ì–´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        print("âœ… ì²« ë²ˆì§¸ ì—ì´ì „íŠ¸ë¡œì„œ í›„ì† ì—ì´ì „íŠ¸ë“¤ì„ ìœ„í•œ ê¸°ì´ˆ ë°ì´í„° ìƒì„± ì™„ë£Œ")
        print("âœ… ì´ë¯¸ì§€-í…ìŠ¤íŠ¸ ì˜ë¯¸ì  ì—°ê²° ê°•í™” ì™„ë£Œ")

    def _calculate_content_quality_score(self, final_content: str, interview_results: Dict[str, str], essay_results: Dict[str, str]) -> float:
        """ì½˜í…ì¸  í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°"""
        score = 0.0
        
        # ê¸¸ì´ ê¸°ë°˜ ì ìˆ˜ (25%)
        if len(final_content) > 3000:
            score += 0.25
        elif len(final_content) > 2000:
            score += 0.2
        elif len(final_content) > 1000:
            score += 0.1
        
        # êµ¬ì¡°í™” ì ìˆ˜ (25%)
        section_count = final_content.count("===")
        if section_count >= 5:
            score += 0.25
        elif section_count >= 3:
            score += 0.2
        elif section_count >= 1:
            score += 0.1
        
        # ì½˜í…ì¸  í†µí•© ì ìˆ˜ (25%)
        if interview_results and essay_results:
            score += 0.25
        elif interview_results or essay_results:
            score += 0.15
        
        # ì´ë¯¸ì§€-í…ìŠ¤íŠ¸ ì‹œë„ˆì§€ ì ìˆ˜ (25%)
        visual_descriptors = ['ë³´ì´ëŠ”', 'ëˆˆì— ë„ëŠ”', 'í™”ë ¤í•œ', 'ì„ ëª…í•œ', 'ë°ì€', 'ì–´ë‘ìš´', 'ì•„ë¦„ë‹¤ìš´']
        synergy_count = sum(1 for descriptor in visual_descriptors if descriptor in final_content)
        if synergy_count >= 5:
            score += 0.25
        elif synergy_count >= 3:
            score += 0.2
        elif synergy_count >= 1:
            score += 0.1
        
        return min(score, 1.0)

    # ê¸°ì¡´ ë©”ì„œë“œë“¤ ìœ ì§€
    def _process_image_analysis(self, image_analysis_results: List[Dict]) -> str:
        """ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼ ì •ë¦¬"""
        if not image_analysis_results:
            return "ì´ë¯¸ì§€ ì •ë³´ ì—†ìŒ"
        
        image_summaries = []
        for i, result in enumerate(image_analysis_results):
            location = result.get('location', f'ì´ë¯¸ì§€ {i+1}')
            description = result.get('description', 'ì„¤ëª… ì—†ìŒ')
            image_summaries.append(f"ğŸ“ {location}: {description}")
        
        return "\n".join(image_summaries)

    def _verify_content_completeness(self, interview_results: Dict[str, str], essay_results: Dict[str, str], qa_map: Dict[str, str]):
        """ì½˜í…ì¸  ì™„ì „ì„± ê²€ì¦"""
        print("ContentCreatorV2 (ì²« ë²ˆì§¸ ì—ì´ì „íŠ¸): ì½˜í…ì¸  ì™„ì „ì„± ê²€ì¦")
        
        # ì›ë³¸ í…ìŠ¤íŠ¸ ê¸¸ì´
        total_original_length = sum(len(text) for text in qa_map.values())
        
        # ì¸í„°ë·° ê²°ê³¼ ê¸¸ì´
        total_interview_length = sum(len(content) for content in interview_results.values())
        
        # ì—ì„¸ì´ ê²°ê³¼ ê¸¸ì´
        total_essay_length = sum(len(content) for content in essay_results.values())
        
        print(f"ì›ë³¸ í…ìŠ¤íŠ¸: {total_original_length}ì")
        print(f"ì¸í„°ë·° ê²°ê³¼: {total_interview_length}ì ({len(interview_results)}ê°œ)")
        print(f"ì—ì„¸ì´ ê²°ê³¼: {total_essay_length}ì ({len(essay_results)}ê°œ)")

    # ë™ê¸° ë²„ì „ ë©”ì„œë“œ (í˜¸í™˜ì„± ë³´ì¥)
    def create_magazine_content_sync(self, raw_user_input, image_analysis_results: List[Dict]) -> str:
        """ë™ê¸° ë²„ì „ ë§¤ê±°ì§„ ì½˜í…ì¸  ìƒì„± (í˜¸í™˜ì„± ìœ ì§€)"""
        return asyncio.run(self.create_magazine_content(raw_user_input, image_analysis_results))


class ContentCreatorV2Crew:
    """ContentCreatorV2ë¥¼ ìœ„í•œ Crew ê´€ë¦¬ (ë¹„ë™ê¸° ì²˜ë¦¬)"""

    def __init__(self):
        self.content_creator = ContentCreatorV2Agent()

    def create_crew(self) -> Crew:
        """ContentCreatorV2 ì „ìš© Crew ìƒì„±"""
        return Crew(
            agents=[self.content_creator.create_agent()],
            verbose=True
        )

    async def execute_content_creation(self, raw_user_input, image_analysis_results: List[Dict]) -> str:
        """Crewë¥¼ í†µí•œ ì½˜í…ì¸  ìƒì„± ì‹¤í–‰ (ë™ì  ì„¹ì…˜ ìƒì„± ë°©ì‹)"""
        crew = self.create_crew()
        
        print("\n=== ContentCreatorV2 Crew ì‹¤í–‰ (ë™ì  ì„¹ì…˜ ìƒì„±) ===")
        
        # ì…ë ¥ì´ ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš°(ê¸°ì¡´ ì½”ë“œ í˜¸í™˜) ë¬¸ìì—´ë¡œ ë³€í™˜
        if isinstance(raw_user_input, list):
            combined_text = "\n\n".join(raw_user_input)
            print(f"- ì…ë ¥ í…ìŠ¤íŠ¸: {len(raw_user_input)}ê°œ í…ìŠ¤íŠ¸ ê²°í•©")
            print(f"- ê²°í•©ëœ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(combined_text)}ì")
        else:
            combined_text = raw_user_input
            print(f"- ì…ë ¥ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(combined_text)}ì")
            
        print(f"- ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼: {len(image_analysis_results)}ê°œ")
        print(f"- ë™ì  ì„¹ì…˜ ìƒì„±: í™œì„±í™”")
        print(f"- ì½˜í…ì¸  ë¶„ëŸ‰ ìë™ ì¡°ì ˆ: í™œì„±í™”")
        print(f"- ì´ë¯¸ì§€-í…ìŠ¤íŠ¸ ì‹œë„ˆì§€: í™œì„±í™”")
        
        # ContentCreatorV2Agentë¥¼ í†µí•œ ì½˜í…ì¸  ìƒì„± (ë¹„ë™ê¸°)
        result = await self.content_creator.create_magazine_content(combined_text, image_analysis_results)
        
        print("âœ… ContentCreatorV2 Crew ì‹¤í–‰ ì™„ë£Œ (ë™ì  ì„¹ì…˜ ìƒì„±)")
        print("âœ… ì½˜í…ì¸  ë¶„ëŸ‰ ìë™ ì¡°ì ˆ ì™„ë£Œ")
        print("âœ… ì´ë¯¸ì§€-í…ìŠ¤íŠ¸ ì˜ë¯¸ì  ì—°ê²° ê°•í™” ì™„ë£Œ")
        
        return result

    # ë™ê¸° ë²„ì „ ë©”ì„œë“œ (í˜¸í™˜ì„± ë³´ì¥)
    def execute_content_creation_sync(self, raw_user_input, image_analysis_results: List[Dict]) -> str:
        """ë™ê¸° ë²„ì „ ì½˜í…ì¸  ìƒì„± ì‹¤í–‰ (í˜¸í™˜ì„± ìœ ì§€)"""
        return asyncio.run(self.execute_content_creation(raw_user_input, image_analysis_results))