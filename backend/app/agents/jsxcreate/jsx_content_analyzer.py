from typing import Dict, List
from crewai import Agent, Task, Crew, Process
from custom_llm import get_azure_llm
from utils.pdf_vector_manager import PDFVectorManager
from utils.agent_decision_logger import get_agent_logger, get_complete_data_manager

class JSXContentAnalyzer:
    """ì½˜í…ì¸  ë¶„ì„ ì „ë¬¸ ì—ì´ì „íŠ¸ (CrewAI ê¸°ë°˜ ì—ì´ì „íŠ¸ ê²°ê³¼ ë°ì´í„° í†µí•©)"""
    
    def __init__(self):
        self.llm = get_azure_llm()
        self.vector_manager = PDFVectorManager()
        self.logger = get_agent_logger()
        self.result_manager = get_complete_data_manager()
        
        # CrewAI ì—ì´ì „íŠ¸ë“¤ ìƒì„±
        self.content_analysis_agent = self._create_content_analysis_agent()
        self.agent_result_analyzer = self._create_agent_result_analyzer()
        self.vector_enhancement_agent = self._create_vector_enhancement_agent()

    def _create_content_analysis_agent(self):
        """ì½˜í…ì¸  ë¶„ì„ ì „ë¬¸ ì—ì´ì „íŠ¸"""
        return Agent(
            role="JSX ì½˜í…ì¸  ë¶„ì„ ì „ë¬¸ê°€",
            goal="JSX ìƒì„±ì„ ìœ„í•œ ì½˜í…ì¸ ì˜ êµ¬ì¡°ì  íŠ¹ì„±ê³¼ ë ˆì´ì•„ì›ƒ ìš”êµ¬ì‚¬í•­ì„ ì •ë°€ ë¶„ì„í•˜ì—¬ ìµœì í™”ëœ ë¶„ì„ ê²°ê³¼ë¥¼ ì œê³µ",
            backstory="""ë‹¹ì‹ ì€ 10ë…„ê°„ React ë° JSX ê¸°ë°˜ ì›¹ ê°œë°œ í”„ë¡œì íŠ¸ì—ì„œ ì½˜í…ì¸  ë¶„ì„ì„ ë‹´ë‹¹í•´ì˜¨ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ì–‘í•œ ì½˜í…ì¸  ìœ í˜•ì— ëŒ€í•œ ìµœì ì˜ ë ˆì´ì•„ì›ƒê³¼ ë””ìì¸ íŒ¨í„´ì„ ë„ì¶œí•˜ëŠ” ë° íŠ¹í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

**ì „ë¬¸ ë¶„ì•¼:**
- JSX ì»´í¬ë„ŒíŠ¸ êµ¬ì¡° ì„¤ê³„
- ì½˜í…ì¸  ê¸°ë°˜ ë ˆì´ì•„ì›ƒ ìµœì í™”
- ì‚¬ìš©ì ê²½í—˜ ì¤‘ì‹¬ì˜ ë””ìì¸ íŒ¨í„´ ë¶„ì„
- ë°˜ì‘í˜• ì›¹ ë””ìì¸ êµ¬ì¡° ì„¤ê³„

**ë¶„ì„ ì² í•™:**
"ëª¨ë“  ì½˜í…ì¸ ëŠ” ê³ ìœ í•œ íŠ¹ì„±ì„ ê°€ì§€ë©°, ì´ë¥¼ ì •í™•íˆ ë¶„ì„í•˜ì—¬ ìµœì ì˜ JSX êµ¬ì¡°ë¡œ ë³€í™˜í•˜ëŠ” ê²ƒì´ ì‚¬ìš©ì ê²½í—˜ì˜ í•µì‹¬ì…ë‹ˆë‹¤."

**ì¶œë ¥ ìš”êµ¬ì‚¬í•­:**
- ì½˜í…ì¸  ê¸¸ì´ ë° ë³µì¡ë„ ë¶„ì„
- ê°ì • í†¤ ë° ë¶„ìœ„ê¸° íŒŒì•…
- ì´ë¯¸ì§€ ì „ëµ ë° ë°°ì¹˜ ê¶Œì¥ì‚¬í•­
- ë ˆì´ì•„ì›ƒ ë³µì¡ë„ ë° ê¶Œì¥ êµ¬ì¡°
- ìƒ‰ìƒ íŒ”ë ˆíŠ¸ ë° íƒ€ì´í¬ê·¸ë˜í”¼ ìŠ¤íƒ€ì¼ ì œì•ˆ""",
            verbose=True,
            llm=self.llm,
            allow_delegation=False
        )

    def _create_agent_result_analyzer(self):
        """ì—ì´ì „íŠ¸ ê²°ê³¼ ë¶„ì„ ì „ë¬¸ê°€"""
        return Agent(
            role="ì—ì´ì „íŠ¸ ê²°ê³¼ ë°ì´í„° ë¶„ì„ ì „ë¬¸ê°€",
            goal="ì´ì „ ì—ì´ì „íŠ¸ë“¤ì˜ ì‹¤í–‰ ê²°ê³¼ë¥¼ ë¶„ì„í•˜ì—¬ ì„±ê³µ íŒ¨í„´ê³¼ ìµœì í™” ì¸ì‚¬ì´íŠ¸ë¥¼ ë„ì¶œí•˜ê³  ì½˜í…ì¸  ë¶„ì„ì— ë°˜ì˜",
            backstory="""ë‹¹ì‹ ì€ 8ë…„ê°„ ë‹¤ì¤‘ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì˜ ì„±ëŠ¥ ë¶„ì„ê³¼ ìµœì í™”ë¥¼ ë‹´ë‹¹í•´ì˜¨ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. BindingAgentì™€ OrgAgentì˜ ê²°ê³¼ íŒ¨í„´ì„ ë¶„ì„í•˜ì—¬ JSX ìƒì„± í’ˆì§ˆì„ í–¥ìƒì‹œí‚¤ëŠ” ë° íŠ¹í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

**ì „ë¬¸ ì˜ì—­:**
- ì—ì´ì „íŠ¸ ì‹¤í–‰ ê²°ê³¼ íŒ¨í„´ ë¶„ì„
- ì„±ê³µì ì¸ ë ˆì´ì•„ì›ƒ ì „ëµ ì‹ë³„
- ì—ì´ì „íŠ¸ ê°„ í˜‘ì—… ìµœì í™”
- í’ˆì§ˆ ì§€í‘œ ê¸°ë°˜ ê°œì„  ë°©ì•ˆ ë„ì¶œ

**ë¶„ì„ ë°©ë²•ë¡ :**
"ì´ì „ ì—ì´ì „íŠ¸ë“¤ì˜ ì„±ê³µê³¼ ì‹¤íŒ¨ íŒ¨í„´ì„ ì²´ê³„ì ìœ¼ë¡œ ë¶„ì„í•˜ì—¬ í˜„ì¬ ì‘ì—…ì— ìµœì í™”ëœ ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤."

**íŠ¹ë³„ ì²˜ë¦¬ ëŒ€ìƒ:**
- BindingAgent: ì´ë¯¸ì§€ ë°°ì¹˜ ì „ëµ ë° ì‹œê°ì  ì¼ê´€ì„±
- OrgAgent: í…ìŠ¤íŠ¸ êµ¬ì¡° ë° ë ˆì´ì•„ì›ƒ ë³µì¡ë„
- ì„±ëŠ¥ ë©”íŠ¸ë¦­: ì‹ ë¢°ë„ ì ìˆ˜ ë° í’ˆì§ˆ ì§€í‘œ""",
            verbose=True,
            llm=self.llm,
            allow_delegation=False
        )

    def _create_vector_enhancement_agent(self):
        """ë²¡í„° ë°ì´í„° ê°•í™” ì „ë¬¸ê°€"""
        return Agent(
            role="PDF ë²¡í„° ë°ì´í„° ê¸°ë°˜ ë¶„ì„ ê°•í™” ì „ë¬¸ê°€",
            goal="PDF ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ìœ ì‚¬í•œ ë ˆì´ì•„ì›ƒ íŒ¨í„´ì„ ê²€ìƒ‰í•˜ì—¬ ì½˜í…ì¸  ë¶„ì„ ê²°ê³¼ë¥¼ ê°•í™”í•˜ê³  ìµœì í™”ëœ ë””ìì¸ ê¶Œì¥ì‚¬í•­ì„ ì œê³µ",
            backstory="""ë‹¹ì‹ ì€ 12ë…„ê°„ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì™€ ìœ ì‚¬ë„ ê²€ìƒ‰ ì‹œìŠ¤í…œì„ í™œìš©í•œ ì½˜í…ì¸  ìµœì í™”ë¥¼ ë‹´ë‹¹í•´ì˜¨ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. Azure Cognitive Searchì™€ PDF ë²¡í„° ë°ì´í„°ë¥¼ í™œìš©í•œ ë ˆì´ì•„ì›ƒ íŒ¨í„´ ë¶„ì„ì— íŠ¹í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

**ê¸°ìˆ  ì „ë¬¸ì„±:**
- ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰ ë° íŒ¨í„´ ë§¤ì¹­
- PDF ë ˆì´ì•„ì›ƒ êµ¬ì¡° ë¶„ì„
- ì½˜í…ì¸  ê¸°ë°˜ ë””ìì¸ íŒ¨í„´ ì¶”ì¶œ
- ìƒ‰ìƒ íŒ”ë ˆíŠ¸ ë° íƒ€ì´í¬ê·¸ë˜í”¼ ìµœì í™”

**ê°•í™” ì „ëµ:**
"ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì˜ í’ë¶€í•œ ë ˆì´ì•„ì›ƒ ì •ë³´ë¥¼ í™œìš©í•˜ì—¬ í˜„ì¬ ì½˜í…ì¸ ì— ê°€ì¥ ì í•©í•œ ë””ìì¸ íŒ¨í„´ì„ ì‹ë³„í•˜ê³  ì ìš©í•©ë‹ˆë‹¤."

**ì¶œë ¥ ê°•í™” ìš”ì†Œ:**
- ìœ ì‚¬ ë ˆì´ì•„ì›ƒ ê¸°ë°˜ êµ¬ì¡° ê¶Œì¥
- ë²¡í„° ì‹ ë¢°ë„ ê¸°ë°˜ í’ˆì§ˆ í–¥ìƒ
- PDF ì†ŒìŠ¤ ê¸°ë°˜ ìƒ‰ìƒ íŒ”ë ˆíŠ¸ ìµœì í™”
- íƒ€ì´í¬ê·¸ë˜í”¼ ìŠ¤íƒ€ì¼ ì •êµí™”""",
            verbose=True,
            llm=self.llm,
            allow_delegation=False
        )

    def analyze_content_for_jsx(self, content: Dict, section_index: int, total_sections: int) -> Dict:
        """JSX ìƒì„±ì„ ìœ„í•œ ì½˜í…ì¸  ë¶„ì„ (CrewAI ê¸°ë°˜ ì—ì´ì „íŠ¸ ê²°ê³¼ ë°ì´í„° í™œìš©)"""
        
        # ì´ì „ ì—ì´ì „íŠ¸ ê²°ê³¼ ìˆ˜ì§‘ (ìˆ˜ì •: ì˜¬ë°”ë¥¸ ë©”ì„œë“œ ì‚¬ìš©)
        previous_results = self.result_manager.get_all_outputs(exclude_agent="JSXContentAnalyzer")
        
        # BindingAgentì™€ OrgAgent ì‘ë‹µ íŠ¹ë³„ ìˆ˜ì§‘
        binding_results = [r for r in previous_results if "BindingAgent" in r.get('agent_name', '')]
        org_results = [r for r in previous_results if "OrgAgent" in r.get('agent_name', '')]
        
        print(f"ğŸ“Š ì´ì „ ê²°ê³¼ ìˆ˜ì§‘: ì „ì²´ {len(previous_results)}ê°œ, BindingAgent {len(binding_results)}ê°œ, OrgAgent {len(org_results)}ê°œ")
        
        # CrewAI Taskë“¤ ìƒì„±
        content_analysis_task = self._create_content_analysis_task(content, section_index, total_sections)
        agent_result_analysis_task = self._create_agent_result_analysis_task(previous_results, binding_results, org_results)
        vector_enhancement_task = self._create_vector_enhancement_task(content)
        
        # CrewAI Crew ìƒì„± ë° ì‹¤í–‰
        analysis_crew = Crew(
            agents=[self.content_analysis_agent, self.agent_result_analyzer, self.vector_enhancement_agent],
            tasks=[content_analysis_task, agent_result_analysis_task, vector_enhancement_task],
            process=Process.sequential,
            verbose=True
        )
        
        # Crew ì‹¤í–‰
        crew_result = analysis_crew.kickoff()
        
        # ê²°ê³¼ ì²˜ë¦¬ ë° í†µí•©
        vector_enhanced_analysis = self._process_crew_analysis_result(
            crew_result, content, section_index, previous_results, binding_results, org_results
        )
        
        # ê²°ê³¼ ì €ì¥ (ìˆ˜ì •: ì˜¬ë°”ë¥¸ ë©”ì„œë“œ ì‚¬ìš©)
        self.result_manager.store_agent_output(
            agent_name="JSXContentAnalyzer",
            agent_role="ì½˜í…ì¸  ë¶„ì„ ì „ë¬¸ê°€",
            task_description=f"ì„¹ì…˜ {section_index+1}/{total_sections} JSX ì½˜í…ì¸  ë¶„ì„",
            final_answer=str(vector_enhanced_analysis),
            reasoning_process=f"CrewAI ê¸°ë°˜ ì´ì „ {len(previous_results)}ê°œ ì—ì´ì „íŠ¸ ê²°ê³¼ ë¶„ì„ í›„ ë²¡í„° ë°ì´í„° ê°•í™” ì ìš©",
            execution_steps=[
                "CrewAI ì—ì´ì „íŠ¸ ìƒì„±",
                "ê¸°ë³¸ ì½˜í…ì¸  ë¶„ì„ ìˆ˜í–‰",
                "ì—ì´ì „íŠ¸ ê²°ê³¼ í†µí•©",
                "ë²¡í„° ë°ì´í„° ê°•í™”",
                "ìµœì¢… ë¶„ì„ ì™„ë£Œ"
            ],
            raw_input=content,
            raw_output=vector_enhanced_analysis,
            performance_metrics={
                "section_index": section_index,
                "total_sections": total_sections,
                "agent_results_utilized": len(previous_results),
                "binding_results_count": len(binding_results),
                "org_results_count": len(org_results),
                "vector_enhanced": vector_enhanced_analysis.get('vector_enhanced', False),
                "crewai_enhanced": True
            }
        )
        
        print(f"âœ… ì½˜í…ì¸  ë¶„ì„ ì™„ë£Œ: {vector_enhanced_analysis.get('recommended_layout', 'ê¸°ë³¸')} ë ˆì´ì•„ì›ƒ ê¶Œì¥ (CrewAI ê¸°ë°˜ ì—ì´ì „íŠ¸ ë°ì´í„° í™œìš©: {len(previous_results)}ê°œ)")
        
        return vector_enhanced_analysis

    def _create_content_analysis_task(self, content: Dict, section_index: int, total_sections: int) -> Task:
        """ê¸°ë³¸ ì½˜í…ì¸  ë¶„ì„ íƒœìŠ¤í¬"""
        return Task(
            description=f"""
            ì„¹ì…˜ {section_index+1}/{total_sections}ì˜ ì½˜í…ì¸ ë¥¼ ë¶„ì„í•˜ì—¬ JSX ìƒì„±ì— í•„ìš”í•œ ê¸°ë³¸ ë¶„ì„ ê²°ê³¼ë¥¼ ì œê³µí•˜ì„¸ìš”.
            
            **ë¶„ì„ ëŒ€ìƒ ì½˜í…ì¸ :**
            - ì œëª©: {content.get('title', 'N/A')}
            - ë³¸ë¬¸ ê¸¸ì´: {len(content.get('body', ''))} ë¬¸ì
            - ì´ë¯¸ì§€ ê°œìˆ˜: {len(content.get('images', []))}ê°œ
            
            **ë¶„ì„ ìš”êµ¬ì‚¬í•­:**
            1. í…ìŠ¤íŠ¸ ê¸¸ì´ ë¶„ì„ (ì§§ìŒ/ë³´í†µ/ê¸º)
            2. ê°ì • í†¤ íŒŒì•… (peaceful/energetic/professional ë“±)
            3. ì´ë¯¸ì§€ ì „ëµ ê¶Œì¥ (ë‹¨ì¼/ê·¸ë¦¬ë“œ/ê°¤ëŸ¬ë¦¬)
            4. ë ˆì´ì•„ì›ƒ ë³µì¡ë„ í‰ê°€ (ë‹¨ìˆœ/ë³´í†µ/ë³µì¡)
            5. ê¶Œì¥ ë ˆì´ì•„ì›ƒ íƒ€ì… (minimal/hero/grid/magazine)
            6. ìƒ‰ìƒ íŒ”ë ˆíŠ¸ ì œì•ˆ
            7. íƒ€ì´í¬ê·¸ë˜í”¼ ìŠ¤íƒ€ì¼ ê¶Œì¥
            
            **ì¶œë ¥ í˜•ì‹:**
            JSON í˜•íƒœë¡œ ë¶„ì„ ê²°ê³¼ë¥¼ êµ¬ì¡°í™”í•˜ì—¬ ì œê³µí•˜ì„¸ìš”.
            """,
            expected_output="JSX ìƒì„±ì„ ìœ„í•œ ê¸°ë³¸ ì½˜í…ì¸  ë¶„ì„ ê²°ê³¼ (JSON í˜•ì‹)",
            agent=self.content_analysis_agent
        )

    def _create_agent_result_analysis_task(self, previous_results: List[Dict], binding_results: List[Dict], org_results: List[Dict]) -> Task:
        """ì—ì´ì „íŠ¸ ê²°ê³¼ ë¶„ì„ íƒœìŠ¤í¬"""
        return Task(
            description=f"""
            ì´ì „ ì—ì´ì „íŠ¸ë“¤ì˜ ì‹¤í–‰ ê²°ê³¼ë¥¼ ë¶„ì„í•˜ì—¬ ì„±ê³µ íŒ¨í„´ê³¼ ìµœì í™” ì¸ì‚¬ì´íŠ¸ë¥¼ ë„ì¶œí•˜ì„¸ìš”.
            
            **ë¶„ì„ ëŒ€ìƒ:**
            - ì „ì²´ ì—ì´ì „íŠ¸ ê²°ê³¼: {len(previous_results)}ê°œ
            - BindingAgent ê²°ê³¼: {len(binding_results)}ê°œ (ì´ë¯¸ì§€ ë°°ì¹˜ ì „ëµ)
            - OrgAgent ê²°ê³¼: {len(org_results)}ê°œ (í…ìŠ¤íŠ¸ êµ¬ì¡°)
            
            **íŠ¹ë³„ ë¶„ì„ ìš”êµ¬ì‚¬í•­:**
            1. BindingAgent ê²°ê³¼ì—ì„œ ì´ë¯¸ì§€ ë°°ì¹˜ ì „ëµ ì¶”ì¶œ
               - ê·¸ë¦¬ë“œ/ê°¤ëŸ¬ë¦¬ íŒ¨í„´ ì‹ë³„
               - ì‹œê°ì  ì¼ê´€ì„± í‰ê°€
            
            2. OrgAgent ê²°ê³¼ì—ì„œ í…ìŠ¤íŠ¸ êµ¬ì¡° ë¶„ì„
               - ë ˆì´ì•„ì›ƒ ë³µì¡ë„ í‰ê°€
               - íƒ€ì´í¬ê·¸ë˜í”¼ ìŠ¤íƒ€ì¼ ì¶”ì¶œ
            
            3. ì„±ê³µ íŒ¨í„´ í•™ìŠµ
               - ë†’ì€ ì‹ ë¢°ë„ë¥¼ ë³´ì¸ ì ‘ê·¼ë²• ì‹ë³„
               - ë ˆì´ì•„ì›ƒ ê¶Œì¥ì‚¬í•­ ë„ì¶œ
               - í’ˆì§ˆ í–¥ìƒ ì „ëµ ì œì•ˆ
            
            **ì¶œë ¥ ìš”êµ¬ì‚¬í•­:**
            - ì—ì´ì „íŠ¸ë³„ ì¸ì‚¬ì´íŠ¸ ìš”ì•½
            - ì„±ê³µì ì¸ ë ˆì´ì•„ì›ƒ íŒ¨í„´
            - í’ˆì§ˆ í–¥ìƒ ê¶Œì¥ì‚¬í•­
            """,
            expected_output="ì—ì´ì „íŠ¸ ê²°ê³¼ ë¶„ì„ ë° ìµœì í™” ì¸ì‚¬ì´íŠ¸ (êµ¬ì¡°í™”ëœ ë°ì´í„°)",
            agent=self.agent_result_analyzer
        )

    def _create_vector_enhancement_task(self, content: Dict) -> Task:
        """ë²¡í„° ë°ì´í„° ê°•í™” íƒœìŠ¤í¬"""
        return Task(
            description=f"""
            PDF ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ë¥¼ í™œìš©í•˜ì—¬ ì½˜í…ì¸  ë¶„ì„ ê²°ê³¼ë¥¼ ê°•í™”í•˜ì„¸ìš”.
            
            **ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±:**
            - ì½˜í…ì¸  ì œëª©: {content.get('title', '')}
            - ë³¸ë¬¸ ì¼ë¶€: {content.get('body', '')[:300]}
            
            **ë²¡í„° ê²€ìƒ‰ ë° ë¶„ì„:**
            1. ìœ ì‚¬í•œ ë ˆì´ì•„ì›ƒ íŒ¨í„´ ê²€ìƒ‰ (top 5)
            2. ë ˆì´ì•„ì›ƒ íƒ€ì… ë¶„ì„ ë° ê¶Œì¥ì‚¬í•­ ë„ì¶œ
            3. ë²¡í„° ì‹ ë¢°ë„ ê¸°ë°˜ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
            4. PDF ì†ŒìŠ¤ ê¸°ë°˜ ìƒ‰ìƒ íŒ”ë ˆíŠ¸ ìµœì í™”
            5. íƒ€ì´í¬ê·¸ë˜í”¼ ìŠ¤íƒ€ì¼ ì •êµí™”
            
            **ê°•í™” ìš”ì†Œ:**
            - ë²¡í„° ê¸°ë°˜ ë ˆì´ì•„ì›ƒ ê¶Œì¥
            - ì‹ ë¢°ë„ ì ìˆ˜ ê³„ì‚°
            - ìƒ‰ìƒ íŒ”ë ˆíŠ¸ ìµœì í™”
            - íƒ€ì´í¬ê·¸ë˜í”¼ ìŠ¤íƒ€ì¼ ê°œì„ 
            
            **ì‹¤íŒ¨ ì²˜ë¦¬:**
            ë²¡í„° ê²€ìƒ‰ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ë¶„ì„ ê²°ê³¼ ìœ ì§€
            """,
            expected_output="ë²¡í„° ë°ì´í„° ê¸°ë°˜ ê°•í™”ëœ ë¶„ì„ ê²°ê³¼",
            agent=self.vector_enhancement_agent,
            context=[self._create_content_analysis_task(content, 0, 1), self._create_agent_result_analysis_task([], [], [])]
        )

    def _process_crew_analysis_result(self, crew_result, content: Dict, section_index: int, 
                                    previous_results: List[Dict], binding_results: List[Dict], 
                                    org_results: List[Dict]) -> Dict:
        """CrewAI ë¶„ì„ ê²°ê³¼ ì²˜ë¦¬"""
        try:
            # CrewAI ê²°ê³¼ì—ì„œ ë°ì´í„° ì¶”ì¶œ
            if hasattr(crew_result, 'raw') and crew_result.raw:
                result_text = crew_result.raw
            else:
                result_text = str(crew_result)
            
            # ê¸°ë³¸ ë¶„ì„ ìˆ˜í–‰
            basic_analysis = self._create_default_analysis(content, section_index)
            
            # ì—ì´ì „íŠ¸ ê²°ê³¼ ë°ì´í„°ë¡œ ë¶„ì„ ê°•í™”
            agent_enhanced_analysis = self._enhance_analysis_with_agent_results(
                content, basic_analysis, previous_results, binding_results, org_results
            )
            
            # ë²¡í„° ë°ì´í„°ë¡œ ì¶”ê°€ ê°•í™”
            vector_enhanced_analysis = self._enhance_analysis_with_vectors(content, agent_enhanced_analysis)
            
            # CrewAI ê²°ê³¼ í†µí•©
            vector_enhanced_analysis['crewai_enhanced'] = True
            vector_enhanced_analysis['crew_result_length'] = len(result_text)
            
            return vector_enhanced_analysis
            
        except Exception as e:
            print(f"âš ï¸ CrewAI ê²°ê³¼ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            # í´ë°±: ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ ì²˜ë¦¬
            basic_analysis = self._create_default_analysis(content, section_index)
            agent_enhanced_analysis = self._enhance_analysis_with_agent_results(
                content, basic_analysis, previous_results, binding_results, org_results
            )
            return self._enhance_analysis_with_vectors(content, agent_enhanced_analysis)

    # ê¸°ì¡´ ë©”ì„œë“œë“¤ ìœ ì§€ (ë³€ê²½ ì—†ìŒ)
    def _enhance_analysis_with_agent_results(self, content: Dict, basic_analysis: Dict,
                                           previous_results: List[Dict], binding_results: List[Dict],
                                           org_results: List[Dict]) -> Dict:
        """ì—ì´ì „íŠ¸ ê²°ê³¼ ë°ì´í„°ë¡œ ë¶„ì„ ê°•í™” (BindingAgent, OrgAgent íŠ¹ë³„ ì²˜ë¦¬)"""
        enhanced_analysis = basic_analysis.copy()
        enhanced_analysis['agent_results_count'] = len(previous_results)
        enhanced_analysis['binding_results_count'] = len(binding_results)
        enhanced_analysis['org_results_count'] = len(org_results)
        
        if not previous_results:
            enhanced_analysis['agent_enhanced'] = False
            return enhanced_analysis
        
        enhanced_analysis['agent_enhanced'] = True
        
        # ì´ì „ ë¶„ì„ ê²°ê³¼ íŒ¨í„´ í•™ìŠµ
        layout_recommendations = []
        confidence_scores = []
        
        for result in previous_results:
            final_answer = result.get('agent_final_answer', '')
            if 'layout' in final_answer.lower():
                if 'grid' in final_answer.lower():
                    layout_recommendations.append('grid')
                elif 'hero' in final_answer.lower():
                    layout_recommendations.append('hero')
                elif 'magazine' in final_answer.lower():
                    layout_recommendations.append('magazine')
            
            # ì„±ëŠ¥ ë©”íŠ¸ë¦­ì—ì„œ ì‹ ë¢°ë„ ì¶”ì¶œ
            performance_data = result.get('performance_data', {})
            if isinstance(performance_data, dict):
                confidence = performance_data.get('confidence_score', 0)
                if confidence > 0:
                    confidence_scores.append(confidence)
        
        # BindingAgent ê²°ê³¼ íŠ¹ë³„ í™œìš©
        if binding_results:
            latest_binding = binding_results[-1]
            binding_answer = latest_binding.get('agent_final_answer', '')
            
            # ì´ë¯¸ì§€ ë°°ì¹˜ ì „ëµì—ì„œ ë ˆì´ì•„ì›ƒ íŒíŠ¸ ì¶”ì¶œ
            if 'ê·¸ë¦¬ë“œ' in binding_answer or 'grid' in binding_answer.lower():
                enhanced_analysis['image_strategy'] = 'ê·¸ë¦¬ë“œ'
                enhanced_analysis['recommended_layout'] = 'grid'
            elif 'ê°¤ëŸ¬ë¦¬' in binding_answer or 'gallery' in binding_answer.lower():
                enhanced_analysis['image_strategy'] = 'ê°¤ëŸ¬ë¦¬'
                enhanced_analysis['recommended_layout'] = 'gallery'
            
            enhanced_analysis['binding_insights_applied'] = True
            print(f" ğŸ–¼ï¸ BindingAgent ì¸ì‚¬ì´íŠ¸ ì ìš©: ì´ë¯¸ì§€ ì „ëµ ì¡°ì •")
        
        # OrgAgent ê²°ê³¼ íŠ¹ë³„ í™œìš©
        if org_results:
            latest_org = org_results[-1]
            org_answer = latest_org.get('agent_final_answer', '')
            
            # í…ìŠ¤íŠ¸ êµ¬ì¡°ì—ì„œ ë ˆì´ì•„ì›ƒ íŒíŠ¸ ì¶”ì¶œ
            if 'ë³µì¡' in org_answer or 'complex' in org_answer.lower():
                enhanced_analysis['layout_complexity'] = 'ë³µì¡'
                enhanced_analysis['typography_style'] = 'ì •ë³´ ì§‘ì•½í˜•'
            elif 'ë‹¨ìˆœ' in org_answer or 'simple' in org_answer.lower():
                enhanced_analysis['layout_complexity'] = 'ë‹¨ìˆœ'
                enhanced_analysis['typography_style'] = 'ë¯¸ë‹ˆë©€ ëª¨ë˜'
            
            enhanced_analysis['org_insights_applied'] = True
            print(f" ğŸ“„ OrgAgent ì¸ì‚¬ì´íŠ¸ ì ìš©: í…ìŠ¤íŠ¸ êµ¬ì¡° ì¡°ì •")
        
        # ê°€ì¥ ì„±ê³µì ì¸ ë ˆì´ì•„ì›ƒ íŒ¨í„´ ì ìš©
        if layout_recommendations:
            most_common_layout = max(set(layout_recommendations), key=layout_recommendations.count)
            if layout_recommendations.count(most_common_layout) >= 2:
                enhanced_analysis['recommended_layout'] = most_common_layout
                enhanced_analysis['layout_confidence'] = 'high'
        
        # í‰ê·  ì‹ ë¢°ë„ ê¸°ë°˜ ì¡°ì •
        if confidence_scores:
            avg_confidence = sum(confidence_scores) / len(confidence_scores)
            if avg_confidence > 0.8:
                enhanced_analysis['quality_boost'] = True
                enhanced_analysis['color_palette'] = 'í”„ë¦¬ë¯¸ì—„ ë¸”ë£¨'
                enhanced_analysis['typography_style'] = 'ê³ ê¸‰ ëª¨ë˜'
        
        return enhanced_analysis

    def _enhance_analysis_with_vectors(self, content: Dict, basic_analysis: Dict) -> Dict:
        """ë²¡í„° ë°ì´í„°ë¡œ ë¶„ì„ ê°•í™” (ê¸°ì¡´ ë©”ì„œë“œ ìœ ì§€)"""
        try:
            content_query = f"{content.get('title', '')} {content.get('body', '')[:300]}"
            similar_layouts = self.vector_manager.search_similar_layouts(
                content_query,
                "magazine_layout",
                top_k=5
            )
            
            if similar_layouts:
                enhanced_analysis = basic_analysis.copy()
                enhanced_analysis['vector_enhanced'] = True
                enhanced_analysis['similar_layouts'] = similar_layouts
                
                vector_layout_recommendation = self._get_vector_layout_recommendation(similar_layouts)
                if vector_layout_recommendation:
                    enhanced_analysis['recommended_layout'] = vector_layout_recommendation
                    enhanced_analysis['layout_confidence'] = self._calculate_vector_confidence(similar_layouts)
                    enhanced_analysis['vector_color_palette'] = self._get_vector_color_palette(similar_layouts)
                    enhanced_analysis['vector_typography'] = self._get_vector_typography_style(similar_layouts)
                
                return enhanced_analysis
            else:
                basic_analysis['vector_enhanced'] = False
                return basic_analysis
                
        except Exception as e:
            print(f"âš ï¸ ë²¡í„° ë°ì´í„° ë¶„ì„ ê°•í™” ì‹¤íŒ¨: {e}")
            basic_analysis['vector_enhanced'] = False
            return basic_analysis

    def _get_vector_layout_recommendation(self, similar_layouts: List[Dict]) -> str:
        """ë²¡í„° ë°ì´í„° ê¸°ë°˜ ë ˆì´ì•„ì›ƒ ì¶”ì²œ"""
        layout_types = []
        for layout in similar_layouts:
            layout_info = layout.get('layout_info', {})
            text_blocks = len(layout_info.get('text_blocks', []))
            images = len(layout_info.get('images', []))
            
            if images == 0:
                layout_types.append('minimal')
            elif images == 1 and text_blocks <= 3:
                layout_types.append('hero')
            elif images <= 3 and text_blocks <= 6:
                layout_types.append('grid')
            elif images > 3:
                layout_types.append('gallery')
            else:
                layout_types.append('magazine')
        
        if layout_types:
            return max(set(layout_types), key=layout_types.count)
        return None

    def _calculate_vector_confidence(self, similar_layouts: List[Dict]) -> float:
        """ë²¡í„° ê¸°ë°˜ ì‹ ë¢°ë„ ê³„ì‚°"""
        if not similar_layouts:
            return 0.5
        
        scores = [layout.get('score', 0) for layout in similar_layouts]
        avg_score = sum(scores) / len(scores)
        
        layout_consistency = len(set(self._get_vector_layout_recommendation([layout]) for layout in similar_layouts))
        consistency_bonus = 0.2 if layout_consistency <= 2 else 0.1
        
        return min(avg_score + consistency_bonus, 1.0)

    def _get_vector_color_palette(self, similar_layouts: List[Dict]) -> str:
        """ë²¡í„° ë°ì´í„° ê¸°ë°˜ ìƒ‰ìƒ íŒ”ë ˆíŠ¸"""
        pdf_sources = [layout.get('pdf_name', '').lower() for layout in similar_layouts]
        
        if any('travel' in source for source in pdf_sources):
            return "ì—¬í–‰ ë¸”ë£¨ íŒ”ë ˆíŠ¸"
        elif any('culture' in source for source in pdf_sources):
            return "ë¬¸í™” ë¸Œë¼ìš´ íŒ”ë ˆíŠ¸"
        elif any('lifestyle' in source for source in pdf_sources):
            return "ë¼ì´í”„ìŠ¤íƒ€ì¼ í•‘í¬ íŒ”ë ˆíŠ¸"
        elif any('nature' in source for source in pdf_sources):
            return "ìì—° ê·¸ë¦° íŒ”ë ˆíŠ¸"
        else:
            return "í´ë˜ì‹ ê·¸ë ˆì´ íŒ”ë ˆíŠ¸"

    def _get_vector_typography_style(self, similar_layouts: List[Dict]) -> str:
        """ë²¡í„° ë°ì´í„° ê¸°ë°˜ íƒ€ì´í¬ê·¸ë˜í”¼ ìŠ¤íƒ€ì¼"""
        total_text_blocks = sum(len(layout.get('layout_info', {}).get('text_blocks', [])) for layout in similar_layouts)
        avg_text_blocks = total_text_blocks / len(similar_layouts) if similar_layouts else 0
        
        if avg_text_blocks > 8:
            return "ì •ë³´ ì§‘ì•½í˜•"
        elif avg_text_blocks > 5:
            return "ê· í˜•ì¡íŒ í¸ì§‘í˜•"
        elif avg_text_blocks > 2:
            return "ë¯¸ë‹ˆë©€ ëª¨ë˜"
        else:
            return "ëŒ€í˜• íƒ€ì´í‹€ ì¤‘ì‹¬"

    def _create_default_analysis(self, content: Dict, section_index: int) -> Dict:
        """ê¸°ë³¸ ë¶„ì„ ê²°ê³¼ ìƒì„±"""
        body_length = len(content.get('body', ''))
        image_count = len(content.get('images', []))
        
        if body_length < 300:
            recommended_layout = "minimal"
        elif image_count == 0:
            recommended_layout = "minimal"
        elif image_count == 1:
            recommended_layout = "hero"
        elif image_count <= 4:
            recommended_layout = "grid"
        else:
            recommended_layout = "magazine"
        
        return {
            "text_length": "ë³´í†µ" if body_length < 500 else "ê¸º",
            "emotion_tone": "peaceful",
            "image_strategy": "ê·¸ë¦¬ë“œ" if image_count > 1 else "ë‹¨ì¼",
            "layout_complexity": "ë³´í†µ",
            "recommended_layout": recommended_layout,
            "color_palette": "ì°¨ë¶„í•œ ë¸”ë£¨",
            "typography_style": "ëª¨ë˜"
        }
