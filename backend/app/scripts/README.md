# `scripts` Directory README

이 디렉토리에는 프로젝트의 주요 로직 외에, 사전 준비나 특별한 작업을 수행하는 데 필요한 헬퍼 스크립트들이 포함되어 있습니다.

## `convert_clip_to_onnx.py`

이 스크립트는 프로젝트의 AI 연산 성능을 최적화하는 데 가장 중요한 역할을 수행합니다.

### 목적

기존 프로젝트는 `PyTorch`로 구현된 원본 CLIP AI 모델 (`ViT-B-32`)을 사용했습니다. 이 모델은 크기가 크고 무거워, GPU가 없는 일반적인 CPU 환경에서 실행할 경우 이미지 및 텍스트의 의미를 분석하는 과정에서 심각한 속도 저하를 유발합니다.

이 스크립트는 다음과 같은 과정을 통해 이 문제를 해결합니다:

1.  무거운 원본 PyTorch 모델을 로드합니다.
2.  이를 여러 환경에서 고속으로 실행되도록 표준화된 **ONNX(Open Neural Network Exchange)** 형식으로 변환합니다.
3.  변환된 ONNX 모델을 **양자화(Quantization)**하여 모델의 크기를 대폭 줄이고 CPU에서 더 효율적으로 연산할 수 있도록 최적화합니다.

이 스크립트는 프로젝트를 처음 설정하거나 AI 모델을 변경할 때 **단 한 번만 실행**하면 되는 일회성 작업입니다.

### 실행 방법

프로젝트의 루트 디렉토리에서 다음 명령어를 실행합니다:

```bash
python scripts/convert_clip_to_onnx.py
```

### 생성되는 파일

스크립트 실행이 완료되면, 프로젝트의 `models/clip_onnx/` 디렉토리 내부에 최적화된 모델 파일들이 생성됩니다.

---

## `clip_visual.quant.onnx` 파일이란?

- **파일 위치**: `models/clip_onnx/clip_visual.quant.onnx`
- **파일 정체**: 위 변환 스크립트를 통해 생성된 **최종 결과물**입니다.

이 파일은 원본 CLIP 모델에서 **이미지 분석을 담당하는 부분(Visual Model)**을 추출하여, CPU 환경에 맞게 최적화한 경량화 버전입니다.

- **`visual`**: CLIP 모델의 이미지 처리 부분임을 의미합니다.
- **`quant`**: 양자화(Quantized)되어 모델의 용량이 작고 연산 속도가 빠르다는 것을 의미합니다.
- **`.onnx`**: 표준화된 ONNX 런타임으로 실행되는 모델임을 의미합니다.

프로젝트 내의 `ImageDiversityManager`와 `SemanticAnalysisEngine` 에이전트는 이제 무거운 원본 모델 대신, 가볍고 빠른 이 `clip_visual.quant.onnx` 파일을 사용하여 모든 이미지 관련 AI 분석을 수행합니다. 이것이 3단계 수정을 통해 CPU 환경에서 프로젝트의 실행 속도가 비약적으로 향상된 핵심적인 이유입니다.
