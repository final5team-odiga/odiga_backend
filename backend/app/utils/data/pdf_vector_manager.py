import os
import json
from typing import List, Dict
from openai import AzureOpenAI
from azure.core.credentials import AzureKeyCredential
from azure.search.documents import SearchClient
from azure.search.documents.indexes import SearchIndexClient
from azure.search.documents.models import VectorizedQuery
from dotenv import load_dotenv
from pathlib import Path

# AI Search ê²©ë¦¬ ì‹œìŠ¤í…œ import
try:
    from utils.isolation.ai_search_isolation import AISearchIsolationManager
    ISOLATION_AVAILABLE = True
except ImportError:
    print("âš ï¸ AI Search ê²©ë¦¬ ëª¨ë“ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.")
    ISOLATION_AVAILABLE = False

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
dotenv_path = Path(r'C:\Users\EL0021\Desktop\odiga_multiomodal_agent\.env')
load_dotenv(dotenv_path=dotenv_path, override=True)

class PDFVectorManager:
    """ë‹¤ì¤‘ ì¸ë±ìŠ¤ ì§€ì› ë²¡í„° ë°ì´í„° ê´€ë¦¬ì - ì¸ë±ìŠ¤ ì—°ê²° ë° ê²€ìƒ‰ ì „ìš©"""

    def __init__(self, isolation_enabled=True, default_index="magazine-vector-index"):
        # Azure ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
        self.search_endpoint = os.getenv("AZURE_SEARCH_ENDPOINT")
        self.search_key = os.getenv("AZURE_SEARCH_KEY")
        self.default_index = default_index
        
        # ì¸ë±ìŠ¤ë³„ SearchClient ìºì‹œ
        self.search_clients = {}
        
        # ì¸ë±ìŠ¤ í´ë¼ì´ì–¸íŠ¸ (ì—°ê²° í™•ì¸ìš©)
        self.search_index_client = SearchIndexClient(
            endpoint=self.search_endpoint,
            credential=AzureKeyCredential(self.search_key)
        )
        
        # Azure OpenAI í´ë¼ì´ì–¸íŠ¸ (ì„ë² ë”© ìƒì„±ìš©)
        self.openai_client = AzureOpenAI(
            api_key=os.getenv("AZURE_OPENAI_KEY"),
            api_version=os.getenv("AZURE_OPENAI_API_VERSION"),
            azure_endpoint=os.getenv("AZURE_OPENAI_ENDPOINT")
        )
        
        self.embedding_model = "text-embedding-ada-002"
        
        # AI Search ê²©ë¦¬ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        self.isolation_enabled = isolation_enabled and ISOLATION_AVAILABLE
        if self.isolation_enabled:
            self.isolation_manager = AISearchIsolationManager()
            print("ğŸ›¡ï¸ PDFVectorManager AI Search ê²©ë¦¬ ì‹œìŠ¤í…œ í™œì„±í™”")
        else:
            self.isolation_manager = None
            print("âš ï¸ PDFVectorManager AI Search ê²©ë¦¬ ì‹œìŠ¤í…œ ë¹„í™œì„±í™”")
        
        # ì§€ì›í•˜ëŠ” ì¸ë±ìŠ¤ ëª©ë¡
        self.supported_indexes = {
            "magazine-vector-index": {
                "description": "ë§¤ê±°ì§„ ë ˆì´ì•„ì›ƒ íŒ¨í„´",
                "vector_field": "content_vector",
                "select_fields": ["id", "pdf_name", "page_number", "content_type", 
                                "text_content", "layout_info", "image_info"]
            },
            "jsx-component-vector-index": {
                "description": "JSX ì»´í¬ë„ŒíŠ¸ íŒ¨í„´", 
                "vector_field": "jsx_vector",
                "select_fields": ["id", "component_name", "jsx_structure", "layout_method",
                                "image_count", "jsx_code", "search_keywords"]
            },
            "text-semantic-patterns-index": {
                "description": "í…ìŠ¤íŠ¸ ì˜ë¯¸ ë¶„ì„ íŒ¨í„´",
                "vector_field": "semantic_vector", 
                "select_fields": ["id", "text_content", "emotional_tone", "primary_theme",
                                "visual_keywords", "search_keywords", "semantic_tags"]
            }
        }
        
        print(f"âœ… PDFVectorManager ì´ˆê¸°í™” ì™„ë£Œ (ê¸°ë³¸ ì¸ë±ìŠ¤: {default_index})")

    def _get_search_client(self, index_name: str) -> SearchClient:
        """ì¸ë±ìŠ¤ë³„ SearchClient ë°˜í™˜ (ìºì‹œ ì‚¬ìš©)"""
        if index_name not in self.search_clients:
            self.search_clients[index_name] = SearchClient(
                endpoint=self.search_endpoint,
                index_name=index_name,
                credential=AzureKeyCredential(self.search_key)
            )
        return self.search_clients[index_name]

    async def verify_index_connectivity(self, index_name: str) -> Dict:
        """ì¸ë±ìŠ¤ ì—°ê²° ìƒíƒœ ë° ë°ì´í„° í™•ì¸"""
        try:
            # ì¸ë±ìŠ¤ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
            try:
                index_info = self.search_index_client.get_index(index_name)
                index_exists = True
            except Exception:
                return {
                    "index_name": index_name,
                    "exists": False,
                    "connected": False,
                    "error": "ì¸ë±ìŠ¤ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤",
                    "status": "not_found"
                }
            
            # SearchClient ì—°ê²° í…ŒìŠ¤íŠ¸
            search_client = self._get_search_client(index_name)
            
            # í…ŒìŠ¤íŠ¸ ê²€ìƒ‰ìœ¼ë¡œ ì—°ê²° ë° ë°ì´í„° í™•ì¸
            test_results = search_client.search(
                search_text="*",
                top=1,
                include_total_count=True
            )
            
            # ë¬¸ì„œ ìˆ˜ í™•ì¸
            document_count = getattr(test_results, 'get_count', lambda: 0)()
            
            # ì²« ë²ˆì§¸ ë¬¸ì„œ í™•ì¸ (ë°ì´í„° í˜•ì‹ ê²€ì¦)
            sample_doc = None
            for doc in test_results:
                sample_doc = dict(doc)
                break
            
            return {
                "index_name": index_name,
                "exists": True,
                "connected": True,
                "document_count": document_count,
                "sample_fields": list(sample_doc.keys()) if sample_doc else [],
                "status": "healthy" if document_count > 0 else "empty",
                "description": self.supported_indexes.get(index_name, {}).get("description", "ì•Œ ìˆ˜ ì—†ìŒ")
            }
            
        except Exception as e:
            return {
                "index_name": index_name,
                "exists": True,
                "connected": False,
                "error": str(e),
                "status": "connection_failed"
            }

    async def verify_all_indexes(self) -> Dict[str, Dict]:
        """ëª¨ë“  ì§€ì› ì¸ë±ìŠ¤ì˜ ì—°ê²° ìƒíƒœ í™•ì¸"""
        results = {}
        
        for index_name in self.supported_indexes.keys():
            print(f"ğŸ” ì¸ë±ìŠ¤ ì—°ê²° í™•ì¸ ì¤‘: {index_name}")
            status = await self.verify_index_connectivity(index_name)
            results[index_name] = status
            
            # ìƒíƒœ ë¡œê¹…
            if status["connected"] and status["document_count"] > 0:
                print(f"âœ… {index_name}: {status['document_count']}ê°œ ë¬¸ì„œ")
            elif status["connected"] and status["document_count"] == 0:
                print(f"âš ï¸ {index_name}: ì—°ê²°ë¨, ë°ì´í„° ì—†ìŒ")
            else:
                print(f"âŒ {index_name}: {status.get('error', 'ì—°ê²° ì‹¤íŒ¨')}")
        
        return results

    def _create_embeddings(self, texts: List[str]) -> List[List[float]]:
        """Azure OpenAI Embeddings APIë¡œ ë²¡í„° ìƒì„±"""
        embeddings = []
        print(f"ğŸ“Š {len(texts)}ê°œ í…ìŠ¤íŠ¸ì— ëŒ€í•œ ì„ë² ë”© ìƒì„± ì¤‘...")
        
        for i, text in enumerate(texts):
            try:
                response = self.openai_client.embeddings.create(
                    input=text,
                    model=self.embedding_model
                )
                embeddings.append(response.data[0].embedding)
                
                if (i + 1) % 10 == 0:
                    print(f" ì§„í–‰ë¥ : {i + 1}/{len(texts)} ì™„ë£Œ")
                    
            except Exception as e:
                print(f"âŒ ì„ë² ë”© ìƒì„± ì‹¤íŒ¨ (í…ìŠ¤íŠ¸ {i+1}): {e}")
                # ê¸°ë³¸ ë²¡í„° (1536 ì°¨ì›)
                embeddings.append([0.0] * 1536)
        
        print(f"âœ… ì„ë² ë”© ìƒì„± ì™„ë£Œ: {len(embeddings)}ê°œ")
        return embeddings

    def search_similar_layouts(self, query_text: str, index_name: str = None, top_k: int = 5) -> List[Dict]:
        """ë‹¤ì¤‘ ì¸ë±ìŠ¤ ì§€ì› ìœ ì‚¬ ë ˆì´ì•„ì›ƒ ê²€ìƒ‰ (AI Search ê²©ë¦¬ ì ìš©)"""
        target_index = index_name or self.default_index
        
        # ì§€ì›í•˜ëŠ” ì¸ë±ìŠ¤ì¸ì§€ í™•ì¸
        if target_index not in self.supported_indexes:
            print(f"âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” ì¸ë±ìŠ¤: {target_index}")
            return []
        
        try:
            # 1. ì¿¼ë¦¬ ê²©ë¦¬ (AI Search í‚¤ì›Œë“œ ì œê±°)
            if self.isolation_enabled:
                clean_query = self.isolation_manager.clean_query_from_azure_keywords(query_text)
                print(f"ğŸ›¡ï¸ ì¿¼ë¦¬ ê²©ë¦¬: '{query_text[:50]}...' â†’ '{clean_query[:50]}...'")
            else:
                clean_query = query_text

            # 2. ì¿¼ë¦¬ í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜
            query_embeddings = self._create_embeddings([clean_query])
            query_vector = query_embeddings[0]

            # 3. ì¸ë±ìŠ¤ë³„ ì„¤ì • ê°€ì ¸ì˜¤ê¸°
            index_config = self.supported_indexes[target_index]
            vector_field = index_config["vector_field"]
            select_fields = index_config["select_fields"]

            # 4. ë²¡í„° ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±
            vector_query = VectorizedQuery(
                vector=query_vector,
                k_nearest_neighbors=top_k * 2,  # ê²©ë¦¬ í•„í„°ë§ì„ ìœ„í•´ ë” ë§ì´ ê²€ìƒ‰
                fields=vector_field
            )

            # 5. SearchClient ê°€ì ¸ì˜¤ê¸° ë° ê²€ìƒ‰ ì‹¤í–‰
            search_client = self._get_search_client(target_index)
            
            search_params = {
                "vector_queries": [vector_query],
                "top": top_k * 2,
                "select": select_fields
            }

            raw_results = search_client.search(**search_params)

            # 6. ì›ì‹œ ê²°ê³¼ ìˆ˜ì§‘ (ì¸ë±ìŠ¤ë³„ í˜•ì‹ì— ë§ê²Œ)
            raw_data = []
            for result in raw_results:
                if target_index == "magazine-vector-index":
                    # ë§¤ê±°ì§„ ë ˆì´ì•„ì›ƒ ë°ì´í„° í˜•ì‹
                    layout_info = json.loads(result.get("layout_info", "{}"))
                    image_info = json.loads(result.get("image_info", "[]"))
                    
                    data = {
                        "id": result["id"],
                        "pdf_name": result["pdf_name"],
                        "page_number": result["page_number"],
                        "text_content": result["text_content"],
                        "layout_info": layout_info,
                        "image_info": image_info,
                        "score": result.get("@search.score", 0.0),
                        "source": "pdf_vector_search",
                        "index_type": "magazine_layout"
                    }
                    
                elif target_index == "jsx-component-vector-index":
                    # JSX ì»´í¬ë„ŒíŠ¸ ë°ì´í„° í˜•ì‹
                    jsx_structure = json.loads(result.get("jsx_structure", "{}"))
                    
                    data = {
                        "id": result["id"],
                        "component_name": result["component_name"],
                        "jsx_structure": jsx_structure,
                        "layout_method": result["layout_method"],
                        "image_count": result["image_count"],
                        "jsx_code": result["jsx_code"],
                        "search_keywords": result["search_keywords"],
                        "score": result.get("@search.score", 0.0),
                        "source": "jsx_vector_search",
                        "index_type": "jsx_component"
                    }
                    
                elif target_index == "text-semantic-patterns-index":
                    # í…ìŠ¤íŠ¸ ì˜ë¯¸ ë¶„ì„ ë°ì´í„° í˜•ì‹
                    data = {
                        "id": result["id"],
                        "text_content": result["text_content"],
                        "emotional_tone": result["emotional_tone"],
                        "primary_theme": result["primary_theme"],
                        "visual_keywords": result["visual_keywords"],
                        "search_keywords": result["search_keywords"],
                        "semantic_tags": result["semantic_tags"],
                        "score": result.get("@search.score", 0.0),
                        "source": "semantic_vector_search",
                        "index_type": "text_semantic"
                    }
                
                raw_data.append(data)

            # 7. AI Search ê²©ë¦¬ í•„í„°ë§
            if self.isolation_enabled:
                filtered_data = self.isolation_manager.filter_contaminated_data(
                    raw_data, f"{target_index}_search"
                )
                
                # 8. ì›ë³¸ ë°ì´í„° ìš°ì„ ìˆœìœ„ ì ìš©
                prioritized_data = self._prioritize_original_data(filtered_data, target_index)
                
                print(f"ğŸ›¡ï¸ ê²€ìƒ‰ ê²°ê³¼ ê²©ë¦¬: {len(raw_data)} â†’ {len(prioritized_data)}ê°œ")
                return prioritized_data[:top_k]
            else:
                return raw_data[:top_k]

        except Exception as e:
            print(f"âŒ ë²¡í„° ê²€ìƒ‰ ì‹¤íŒ¨ ({target_index}): {e}")
            if self.isolation_enabled:
                print("ğŸ›¡ï¸ ê²©ë¦¬ëœ í´ë°± ê²°ê³¼ ë°˜í™˜")
                return self._get_isolated_fallback_data(target_index)
            return []

    def _prioritize_original_data(self, data: List[Dict], index_type: str) -> List[Dict]:
        """ì¸ë±ìŠ¤ íƒ€ì…ë³„ ì›ë³¸ ë°ì´í„° ìš°ì„ ìˆœìœ„ ì ìš©"""
        if not self.isolation_enabled:
            return data

        prioritized = []
        
        for item in data:
            # ì¸ë±ìŠ¤ë³„ ì‹ ë¢°ë„ ê¸°ì¤€
            if index_type == "magazine-vector-index":
                pdf_name = item.get('pdf_name', '').lower()
                if any(pattern in pdf_name for pattern in ['template', 'layout', 'design', 'magazine']):
                    item['priority'] = 1
                    prioritized.insert(0, item)
                else:
                    item['priority'] = 2
                    prioritized.append(item)
                    
            elif index_type == "jsx-component-vector-index":
                component_name = item.get('component_name', '').lower()
                if any(pattern in component_name for pattern in ['magazine', 'article', 'content']):
                    item['priority'] = 1
                    prioritized.insert(0, item)
                else:
                    item['priority'] = 2
                    prioritized.append(item)
                    
            elif index_type == "text-semantic-patterns-index":
                semantic_tags = item.get('semantic_tags', '').lower()
                if any(pattern in semantic_tags for pattern in ['travel', 'magazine', 'descriptive']):
                    item['priority'] = 1
                    prioritized.insert(0, item)
                else:
                    item['priority'] = 2
                    prioritized.append(item)
            else:
                item['priority'] = 3
                prioritized.append(item)

        return prioritized

    def _get_isolated_fallback_data(self, index_type: str) -> List[Dict]:
        """ì¸ë±ìŠ¤ íƒ€ì…ë³„ ê²©ë¦¬ëœ í´ë°± ë°ì´í„° ë°˜í™˜"""
        if index_type == "magazine-vector-index":
            return [{
                "id": "fallback_magazine_1",
                "pdf_name": "isolated_default_layout",
                "page_number": 1,
                "text_content": "ê¸°ë³¸ ë§¤ê±°ì§„ ë ˆì´ì•„ì›ƒ",
                "layout_info": {
                    "text_blocks": [],
                    "images": [],
                    "layout_structure": ["single_column"]
                },
                "image_info": [],
                "score": 0.5,
                "source": "isolated_fallback",
                "index_type": "magazine_layout",
                "priority": 1
            }]
            
        elif index_type == "jsx-component-vector-index":
            return [{
                "id": "fallback_jsx_1",
                "component_name": "DefaultMagazineComponent",
                "jsx_structure": {"type": "basic", "layout": "single_column"},
                "layout_method": "flex",
                "image_count": 1,
                "jsx_code": "// ê¸°ë³¸ JSX ì»´í¬ë„ŒíŠ¸",
                "search_keywords": "ê¸°ë³¸ ì»´í¬ë„ŒíŠ¸",
                "score": 0.5,
                "source": "isolated_fallback",
                "index_type": "jsx_component",
                "priority": 1
            }]
            
        elif index_type == "text-semantic-patterns-index":
            return [{
                "id": "fallback_semantic_1",
                "text_content": "ê¸°ë³¸ ì—¬í–‰ ê²½í—˜ í…ìŠ¤íŠ¸",
                "emotional_tone": "neutral",
                "primary_theme": "travel",
                "visual_keywords": "ì¼ë°˜ì ì¸, ê¸°ë³¸ì ì¸",
                "search_keywords": "ì—¬í–‰ ê²½í—˜ ê¸°ë³¸",
                "semantic_tags": "travel basic",
                "score": 0.5,
                "source": "isolated_fallback",
                "index_type": "text_semantic",
                "priority": 1
            }]
        
        return []

    def get_layout_recommendations(self, content_description: str, image_count: int, 
                                 index_type: str = "magazine-vector-index") -> List[Dict]:
        """ì½˜í…ì¸  ì„¤ëª…ê³¼ ì´ë¯¸ì§€ ìˆ˜ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë ˆì´ì•„ì›ƒ ì¶”ì²œ (ë‹¤ì¤‘ ì¸ë±ìŠ¤ ì§€ì›)"""
        
        # ì´ë¯¸ì§€ ìˆ˜ì— ë”°ë¥¸ ê²€ìƒ‰ ì¿¼ë¦¬ ì¡°ì •
        if image_count <= 1:
            base_query = f"single image layout simple clean {content_description}"
        elif image_count <= 3:
            base_query = f"multiple images grid layout {content_description}"
        else:
            base_query = f"many images gallery layout complex {content_description}"

        # AI Search ê²©ë¦¬ ì ìš©
        if self.isolation_enabled:
            clean_query = self.isolation_manager.clean_query_from_azure_keywords(base_query)
            print(f"ğŸ›¡ï¸ ë ˆì´ì•„ì›ƒ ì¶”ì²œ ì¿¼ë¦¬ ê²©ë¦¬ ì ìš©")
        else:
            clean_query = base_query

        return self.search_similar_layouts(clean_query, index_type, top_k=3)

    def get_index_statistics(self) -> Dict[str, Dict]:
        """ëª¨ë“  ì¸ë±ìŠ¤ì˜ í†µê³„ ì •ë³´ ë°˜í™˜"""
        stats = {}
        
        for index_name, config in self.supported_indexes.items():
            try:
                search_client = self._get_search_client(index_name)
                results = search_client.search(
                    search_text="*",
                    top=0,
                    include_total_count=True
                )
                
                document_count = getattr(results, 'get_count', lambda: 0)()
                
                stats[index_name] = {
                    "description": config["description"],
                    "document_count": document_count,
                    "vector_field": config["vector_field"],
                    "status": "active" if document_count > 0 else "empty"
                }
                
            except Exception as e:
                stats[index_name] = {
                    "description": config["description"],
                    "document_count": 0,
                    "error": str(e),
                    "status": "error"
                }
        
        return stats

    def test_search_functionality(self) -> Dict[str, bool]:
        """ê° ì¸ë±ìŠ¤ì˜ ê²€ìƒ‰ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"""
        test_results = {}
        
        test_queries = {
            "magazine-vector-index": "magazine layout design",
            "jsx-component-vector-index": "react component image",
            "text-semantic-patterns-index": "travel experience positive"
        }
        
        for index_name, test_query in test_queries.items():
            try:
                results = self.search_similar_layouts(test_query, index_name, top_k=1)
                test_results[index_name] = len(results) > 0
                print(f"âœ… {index_name}: ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ {'ì„±ê³µ' if test_results[index_name] else 'ì‹¤íŒ¨'}")
                
            except Exception as e:
                test_results[index_name] = False
                print(f"âŒ {index_name}: ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨ - {e}")
        
        return test_results

    def check_compatibility_with_agents(self) -> Dict[str, Dict]:
        """ì—ì´ì „íŠ¸ë³„ ì¸ë±ìŠ¤ í˜¸í™˜ì„± í™•ì¸"""
        compatibility = {
            "SemanticAnalysisEngine": {
                "required_indexes": ["text-semantic-patterns-index", "magazine-vector-index"],
                "compatibility_score": 0.0
            },
            "RealtimeLayoutGenerator": {
                "required_indexes": ["magazine-vector-index"],
                "compatibility_score": 0.0
            },
            "UnifiedJSXGenerator": {
                "required_indexes": ["jsx-component-vector-index"],
                "compatibility_score": 0.0
            },
            "UnifiedMultimodalAgent": {
                "required_indexes": ["text-semantic-patterns-index", "magazine-vector-index"],
                "compatibility_score": 0.0
            }
        }
        
        # ê° ì—ì´ì „íŠ¸ë³„ í˜¸í™˜ì„± ì ìˆ˜ ê³„ì‚°
        for agent_name, agent_info in compatibility.items():
            required_indexes = agent_info["required_indexes"]
            available_count = 0
            
            for index_name in required_indexes:
                if index_name in self.supported_indexes:
                    # ì‹¤ì œ ì—°ê²° í…ŒìŠ¤íŠ¸
                    try:
                        test_results = self.search_similar_layouts("test", index_name, top_k=1)
                        if len(test_results) >= 0:  # ì—°ê²°ë§Œ ë˜ë©´ ì„±ê³µ
                            available_count += 1
                    except:
                        pass
            
            compatibility[agent_name]["compatibility_score"] = available_count / len(required_indexes)
            compatibility[agent_name]["available_indexes"] = available_count
            compatibility[agent_name]["total_required"] = len(required_indexes)
        
        return compatibility



