"""
AI Search ê²©ë¦¬ ëª¨ë“ˆ
ëª¨ë“  ì—ì´ì „íŠ¸ì—ì„œ Azure AI Search ë°ì´í„° ì˜¤ì—¼ì„ ì°¨ë‹¨í•˜ê³  ì›ë³¸ ë°ì´í„° ë¬´ê²°ì„±ì„ ë³´ì¥
"""

import re
import json
import os
from typing import Any, Dict, List, Optional
from dataclasses import dataclass


@dataclass
class IsolationConfig:
    """ê²©ë¦¬ ì„¤ì • í´ë˜ìŠ¤"""
    azure_search_keywords: List[str]
    ai_generated_patterns: List[str]
    trusted_domains: List[str]
    preservation_threshold: float
    max_images_per_section: int
    enable_logging: bool

class AISearchIsolationManager:
    """AI Search ê²©ë¦¬ ê´€ë¦¬ì - ëª¨ë“  ì—ì´ì „íŠ¸ì—ì„œ ê³µí†µ ì‚¬ìš©"""
    
    def __init__(self, config: Optional[IsolationConfig] = None):
        self.config = config or self._get_default_config()
        self.contamination_log = []
        
    def _get_default_config(self) -> IsolationConfig:
        """ê¸°ë³¸ ê²©ë¦¬ ì„¤ì •"""
        return IsolationConfig(
            azure_search_keywords=[
                "ë„ì‹œì˜ ë¯¸í•™", "ê³¨ëª©ê¸¸ì˜ ì¬ë°œê²¬", "ì•„í‹°ìŠ¤íŠ¸ ì¸í„°ë·°", "ì¹œí™˜ê²½ ë„ì‹œ",
                "ë„ì‹¬ ì† ìì—°", "ë¹›ê³¼ ê·¸ë¦¼ì", "ìƒˆë¡œìš´ ì‹œì„ ", "í¸ì§‘ì¥ì˜ ê¸€",
                "íŠ¹ì§‘:", "í¬í†  ì—ì„¸ì´", "íŠ¸ë Œë“œ:", "í”„ë¡œíŒŒì¼ í•˜ì´ë¼ì´íŠ¸",
                "ë„ì‹œ ê³„íš", "ê±´ì¶•ì˜ ë¯¸í•™", "ë¬¸í™” íƒë°©", "ë¼ì´í”„ìŠ¤íƒ€ì¼"
            ],
            ai_generated_patterns=[
                "íŠ¹ë³„í•œ ì´ì•¼ê¸°ë¥¼ ë‹´ê³  ìˆìŠµë‹ˆë‹¤",
                "ìì„¸í•œ ì´ì•¼ê¸°ë¥¼ ë‹´ê³  ìˆìŠµë‹ˆë‹¤", 
                "ìƒˆë¡œìš´ ê´€ì ì—ì„œ",
                "ë…íŠ¹í•œ ë§¤ë ¥ì„",
                "í¥ë¯¸ë¡œìš´ ê²½í—˜ì„",
                "ë‹¤ì–‘í•œ ì´ì•¼ê¸°ê°€ í¼ì³ì§‘ë‹ˆë‹¤",
                "íŠ¹ë³„í•œ ê²½í—˜ì„ ì„ ì‚¬í•©ë‹ˆë‹¤"
            ],
            trusted_domains=[
                "blob.core.windows.net",
                "your-trusted-cdn.com"
            ],
            preservation_threshold=0.3,
            max_images_per_section=3,
            enable_logging=True
        )
    
    def is_contaminated(self, data: Any, context: str = "") -> bool:
        """ë°ì´í„° ì˜¤ì—¼ ì—¬ë¶€ ê²€ì‚¬"""
        if isinstance(data, str):
            return self._check_text_contamination(data, context)
        elif isinstance(data, dict):
            return self._check_dict_contamination(data, context)
        elif isinstance(data, list):
            return any(self.is_contaminated(item, f"{context}[{i}]") for i, item in enumerate(data))
        return False
    
    def _check_text_contamination(self, text: str, context: str = "") -> bool:
        """í…ìŠ¤íŠ¸ ì˜¤ì—¼ ê²€ì‚¬"""
        if not text or not isinstance(text, str):
            return False
            
        text_lower = text.lower()
        
        # Azure AI Search í‚¤ì›Œë“œ ê²€ì‚¬
        for keyword in self.config.azure_search_keywords:
            if keyword.lower() in text_lower:
                self._log_contamination("azure_keyword", keyword, context)
                return True
        
        # AI ìƒì„± íŒ¨í„´ ê²€ì‚¬
        for pattern in self.config.ai_generated_patterns:
            if pattern.lower() in text_lower:
                self._log_contamination("ai_pattern", pattern, context)
                return True
                
        return False
    
    def _check_dict_contamination(self, data: dict, context: str = "") -> bool:
        """ë”•ì…”ë„ˆë¦¬ ì˜¤ì—¼ ê²€ì‚¬"""
        # í´ë°± ë°ì´í„° ê²€ì‚¬
        if data.get("fallback_used") or data.get("metadata", {}).get("fallback_used"):
            self._log_contamination("fallback_data", "fallback_used=True", context)
            return True
            
        # í…ìŠ¤íŠ¸ í•„ë“œ ê²€ì‚¬
        text_fields = ["title", "subtitle", "body", "content", "final_answer", "description"]
        for field in text_fields:
            if field in data and self._check_text_contamination(str(data[field]), f"{context}.{field}"):
                return True
                
        return False
    
    def _log_contamination(self, contamination_type: str, detected_content: str, context: str):
        """ì˜¤ì—¼ ê°ì§€ ë¡œê¹…"""
        if self.config.enable_logging:
            log_entry = {
                "type": contamination_type,
                "content": detected_content[:100],
                "context": context,
                "timestamp": __import__("time").time()
            }
            self.contamination_log.append(log_entry)
            print(f"ğŸš« AI Search ì˜¤ì—¼ ê°ì§€ [{contamination_type}]: {detected_content[:50]}... (ìœ„ì¹˜: {context})")
    
    def filter_contaminated_data(self, data_list: List[Any], context: str = "") -> List[Any]:
        """ì˜¤ì—¼ëœ ë°ì´í„° í•„í„°ë§"""
        if not isinstance(data_list, list):
            return data_list
            
        clean_data = []
        contaminated_count = 0
        
        for i, item in enumerate(data_list):
            if not self.is_contaminated(item, f"{context}[{i}]"):
                clean_data.append(item)
            else:
                contaminated_count += 1
        
        if contaminated_count > 0:
            print(f"ğŸ›¡ï¸ AI Search ê²©ë¦¬: {contaminated_count}ê°œ ì˜¤ì—¼ ë°ì´í„° ì œê±°, {len(clean_data)}ê°œ ì •í™” ë°ì´í„° ìœ ì§€")
            
        return clean_data
    
    def validate_original_preservation(self, result: Any, original: str, context: str = "") -> Dict[str, Any]:
        """ì›ë³¸ ë°ì´í„° ë³´ì¡´ ê²€ì¦"""
        if not isinstance(result, dict) or not original:
            return {"preservation_rate": 0.0, "contamination_detected": True}
        
        # ì›ë³¸ í‚¤ì›Œë“œ ì¶”ì¶œ
        original_words = set(re.findall(r'\w+', original.lower()))
        
        # ê²°ê³¼ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
        result_text = ""
        for key in ['title', 'subtitle', 'content', 'body', 'final_answer']:
            if key in result:
                result_text += str(result[key]) + " "
        
        result_words = set(re.findall(r'\w+', result_text.lower()))
        
        # ë³´ì¡´ìœ¨ ê³„ì‚°
        if original_words:
            preserved = original_words.intersection(result_words)
            preservation_rate = len(preserved) / len(original_words)
        else:
            preservation_rate = 0.0
        
        # ì˜¤ì—¼ ê²€ì‚¬
        contamination_detected = self.is_contaminated(result, context)
        
        return {
            "preservation_rate": preservation_rate,
            "original_keywords": len(original_words),
            "preserved_keywords": len(preserved),
            "contamination_detected": contamination_detected,
            "meets_threshold": preservation_rate >= self.config.preservation_threshold,
            "context": context
        }
    
    def clean_query_from_azure_keywords(self, query: str) -> str:
        """ì¿¼ë¦¬ì—ì„œ Azure AI Search í‚¤ì›Œë“œ ì œê±°"""
        if not query:
            return "magazine layout design structure"
            
        clean_query = query
        for keyword in self.config.azure_search_keywords:
            clean_query = clean_query.replace(keyword, "")
        
        # ë¹ˆ ì¿¼ë¦¬ ë°©ì§€
        clean_query = clean_query.strip()
        if len(clean_query) < 10:
            clean_query = "magazine layout design structure"
            
        return clean_query
    
    def is_trusted_image_url(self, url: str) -> bool:
        """ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì´ë¯¸ì§€ URL ê²€ì¦"""
        if not url or not isinstance(url, str):
            return False
        
        # ì˜ˆì‹œ URLì´ë‚˜ í”Œë ˆì´ìŠ¤í™€ë” ì œì™¸
        excluded_patterns = ['example.com', 'placeholder', 'sample', 'demo']
        for pattern in excluded_patterns:
            if pattern in url.lower():
                return False
        
        # ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ë„ë©”ì¸ í™•ì¸
        for domain in self.config.trusted_domains:
            if domain in url:
                return True
                
        return False
    
    def restore_original_content(self, original_data: Dict[str, Any], exclude_keys: Optional[List[str]] = None) -> Dict[str, Any]:
        """ì›ë³¸ ì½˜í…ì¸  ë³µì›"""
        if not original_data:
            return {}
        
        exclude_keys = exclude_keys or ['template', 'template_data', 'jsx_template']
        restored_data = {}
        
        try:
            for key, value in original_data.items():
                if key.lower() not in [k.lower() for k in exclude_keys]:
                    if isinstance(value, dict):
                        restored_value = {}
                        for nested_key, nested_value in value.items():
                            if nested_key.lower() not in [k.lower() for k in exclude_keys]:
                                restored_value[nested_key] = self._deep_copy_value(nested_value)
                        restored_data[key] = restored_value
                    else:
                        restored_data[key] = self._deep_copy_value(value)
            
            return restored_data
            
        except Exception as e:
            print(f"âš ï¸ ì›ë³¸ ì½˜í…ì¸  ë³µì› ì¤‘ ì˜¤ë¥˜: {e}")
            return original_data
    
    def _deep_copy_value(self, value: Any) -> Any:
        """ê°’ ê¹Šì€ ë³µì‚¬"""
        try:
            if isinstance(value, dict):
                return {k: self._deep_copy_value(v) for k, v in value.items()}
            elif isinstance(value, list):
                return [self._deep_copy_value(item) for item in value]
            elif isinstance(value, tuple):
                return tuple(self._deep_copy_value(item) for item in value)
            else:
                return value
        except Exception:
            return value
    
    def get_contamination_report(self) -> Dict[str, Any]:
        """ì˜¤ì—¼ ê°ì§€ ë³´ê³ ì„œ ìƒì„±"""
        if not self.contamination_log:
            return {"total_contaminations": 0, "types": {}, "recent_detections": []}
        
        types_count = {}
        for entry in self.contamination_log:
            contamination_type = entry["type"]
            types_count[contamination_type] = types_count.get(contamination_type, 0) + 1
        
        return {
            "total_contaminations": len(self.contamination_log),
            "types": types_count,
            "recent_detections": self.contamination_log[-10:],  # ìµœê·¼ 10ê°œ
            "config": {
                "keywords_count": len(self.config.azure_search_keywords),
                "patterns_count": len(self.config.ai_generated_patterns),
                "preservation_threshold": self.config.preservation_threshold
            }
        }
    
    def reset_contamination_log(self):
        """ì˜¤ì—¼ ë¡œê·¸ ì´ˆê¸°í™”"""
        self.contamination_log.clear()
        print("ğŸ§¹ AI Search ê²©ë¦¬ ë¡œê·¸ ì´ˆê¸°í™” ì™„ë£Œ")

class AgentIsolationMixin:
    """ì—ì´ì „íŠ¸ ê²©ë¦¬ ê¸°ëŠ¥ ë¯¹ìŠ¤ì¸ í´ë˜ìŠ¤"""
    
    def __init_isolation__(self, config: Optional[IsolationConfig] = None):
        """ê²©ë¦¬ ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        self.isolation_manager = AISearchIsolationManager(config)
        self.ai_search_isolation = True
        print(f"ğŸ›¡ï¸ {self.__class__.__name__} AI Search ê²©ë¦¬ ì‹œìŠ¤í…œ í™œì„±í™”")
    
    def _isolate_vector_search_results(self, results: List[Dict], context: str = "") -> List[Dict]:
        """ë²¡í„° ê²€ìƒ‰ ê²°ê³¼ ê²©ë¦¬"""
        return self.isolation_manager.filter_contaminated_data(results, f"{context}_vector_search")
    
    def _isolate_agent_responses(self, responses: List[Dict], context: str = "") -> List[Dict]:
        """ì—ì´ì „íŠ¸ ì‘ë‹µ ê²©ë¦¬"""
        return self.isolation_manager.filter_contaminated_data(responses, f"{context}_agent_responses")
    
    def _validate_content_integrity(self, result: Dict, original_content: str, context: str = "") -> Dict:
        """ì½˜í…ì¸  ë¬´ê²°ì„± ê²€ì¦"""
        validation_result = self.isolation_manager.validate_original_preservation(
            result, original_content, context
        )
        
        # ë³´ì¡´ìœ¨ì´ ë‚®ìœ¼ë©´ ì›ë³¸ ì‚¬ìš©
        if not validation_result["meets_threshold"]:
            print(f"âš ï¸ {context} ì›ë³¸ ë³´ì¡´ìœ¨ ë‚®ìŒ ({validation_result['preservation_rate']:.2f}), ì›ë³¸ ì‚¬ìš©")
            if isinstance(result, dict):
                result["content"] = original_content
                result["preservation_fallback"] = True
        
        # ë©”íƒ€ë°ì´í„° ì¶”ê°€
        if isinstance(result, dict):
            result["ai_search_isolation"] = {
                **validation_result,
                "isolation_applied": True
            }
        
        return result
    
    def _get_isolation_report(self) -> Dict[str, Any]:
        """ê²©ë¦¬ ë³´ê³ ì„œ ë°˜í™˜"""
        return self.isolation_manager.get_contamination_report()

# ì—ì´ì „íŠ¸ë³„ íŠ¹í™” ê²©ë¦¬ í´ë˜ìŠ¤ë“¤

class BindingAgentIsolation(AgentIsolationMixin):
    """BindingAgent ì „ìš© ê²©ë¦¬ ê¸°ëŠ¥"""
    
    def isolate_layout_recommendations(self, recommendations: List[Dict], image_count: int) -> List[Dict]:
        """ë ˆì´ì•„ì›ƒ ì¶”ì²œ ê²©ë¦¬"""
        # 1ì°¨: ê¸°ë³¸ ì˜¤ì—¼ í•„í„°ë§
        clean_recommendations = self.isolation_manager.filter_contaminated_data(
            recommendations, "layout_recommendations"
        )
        
        # 2ì°¨: ì´ë¯¸ì§€ ìˆ˜ ê¸°ë°˜ í•„í„°ë§
        relevant_layouts = []
        for layout in clean_recommendations:
            layout_image_count = len(layout.get('image_info', []))
            if abs(layout_image_count - image_count) <= 2:  # ì´ë¯¸ì§€ ìˆ˜ ì°¨ì´ 2ê°œ ì´í•˜
                relevant_layouts.append(layout)
        
        # 3ì°¨: ìš°ì„ ìˆœìœ„ ì ìš© (ì›ë³¸ ë°ì´í„° ìš°ì„ )
        prioritized = self._prioritize_original_layouts(relevant_layouts)
        
        print(f"ğŸ›¡ï¸ ë ˆì´ì•„ì›ƒ ì¶”ì²œ ê²©ë¦¬: {len(recommendations)} â†’ {len(prioritized)}ê°œ")
        return prioritized[:3]  # ìµœëŒ€ 3ê°œ
    
    def _prioritize_original_layouts(self, layouts: List[Dict]) -> List[Dict]:
        """ì›ë³¸ ë ˆì´ì•„ì›ƒ ìš°ì„ ìˆœìœ„ ì ìš©"""
        original_sources = ['image_analysis_json', 'user_uploaded', 'direct_input']
        prioritized = []
        
        for layout in layouts:
            source = layout.get('source', 'unknown')
            if any(original_source in source for original_source in original_sources):
                layout['priority'] = 1
                prioritized.insert(0, layout)
            else:
                layout['priority'] = 2
                prioritized.append(layout)
        
        return prioritized
    
    def isolate_image_urls(self, image_urls: List[str]) -> List[str]:
        """ì´ë¯¸ì§€ URL ê²©ë¦¬"""
        clean_urls = []
        for url in image_urls:
            if self.isolation_manager.is_trusted_image_url(url):
                clean_urls.append(url)
            else:
                print(f"ğŸš« ì‹ ë¢°í•  ìˆ˜ ì—†ëŠ” ì´ë¯¸ì§€ URL ì œì™¸: {url[:50]}...")
        
        return clean_urls

class OrgAgentIsolation(AgentIsolationMixin):
    """OrgAgent ì „ìš© ê²©ë¦¬ ê¸°ëŠ¥"""
    
    def isolate_content_sections(self, sections: List[str], context: str = "content_sections") -> List[str]:
        """ì½˜í…ì¸  ì„¹ì…˜ ê²©ë¦¬"""
        clean_sections = []
        
        for i, section in enumerate(sections):
            if not self.isolation_manager.is_contaminated(section, f"{context}[{i}]"):
                clean_sections.append(section)
        
        print(f"ğŸ›¡ï¸ ì½˜í…ì¸  ì„¹ì…˜ ê²©ë¦¬: {len(sections)} â†’ {len(clean_sections)}ê°œ")
        return clean_sections
    
    def isolate_vector_query(self, query: str) -> str:
        """ë²¡í„° ê²€ìƒ‰ ì¿¼ë¦¬ ê²©ë¦¬"""
        return self.isolation_manager.clean_query_from_azure_keywords(query)
    
    def extract_original_content_only(self, magazine_content: Any) -> str:
        """ì›ë³¸ ì½˜í…ì¸ ë§Œ ì¶”ì¶œ"""
        if isinstance(magazine_content, dict):
            sections = magazine_content.get("sections", [])
            original_text = []
            
            for section in sections:
                if isinstance(section, dict):
                    title = section.get("title", "")
                    content = section.get("content", "")
                    combined_text = title + " " + content
                    
                    if not self.isolation_manager.is_contaminated(combined_text, "magazine_content_section"):
                        original_text.append(combined_text)
            
            return "\n\n".join(original_text)
        
        elif isinstance(magazine_content, str):
            if not self.isolation_manager.is_contaminated(magazine_content, "magazine_content_string"):
                return magazine_content
        
        return ""

class CoordinatorAgentIsolation(AgentIsolationMixin):
    """CoordinatorAgent ì „ìš© ê²©ë¦¬ ê¸°ëŠ¥"""
    
    def block_azure_search_influence(self, crew_result: Any) -> Dict:
        """Azure AI Search ì˜í–¥ ì°¨ë‹¨"""
        try:
            if hasattr(crew_result, 'raw'):
                result_text = crew_result.raw
            else:
                result_text = str(crew_result)
            
            if self.isolation_manager.is_contaminated(result_text, "crew_result"):
                print("ğŸš« Azure AI Search ì˜í–¥ ê°ì§€, ì›ë³¸ ë°ì´í„°ë¡œ ë³µì›")
                return self._restore_from_magazine_content()
            
            return self._extract_json_from_text(result_text)
            
        except Exception as e:
            print(f"âš ï¸ Azure Search ì˜í–¥ ì°¨ë‹¨ ì‹¤íŒ¨: {e}")
            return self._restore_from_magazine_content()
    
    def _restore_from_magazine_content(self) -> Dict:
        """magazine_content.jsonì—ì„œ ë³µì›"""
        try:
            magazine_content_path = "./output/magazine_content.json"
            if os.path.exists(magazine_content_path):
                with open(magazine_content_path, 'r', encoding='utf-8') as f:
                    original_data = json.load(f)
                
                return self.isolation_manager.restore_original_content(
                    original_data, exclude_keys=['template', 'template_data']
                )
        except Exception as e:
            print(f"âš ï¸ magazine_content.json ë³µì› ì‹¤íŒ¨: {e}")
        
        return {"selected_templates": [], "content_sections": []}
    
    def _extract_json_from_text(self, text: str) -> Dict:
        """í…ìŠ¤íŠ¸ì—ì„œ JSON ì¶”ì¶œ"""
        try:
            json_match = re.search(r'\{.*\}', text, re.DOTALL)
            if json_match:
                return json.loads(json_match.group())
        except Exception as e:
            print(f"âš ï¸ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
        
        return {"selected_templates": [], "content_sections": []}
    
    def validate_content_authenticity(self, final_result: Dict) -> Dict:
        """ì½˜í…ì¸  ì§„ì •ì„± ê²€ì¦"""
        try:
            content_sections = final_result.get("content_sections", [])
            magazine_content_path = "./output/magazine_content.json"
            
            if os.path.exists(magazine_content_path):
                with open(magazine_content_path, 'r', encoding='utf-8') as f:
                    original_data = json.load(f)
                
                original_sections = original_data.get("sections", [])
                
                if len(content_sections) == len(original_sections):
                    corrected_count = 0
                    
                    for i, (generated, original) in enumerate(zip(content_sections, original_sections)):
                        if not self._is_content_similar(
                            generated.get("title", ""), 
                            original.get("title", "")
                        ):
                            print(f"ğŸ”„ ì„¹ì…˜ {i+1} ì›ë³¸ ë°ì´í„°ë¡œ êµì²´")
                            content_sections[i].update({
                                "title": original.get("title", ""),
                                "subtitle": original.get("subtitle", ""),
                                "body": original.get("content", original.get("body", "")),
                                "metadata": {
                                    **content_sections[i].get("metadata", {}),
                                    "source": "magazine_content_json_corrected",
                                    "azure_search_influence": "corrected",
                                    "original_content_preserved": True
                                }
                            })
                            corrected_count += 1
                    
                    if corrected_count > 0:
                        print(f"âœ… {corrected_count}ê°œ ì„¹ì…˜ì´ ì›ë³¸ ë°ì´í„°ë¡œ êµì •ë¨")
                        final_result["integration_metadata"] = {
                            **final_result.get("integration_metadata", {}),
                            "content_corrections_applied": corrected_count,
                            "azure_search_influence": "corrected"
                        }
            
            return final_result
            
        except Exception as e:
            print(f"âš ï¸ ì½˜í…ì¸  ì§„ì •ì„± ê²€ì¦ ì‹¤íŒ¨: {e}")
            return final_result
    
    def _is_content_similar(self, text1: str, text2: str) -> bool:
        """ì½˜í…ì¸  ìœ ì‚¬ì„± ê²€ì‚¬"""
        if not text1 or not text2:
            return False
        
        words1 = set(text1.lower().split())
        words2 = set(text2.lower().split())
        
        if not words1 or not words2:
            return False
        
        intersection = words1.intersection(words2)
        union = words1.union(words2)
        similarity = len(intersection) / len(union) if union else 0
        
        return similarity > self.isolation_manager.config.preservation_threshold

# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤

def create_isolation_manager(agent_type: str = "default") -> AISearchIsolationManager:
    """ì—ì´ì „íŠ¸ íƒ€ì…ë³„ ê²©ë¦¬ ë§¤ë‹ˆì € ìƒì„±"""
    configs = {
        "binding": IsolationConfig(
            azure_search_keywords=[
                "ë„ì‹œì˜ ë¯¸í•™", "ê³¨ëª©ê¸¸ì˜ ì¬ë°œê²¬", "ì•„í‹°ìŠ¤íŠ¸ ì¸í„°ë·°", "ì¹œí™˜ê²½ ë„ì‹œ",
                "ë„ì‹¬ ì† ìì—°", "ë¹›ê³¼ ê·¸ë¦¼ì", "ìƒˆë¡œìš´ ì‹œì„ ", "í¸ì§‘ì¥ì˜ ê¸€"
            ],
            ai_generated_patterns=[
                "íŠ¹ë³„í•œ ì´ì•¼ê¸°ë¥¼ ë‹´ê³  ìˆìŠµë‹ˆë‹¤",
                "ìì„¸í•œ ì´ì•¼ê¸°ë¥¼ ë‹´ê³  ìˆìŠµë‹ˆë‹¤"
            ],
            trusted_domains=["blob.core.windows.net"],
            preservation_threshold=0.3,
            max_images_per_section=3,
            enable_logging=True
        ),
        "org": IsolationConfig(
            azure_search_keywords=[
                "ë„ì‹œì˜ ë¯¸í•™", "ê³¨ëª©ê¸¸", "ë„ì‹œ ê³„íš", "ì¹œí™˜ê²½ ë„ì‹œ",
                "ë„ì‹¬ ì† ìì—°", "ë¹›ê³¼ ê·¸ë¦¼ì", "ì•„í‹°ìŠ¤íŠ¸ ì¸í„°ë·°"
            ],
            ai_generated_patterns=[
                "íŠ¹ë³„í•œ ì´ì•¼ê¸°ë¥¼ ë‹´ê³  ìˆìŠµë‹ˆë‹¤",
                "ìƒˆë¡œìš´ ê´€ì ì—ì„œ", "ë…íŠ¹í•œ ë§¤ë ¥ì„"
            ],
            trusted_domains=["blob.core.windows.net"],
            preservation_threshold=0.3,
            max_images_per_section=3,
            enable_logging=True
        ),
        "coordinator": IsolationConfig(
            azure_search_keywords=[
                "ë„ì‹œì˜ ë¯¸í•™", "ê³¨ëª©ê¸¸", "ë„ì‹œ ê³„íš", "ì¹œí™˜ê²½ ë„ì‹œ",
                "ë„ì‹¬ ì† ìì—°", "ë¹›ê³¼ ê·¸ë¦¼ì", "ì•„í‹°ìŠ¤íŠ¸ ì¸í„°ë·°",
                "íŠ¹ì§‘:", "í¬í†  ì—ì„¸ì´", "íŠ¸ë Œë“œ:"
            ],
            ai_generated_patterns=[
                "íŠ¹ë³„í•œ ì´ì•¼ê¸°ë¥¼ ë‹´ê³  ìˆìŠµë‹ˆë‹¤",
                "ìì„¸í•œ ì´ì•¼ê¸°ë¥¼ ë‹´ê³  ìˆìŠµë‹ˆë‹¤",
                "ìƒˆë¡œìš´ ê´€ì ì—ì„œ", "ë…íŠ¹í•œ ë§¤ë ¥ì„"
            ],
            trusted_domains=["blob.core.windows.net"],
            preservation_threshold=0.3,
            max_images_per_section=3,
            enable_logging=True
        )
    }
    
    config = configs.get(agent_type, configs["default"])
    return AISearchIsolationManager(config)

def test_isolation_system():
    """ê²©ë¦¬ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸"""
    print("ğŸ§ª AI Search ê²©ë¦¬ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„°
    contaminated_text = "ë„ì‹œì˜ ë¯¸í•™ì„ ë‹´ì€ íŠ¹ë³„í•œ ì´ì•¼ê¸°ë¥¼ ë‹´ê³  ìˆìŠµë‹ˆë‹¤"
    clean_text = "ë…ì¼ ì—¬í–‰ì—ì„œ ë§Œë‚œ ì•„ë¦„ë‹¤ìš´ ìˆœê°„ë“¤"
    
    manager = AISearchIsolationManager()
    
    # ì˜¤ì—¼ ê²€ì‚¬ í…ŒìŠ¤íŠ¸
    assert manager.is_contaminated(contaminated_text), "ì˜¤ì—¼ëœ í…ìŠ¤íŠ¸ ê°ì§€ ì‹¤íŒ¨"
    assert not manager.is_contaminated(clean_text), "ê¹¨ë—í•œ í…ìŠ¤íŠ¸ ì˜¤íƒì§€"
    
    # í•„í„°ë§ í…ŒìŠ¤íŠ¸
    test_data = [clean_text, contaminated_text, "ë˜ ë‹¤ë¥¸ ê¹¨ë—í•œ í…ìŠ¤íŠ¸"]
    filtered = manager.filter_contaminated_data(test_data)
    assert len(filtered) == 2, "í•„í„°ë§ ê²°ê³¼ ë¶ˆì¼ì¹˜"
    
    print("âœ… AI Search ê²©ë¦¬ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ í†µê³¼")
    return True

if __name__ == "__main__":
    test_isolation_system()
    print("ğŸ›¡ï¸ AI Search ê²©ë¦¬ ëª¨ë“ˆ ë¡œë“œ ì™„ë£Œ")
