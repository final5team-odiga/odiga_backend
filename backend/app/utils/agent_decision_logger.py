import os
import json
import time
from datetime import datetime
from typing import Dict, List, Any, Optional
from dataclasses import dataclass, asdict

@dataclass
class AgentDecision:
    """ì—ì´ì „íŠ¸ ì˜ì‚¬ê²°ì • ë¡œê·¸"""
    agent_name: str
    agent_role: str
    decision_id: str
    timestamp: str
    input_data: Dict
    decision_process: Dict
    output_result: Dict
    reasoning: str
    confidence_score: float
    context: Dict
    performance_metrics: Dict

@dataclass
class AgentInteraction:
    """ì—ì´ì „íŠ¸ ê°„ ìƒí˜¸ì‘ìš© ë¡œê·¸"""
    interaction_id: str
    source_agent: str
    target_agent: str
    interaction_type: str  # "handoff", "collaboration", "feedback"
    data_transferred: Dict
    success: bool
    timestamp: str

class AgentDecisionLogger:
    """ì—ì´ì „íŠ¸ ì˜ì‚¬ê²°ì • ë¡œê¹… ë° í•™ìŠµ ì‹œìŠ¤í…œ"""
    
    def __init__(self, log_dir: str = "./agent_logs"):
        self.log_dir = log_dir
        self.current_session_id = self._generate_session_id()
        self.decision_logs = []
        self.interaction_logs = []
        
        # ë¡œê·¸ ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(log_dir, exist_ok=True)
        
        # ì„¸ì…˜ë³„ ë¡œê·¸ íŒŒì¼ ê²½ë¡œ
        self.session_log_path = os.path.join(log_dir, f"session_{self.current_session_id}.json")
        self.cumulative_log_path = os.path.join(log_dir, "cumulative_decisions.json")
        self.learning_insights_path = os.path.join(log_dir, "learning_insights.json")
    
    def _generate_session_id(self) -> str:
        """ì„¸ì…˜ ID ìƒì„±"""
        return datetime.now().strftime("%Y%m%d_%H%M%S")
    
    def log_agent_decision(self, 
                          agent_name: str,
                          agent_role: str,
                          input_data: Dict,
                          decision_process: Dict,
                          output_result: Dict,
                          reasoning: str,
                          confidence_score: float = 0.8,
                          context: Dict = None,
                          performance_metrics: Dict = None) -> str:
        """ì—ì´ì „íŠ¸ ì˜ì‚¬ê²°ì • ë¡œê¹…"""
        
        decision_id = f"{agent_name}_{int(time.time() * 1000)}"
        
        decision = AgentDecision(
            agent_name=agent_name,
            agent_role=agent_role,
            decision_id=decision_id,
            timestamp=datetime.now().isoformat(),
            input_data=input_data,
            decision_process=decision_process,
            output_result=output_result,
            reasoning=reasoning,
            confidence_score=confidence_score,
            context=context or {},
            performance_metrics=performance_metrics or {}
        )
        
        self.decision_logs.append(decision)
        
        # ì‹¤ì‹œê°„ ë¡œê·¸ ì €ì¥
        self._save_session_logs()
        
        print(f"ğŸ“ {agent_name} ì˜ì‚¬ê²°ì • ë¡œê·¸ ê¸°ë¡: {decision_id}")
        return decision_id
    
    def log_agent_interaction(self,
                             source_agent: str,
                             target_agent: str,
                             interaction_type: str,
                             data_transferred: Dict,
                             success: bool = True) -> str:
        """ì—ì´ì „íŠ¸ ê°„ ìƒí˜¸ì‘ìš© ë¡œê¹…"""
        
        interaction_id = f"{source_agent}_to_{target_agent}_{int(time.time() * 1000)}"
        
        interaction = AgentInteraction(
            interaction_id=interaction_id,
            source_agent=source_agent,
            target_agent=target_agent,
            interaction_type=interaction_type,
            data_transferred=data_transferred,
            success=success,
            timestamp=datetime.now().isoformat()
        )
        
        self.interaction_logs.append(interaction)
        
        # ì‹¤ì‹œê°„ ë¡œê·¸ ì €ì¥
        self._save_session_logs()
        
        print(f"ğŸ”„ ì—ì´ì „íŠ¸ ìƒí˜¸ì‘ìš© ë¡œê·¸: {source_agent} â†’ {target_agent} ({interaction_type})")
        return interaction_id
    
    def get_previous_decisions(self, agent_name: str = None, limit: int = 10) -> List[Dict]:
        """ì´ì „ ì˜ì‚¬ê²°ì • ë¡œê·¸ ì¡°íšŒ"""
        
        # ëˆ„ì  ë¡œê·¸ì—ì„œ ì´ì „ ì˜ì‚¬ê²°ì • ë¡œë“œ
        previous_decisions = self._load_cumulative_logs()
        
        if agent_name:
            previous_decisions = [
                decision for decision in previous_decisions 
                if decision.get('agent_name') == agent_name
            ]
        
        # ìµœì‹  ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ì œí•œëœ ìˆ˜ë§Œ ë°˜í™˜
        return sorted(previous_decisions, key=lambda x: x.get('timestamp', ''), reverse=True)[:limit]
    
    def get_learning_insights(self, target_agent: str) -> Dict:
        """íŠ¹ì • ì—ì´ì „íŠ¸ë¥¼ ìœ„í•œ í•™ìŠµ ì¸ì‚¬ì´íŠ¸ ìƒì„±"""
        
        previous_decisions = self.get_previous_decisions(limit=50)
        
        if not previous_decisions:
            return {
                "insights": "ì´ì „ ì˜ì‚¬ê²°ì • ë¡œê·¸ê°€ ì—†ìŠµë‹ˆë‹¤.",
                "patterns": [],
                "recommendations": []
            }
        
        # íŒ¨í„´ ë¶„ì„
        patterns = self._analyze_decision_patterns(previous_decisions)
        
        # ì„±ê³µ/ì‹¤íŒ¨ ë¶„ì„
        performance_analysis = self._analyze_performance_patterns(previous_decisions)
        
        # ì¶”ì²œì‚¬í•­ ìƒì„±
        recommendations = self._generate_recommendations(patterns, performance_analysis, target_agent)
        
        insights = {
            "target_agent": target_agent,
            "analysis_timestamp": datetime.now().isoformat(),
            "total_decisions_analyzed": len(previous_decisions),
            "patterns": patterns,
            "performance_analysis": performance_analysis,
            "recommendations": recommendations,
            "key_insights": self._extract_key_insights(previous_decisions, target_agent)
        }
        
        # ì¸ì‚¬ì´íŠ¸ ì €ì¥
        self._save_learning_insights(insights)
        
        return insights
    
    def _analyze_decision_patterns(self, decisions: List[Dict]) -> List[Dict]:
        """ì˜ì‚¬ê²°ì • íŒ¨í„´ ë¶„ì„"""
        
        patterns = []
        
        # ì—ì´ì „íŠ¸ë³„ ì˜ì‚¬ê²°ì • ë¹ˆë„
        agent_frequency = {}
        for decision in decisions:
            agent_name = decision.get('agent_name', 'unknown')
            agent_frequency[agent_name] = agent_frequency.get(agent_name, 0) + 1
        
        patterns.append({
            "type": "agent_activity",
            "description": "ì—ì´ì „íŠ¸ë³„ í™œë™ ë¹ˆë„",
            "data": agent_frequency
        })
        
        # ì‹ ë¢°ë„ ì ìˆ˜ ë¶„í¬
        confidence_scores = [d.get('confidence_score', 0) for d in decisions if d.get('confidence_score')]
        if confidence_scores:
            avg_confidence = sum(confidence_scores) / len(confidence_scores)
            patterns.append({
                "type": "confidence_distribution",
                "description": "í‰ê·  ì‹ ë¢°ë„ ì ìˆ˜",
                "data": {
                    "average": round(avg_confidence, 3),
                    "min": min(confidence_scores),
                    "max": max(confidence_scores),
                    "count": len(confidence_scores)
                }
            })
        
        # ì˜ì‚¬ê²°ì • ì‹œê°„ íŒ¨í„´
        timestamps = [d.get('timestamp') for d in decisions if d.get('timestamp')]
        if len(timestamps) > 1:
            patterns.append({
                "type": "temporal_pattern",
                "description": "ì˜ì‚¬ê²°ì • ì‹œê°„ ë¶„í¬",
                "data": {
                    "first_decision": timestamps[-1],  # ê°€ì¥ ì˜¤ë˜ëœ ê²ƒ
                    "last_decision": timestamps[0],    # ê°€ì¥ ìµœê·¼ ê²ƒ
                    "total_span": len(timestamps)
                }
            })
        
        return patterns
    
    def _analyze_performance_patterns(self, decisions: List[Dict]) -> Dict:
        """ì„±ëŠ¥ íŒ¨í„´ ë¶„ì„"""
        
        performance_data = []
        for decision in decisions:
            metrics = decision.get('performance_metrics', {})
            if metrics:
                performance_data.append(metrics)
        
        if not performance_data:
            return {"message": "ì„±ëŠ¥ ë©”íŠ¸ë¦­ ë°ì´í„° ì—†ìŒ"}
        
        # ì„±ëŠ¥ ì§€í‘œ í‰ê·  ê³„ì‚°
        avg_metrics = {}
        for metrics in performance_data:
            for key, value in metrics.items():
                if isinstance(value, (int, float)):
                    if key not in avg_metrics:
                        avg_metrics[key] = []
                    avg_metrics[key].append(value)
        
        # í‰ê· ê°’ ê³„ì‚°
        for key, values in avg_metrics.items():
            avg_metrics[key] = {
                "average": sum(values) / len(values),
                "min": min(values),
                "max": max(values),
                "count": len(values)
            }
        
        return {
            "performance_metrics": avg_metrics,
            "total_samples": len(performance_data)
        }
    
    def _generate_recommendations(self, patterns: List[Dict], performance: Dict, target_agent: str) -> List[str]:
        """ì¶”ì²œì‚¬í•­ ìƒì„±"""
        
        recommendations = []
        
        # ì‹ ë¢°ë„ ê¸°ë°˜ ì¶”ì²œ
        for pattern in patterns:
            if pattern["type"] == "confidence_distribution":
                avg_confidence = pattern["data"].get("average", 0)
                if avg_confidence < 0.7:
                    recommendations.append(
                        f"{target_agent}ëŠ” ì´ì „ ì—ì´ì „íŠ¸ë“¤ì˜ ë‚®ì€ ì‹ ë¢°ë„({avg_confidence:.2f})ë¥¼ ê³ ë ¤í•˜ì—¬ "
                        "ë” ì‹ ì¤‘í•œ ê²€ì¦ ê³¼ì •ì„ ê±°ì³ì•¼ í•©ë‹ˆë‹¤."
                    )
                elif avg_confidence > 0.9:
                    recommendations.append(
                        f"ì´ì „ ì—ì´ì „íŠ¸ë“¤ì˜ ë†’ì€ ì‹ ë¢°ë„({avg_confidence:.2f})ë¥¼ ë°”íƒ•ìœ¼ë¡œ "
                        f"{target_agent}ëŠ” ê¸°ì¡´ ê²°ê³¼ë¥¼ ì ê·¹ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
                    )
        
        # í™œë™ íŒ¨í„´ ê¸°ë°˜ ì¶”ì²œ
        for pattern in patterns:
            if pattern["type"] == "agent_activity":
                most_active_agent = max(pattern["data"].items(), key=lambda x: x[1])
                recommendations.append(
                    f"ê°€ì¥ í™œë°œí–ˆë˜ {most_active_agent[0]} ì—ì´ì „íŠ¸ì˜ ì˜ì‚¬ê²°ì • íŒ¨í„´ì„ "
                    f"{target_agent}ê°€ ì°¸ê³ í•˜ë©´ ë„ì›€ì´ ë  ê²ƒì…ë‹ˆë‹¤."
                )
        
        # ì„±ëŠ¥ ê¸°ë°˜ ì¶”ì²œ
        if performance.get("performance_metrics"):
            recommendations.append(
                f"{target_agent}ëŠ” ì´ì „ ì—ì´ì „íŠ¸ë“¤ì˜ ì„±ëŠ¥ ë©”íŠ¸ë¦­ì„ ì°¸ê³ í•˜ì—¬ "
                "ìœ ì‚¬í•œ í’ˆì§ˆ ìˆ˜ì¤€ì„ ìœ ì§€í•˜ê±°ë‚˜ ê°œì„ í•´ì•¼ í•©ë‹ˆë‹¤."
            )
        
        return recommendations
    
    def _extract_key_insights(self, decisions: List[Dict], target_agent: str) -> List[str]:
        """í•µì‹¬ ì¸ì‚¬ì´íŠ¸ ì¶”ì¶œ"""
        
        insights = []
        
        if not decisions:
            return ["ì´ì „ ì˜ì‚¬ê²°ì • ë°ì´í„°ê°€ ì—†ì–´ ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."]
        
        # ìµœê·¼ ì˜ì‚¬ê²°ì • íŠ¸ë Œë“œ
        recent_decisions = decisions[:5]  # ìµœê·¼ 5ê°œ
        recent_agents = [d.get('agent_name') for d in recent_decisions]
        
        if recent_agents:
            most_recent_agent = recent_agents[0]
            insights.append(
                f"ê°€ì¥ ìµœê·¼ì— í™œë™í•œ {most_recent_agent} ì—ì´ì „íŠ¸ì˜ ê²°ê³¼ë¥¼ "
                f"{target_agent}ê°€ ìš°ì„ ì ìœ¼ë¡œ ê²€í† í•´ì•¼ í•©ë‹ˆë‹¤."
            )
        
        # ì„±ê³µ íŒ¨í„´ ì‹ë³„
        high_confidence_decisions = [
            d for d in decisions 
            if d.get('confidence_score', 0) > 0.8
        ]
        
        if high_confidence_decisions:
            insights.append(
                f"ì‹ ë¢°ë„ê°€ ë†’ì€ ì˜ì‚¬ê²°ì • {len(high_confidence_decisions)}ê°œë¥¼ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. "
                f"{target_agent}ëŠ” ì´ë“¤ì˜ ì ‘ê·¼ ë°©ì‹ì„ ì°¸ê³ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
            )
        
        # ì¼ê´€ì„± ë¶„ì„
        reasoning_patterns = [d.get('reasoning', '') for d in decisions if d.get('reasoning')]
        if len(reasoning_patterns) > 3:
            insights.append(
                f"ì´ì „ ì—ì´ì „íŠ¸ë“¤ì˜ ì¶”ë¡  íŒ¨í„´ì„ ë¶„ì„í•œ ê²°ê³¼, "
                f"{target_agent}ëŠ” ì¼ê´€ëœ ë…¼ë¦¬ì  ì ‘ê·¼ì„ ìœ ì§€í•´ì•¼ í•©ë‹ˆë‹¤."
            )
        
        return insights
    
    def _save_session_logs(self):
        """í˜„ì¬ ì„¸ì…˜ ë¡œê·¸ ì €ì¥"""
        
        session_data = {
            "session_id": self.current_session_id,
            "timestamp": datetime.now().isoformat(),
            "decisions": [asdict(decision) for decision in self.decision_logs],
            "interactions": [asdict(interaction) for interaction in self.interaction_logs]
        }
        
        with open(self.session_log_path, 'w', encoding='utf-8') as f:
            json.dump(session_data, f, ensure_ascii=False, indent=2)
        
        # ëˆ„ì  ë¡œê·¸ì—ë„ ì¶”ê°€
        self._update_cumulative_logs()
    
    def _update_cumulative_logs(self):
        """ëˆ„ì  ë¡œê·¸ ì—…ë°ì´íŠ¸"""
        
        # ê¸°ì¡´ ëˆ„ì  ë¡œê·¸ ë¡œë“œ
        cumulative_data = self._load_cumulative_logs()
        
        # í˜„ì¬ ì„¸ì…˜ì˜ ì˜ì‚¬ê²°ì • ì¶”ê°€
        for decision in self.decision_logs:
            decision_dict = asdict(decision)
            # ì¤‘ë³µ ë°©ì§€
            if not any(d.get('decision_id') == decision_dict['decision_id'] for d in cumulative_data):
                cumulative_data.append(decision_dict)
        
        # ìµœì‹  100ê°œë§Œ ìœ ì§€ (ë©”ëª¨ë¦¬ ê´€ë¦¬)
        cumulative_data = sorted(
            cumulative_data, 
            key=lambda x: x.get('timestamp', ''), 
            reverse=True
        )[:100]
        
        # ì €ì¥
        with open(self.cumulative_log_path, 'w', encoding='utf-8') as f:
            json.dump(cumulative_data, f, ensure_ascii=False, indent=2)
    
    def _load_cumulative_logs(self) -> List[Dict]:
        """ëˆ„ì  ë¡œê·¸ ë¡œë“œ"""
        
        if not os.path.exists(self.cumulative_log_path):
            return []
        
        try:
            with open(self.cumulative_log_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except:
            return []
    
    def _save_learning_insights(self, insights: Dict):
        """í•™ìŠµ ì¸ì‚¬ì´íŠ¸ ì €ì¥"""
        
        # ê¸°ì¡´ ì¸ì‚¬ì´íŠ¸ ë¡œë“œ
        existing_insights = []
        if os.path.exists(self.learning_insights_path):
            try:
                with open(self.learning_insights_path, 'r', encoding='utf-8') as f:
                    existing_insights = json.load(f)
            except:
                existing_insights = []
        
        # ìƒˆ ì¸ì‚¬ì´íŠ¸ ì¶”ê°€
        existing_insights.append(insights)
        
        # ìµœì‹  10ê°œë§Œ ìœ ì§€
        existing_insights = existing_insights[-10:]
        
        # ì €ì¥
        with open(self.learning_insights_path, 'w', encoding='utf-8') as f:
            json.dump(existing_insights, f, ensure_ascii=False, indent=2)

# ì „ì—­ ë¡œê±° ì¸ìŠ¤í„´ìŠ¤
_global_logger = None

def get_agent_logger() -> AgentDecisionLogger:
    """ì „ì—­ ì—ì´ì „íŠ¸ ë¡œê±° ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _global_logger
    if _global_logger is None:
        _global_logger = AgentDecisionLogger()
    return _global_logger
